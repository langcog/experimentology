<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 13 Project management | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 13 Project management | Experimentology">

<title>Chapter 13 Project management | Experimentology</title>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.18/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-experiments.html#experiments"><span class="toc-section-number">1</span> Experiments</a></li>
<li><a href="2-theories.html#theories"><span class="toc-section-number">2</span> Theories</a></li>
<li><a href="3-replication.html#replication"><span class="toc-section-number">3</span> Replication and reproducibility</a></li>
<li><a href="4-ethics.html#ethics"><span class="toc-section-number">4</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="5-estimation.html#estimation"><span class="toc-section-number">5</span> Estimation</a></li>
<li><a href="6-inference.html#inference"><span class="toc-section-number">6</span> Inference</a></li>
<li><a href="7-models.html#models"><span class="toc-section-number">7</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="8-measurement.html#measurement"><span class="toc-section-number">8</span> Measurement</a></li>
<li><a href="9-design.html#design"><span class="toc-section-number">9</span> Design of experiments</a></li>
<li><a href="10-sampling.html#sampling"><span class="toc-section-number">10</span> Sampling</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="11-prereg.html#prereg"><span class="toc-section-number">11</span> Preregistration</a></li>
<li><a href="12-collection.html#collection"><span class="toc-section-number">12</span> Data collection</a></li>
<li><a href="13-management.html#management"><span class="toc-section-number">13</span> Project management</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="14-viz.html#viz"><span class="toc-section-number">14</span> Visualization</a></li>
<li><a href="15-writing.html#writing"><span class="toc-section-number">15</span> Writing</a></li>
<li><a href="16-meta.html#meta"><span class="toc-section-number">16</span> Meta-analysis</a></li>
<li><a href="17-conclusions.html#conclusions"><span class="toc-section-number">17</span> Conclusions</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li><a href="A-git.html#git"><span class="toc-section-number">A</span> GitHub Tutorial</a></li>
<li><a href="B-rmarkdown.html#rmarkdown"><span class="toc-section-number">B</span> R Markdown Tutorial</a></li>
<li><a href="C-tidyverse.html#tidyverse"><span class="toc-section-number">C</span> Tidyverse Tutorial</a></li>
<li><a href="D-ggplot.html#ggplot"><span class="toc-section-number">D</span> ggplot Tutorial</a></li>
<li><a href="E-instructors.html#instructors"><span class="toc-section-number">E</span> Instructor‚Äôs guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="management" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> Project management</h1>
<!-- ```{r management-meme} -->
<!-- knitr::include_graphics("images/management/meme.jpg") -->
<!-- ``` -->
<div class="learning-goals">
<p>üçé Learning goals:</p>
<ul>
<li>Learn how to manage your research projects efficiently and transparently</li>
<li>Describe important elements of version control</li>
<li>Optimize sharing of research products, like data and analysis code, by ensuring they are Findable, Accessible, Interoperable, Reusable (FAIR)</li>
<li>Understand potential ethical constraints on sharing research products</li>
</ul>
</div>
<blockquote>
<p>Your closest collaborator is you six months ago, but you don‚Äôt reply to emails.</p>
<footer>
‚Äî Karl Broman (2016)
</footer>
</blockquote>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:versions"></span>
<img src="images/management/versions_xkcd.png" alt="Poor file management creates chaos! By xkcd (https://xkcd.com/1459). Shared under CC BY-NC 2.5" width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 13.1: Poor file management creates chaos! By xkcd (<a href="https://xkcd.com/1459" class="uri">https://xkcd.com/1459</a>). Shared under CC BY-NC 2.5<!--</p>-->
<!--</div>--></span>
</p>
<p>Have you ever returned to an old project folder to find a chaotic mess of files with names like <code>analysis-FINAL</code>, <code>analysis-FINAL-COPY</code>, and <code>analysis-FINAL-COPY-v2</code>? Which file is actually the final version!? Or perhaps you‚Äôve spent hours searching for a data file to send to your advisor, only to realize with horror that it was <em>only</em> stored on your old laptop ‚Äì the one that experienced a catastrophic hard drive failure when you spilled coffee all over it one sleepy Sunday morning. These experiences may make you sympathetic to Karl Broman‚Äôs quip: good project management practices not only make it easier to share your research with others, they also make for a more efficient and less error prone workflow that will avoid giving your future-self a headache. This chapter is about the process of managing all of the products of your research workflow ‚Äî methodological protocols, materials <a href="E-instructors.html#fn193" class="footnote-ref" id="fnref193"><sup>193</sup></a>, data, and analysis scripts ‚Äì in ways that maximize their value to you and to the broader research community.</p>
<p>When we talk about research products, we typically think of articles in academic journals, which have been scientists‚Äô main method of communication since the scientific revolution in the 1600s.<a href="E-instructors.html#fn194" class="footnote-ref" id="fnref194"><sup>194</sup></a> But articles only provide written summaries of research; they are not the original research products. In recent years, there have been widespread calls for increased sharing of research products, such as materials, data, and analysis code <span class="citation">(<a href="#ref-munafo2017" role="doc-biblioref">Munaf√≤ et al., 2017</a>)</span>. When shared appropriately, these other products can be at least as valuable as a summary article. Shared stimulus materials can be reused for new studies in creative ways; shared analysis scripts can allow for reproduction of reported results and become templates for new analyses; and shared data can enable new analyses or meta-analyses. Indeed, many funding agencies, and some journals, now require that research products be shared publicly, except when there are justified ethical or legal constraints, such as with sensitive medical data <span class="citation">(<a href="#ref-nosek2015" role="doc-biblioref">B. A. Nosek et al., 2015</a>)</span>.</p>
<p>There have been particularly intensive efforts to improve data sharing, which has been associated with benefits in terms of error detection <span class="citation">(<a href="#ref-hardwicke2021d" role="doc-biblioref">Hardwicke et al., 2021b</a>)</span>, creative re-use that generates new discoveries <span class="citation">(<a href="#ref-voytek2016" role="doc-biblioref">Voytek, 2016</a>)</span>, increased citations <span class="citation">(<a href="#ref-piwowar2013" role="doc-biblioref">Piwowar &amp; Vision, 2013</a>)</span>, and detection of fraud <span class="citation">(<a href="#ref-simonsohn2013" role="doc-biblioref">Simonsohn, 2013</a>)</span>. According to surveys, researchers are usually willing to share data in principle <span class="citation">(<a href="#ref-houtkoop2018" role="doc-biblioref">Houtkoop et al., 2018</a>)</span>, but unfortunately, in practice, they often do not, even if you directly ask them <span class="citation">(<a href="#ref-hardwicke2018c" role="doc-biblioref">Hardwicke &amp; Ioannidis, 2018</a>)</span>! Sometimes it is reported that data have been lost because they were stored on a misplaced or damaged computer or external drive, or team members with access to the data are no longer contactable <span class="citation">(<a href="#ref-tenopir2020" role="doc-biblioref">Tenopir et al., 2020</a>)</span>.</p>
<p>As we have discussed in Chapter <a href="3-replication.html#replication">3</a>, even when data are shared, they are not always formatted in a way that they can be easily understood and re-used by other researchers, or even the original authors! This issue highlights the critical role of <strong>meta-data</strong>: information that documents the data (and other products) that you share, including README files, <strong>codebooks</strong> that document datasets themselves, licenses that provide legal restrictions on reuse, etc. We will discuss best-practices for meta-data throughout the chapter.</p>
<p>Sound project management practices and sharing of research projects are mutually reinforcing goals that bring benefits for both yourself, the broader research community, and scientific progress. One particularly important benefit of good project management practices is that they enable reproducibility. As we discussed in Chapter <a href="3-replication.html#replication">3</a>, computational reproducibility involves being able to trace the provenance of any reported analytic result in a research report back to its original source. That means being able to recreate the entire analytic chain from data collection to data files, though analytic specifications to the research results reported in text, tables, and figures. If data collection is documented appropriately, and if data are stored, organized, and shared, then the provenance of a particular result is relatively easy to verify. But once this chain is broken it can be hard to reconstruct <span class="citation">(<a href="#ref-hardwicke2018b" role="doc-biblioref">Hardwicke et al., 2018</a>)</span>. That‚Äôs why it‚Äôs critical to build good project management practices into your research workflow right from the start.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:fleetwood"></span>
<img src="images/management/fleetwood_mac.jpg" alt="Fleetwood Mac fans can easily remind themsevles that the key principle of computational reproducibility is to *never break the chain* between the data and the reported results." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 13.2: Fleetwood Mac fans can easily remind themsevles that the key principle of computational reproducibility is to <em>never break the chain</em> between the data and the reported results.<!--</p>-->
<!--</div>--></span>
</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:chain"></span>
<img src="images/management/analysis_pipeline.png" alt="Illustration of the analytic chain from raw data through to research report. Based on an image shared under a CC-BY license by Hardwicke (2022; https://osf.io/vwf6e/)." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 13.3: Illustration of the analytic chain from raw data through to research report. Based on an image shared under a CC-BY license by Hardwicke (2022; <a href="https://osf.io/vwf6e/" class="uri">https://osf.io/vwf6e/</a>).<!--</p>-->
<!--</div>--></span>
</p>
<p>In this chapter, you will learn how to manage your research project both efficiently and transparently. These goals create a virtuous cycle: if you organize your research products well, they are easier to share later, and if you assume that you will be sharing, you will be motivated to organize your work better! We begin by discussing some important principles of project management, including folder structure, file naming, organization, and version control. Then we zoom in specifically on data and discuss best practices for data sharing. We end by discussing the question of what research products to share and some of the potential ethical issues that might limit your ability to share in certain circumstances.<a href="E-instructors.html#fn195" class="footnote-ref" id="fnref195"><sup>195</sup></a></p>
<div class="case-study">
<p>üî¨ Case study: ManyBabies, ManySpreadsheetFormats!</p>
<p>The ManyBabies project is an example of ‚ÄúBig Team Science‚Äù in psychology. A group of developmental psychology researchers (including some of us) were worried about many of the issues of reproducibility, replicability, and experimental methods that we‚Äôve been discussing throughout this book, so they set up a large-scale collaboration to replicate key effects in developmental science. The first of these studies was ManyBabies 1 <span class="citation">(<a href="#ref-manybabies2020" role="doc-biblioref">The ManyBabies Consortium et al., 2020</a>)</span>, a study of infants‚Äô preference for baby-talk (also known as Infant Directed Speech).</p>
<p>The core team expected a handful of labs to contribute, but after a year-long data collection period, they ended up receiving data from 69 labs around the world! The outpouring of interest signaled a lot of enthusiasm from the community for this kind of collaborative science. Unfortunately, it also made for a tremendous data management headache. As the idiosyncratic data formatting preferences of the various labs had to be reorganised to fit into a single standardized analysis pipeline, all kinds of complications and hilarity ensued <span class="citation">(<a href="#ref-byers-heinlein2020" role="doc-biblioref">Byers-Heinlein et al., 2020</a>)</span>.</p>
<p>All of the formatting changes that individual labs made were reasonable ‚Äì altering column names for clarity, combining templates into a single Excel file, changing units (e.g., from seconds to milliseconds) ‚Äì but together they created a very challenging <strong>data validation</strong> problem for the core analysis team, requiring many dozens of hours of coding and hand-checking. The data checking was critical: an error in one lab‚Äôs data was flagged during validation and led to the painful decision to drop those data from the final dataset. In future ManyBabies projects, the group has committed to using data validation software to ensure that data files uploaded by individual labs conforms to a shared standard.<a href="E-instructors.html#fn196" class="footnote-ref" id="fnref196"><sup>196</sup></a></p>
</div>
<div id="principles-of-project-management" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Principles of project management</h2>
<p>A lot of project management problems can be avoided by following a very simple file organisation system. For those researchers that ‚Äúgrew up‚Äù managing their files locally on their own computers and emailing colleagues versions of data files and manuscripts with names like <code>manuscript-FINAL-JS-rev1.xlsx</code>, a few aspects of this system may seem disconcerting. However, with a little practice, this new way of working will start to feel intuitive and have substantial benefits. Here are the principles:</p>
<ol style="list-style-type: decimal">
<li>There should be exactly one definitive copy of each document in the project, with its name denoting what it is. For example, <code>fifo_manuscript.Rmd</code> or <code>fifo_manuscript.docx</code> is the write-up of the ‚Äúfifo‚Äù project as a journal manuscript.</li>
<li>The location of each document should be within a folder which serves to uniquely identify the document‚Äôs function within the project. For example, <code>/analysis/experiment1/eye_tracking_preprocesssing.Rmd</code> is clearly the file that performs pre-processing for the analysis of eye-tracking data from Experiment 1.</li>
<li>The full project should be accessible to all collaborators and archived across multiple storage devices, either via a version control platform (e.g., <a href="">github.com</a>) or cloud provider (e.g., dropbox, box, google drive).</li>
<li>The revision history of all text- and text-based documents (minimally, data, analysis code, and manuscript files) should be archived automatically. Automatic versioning is the key feature of all version control systems and is often included by cloud storage providers.</li>
</ol>
<p>Keeping these principles in mind, we discuss best practices for project organization, version control, and file naming.</p>
<div id="organizing-your-project" class="section level3" number="13.1.1">
<h3><span class="header-section-number">13.1.1</span> Organizing your project</h3>
<p>To the greatest extent possible, all files related to a project should be stored in the same project folder (with appropriate sub-folders), and on the same storage provider.<a href="E-instructors.html#fn197" class="footnote-ref" id="fnref197"><sup>197</sup></a></p>
<p>Figure <a href="13-management.html#fig:management-organization-ex">13.4</a> shows an example project stored on the Open Science Framework. The top level folder contains sub-folders for analyses, materials, raw and processed data (kept separately). It also contains the paper manuscript, and, critically, a README file in a text format that describes the project (as well as any other meta-data that the authors would like to be associated with the research products, for example a license, explained below).</p>
<div class="figure"><span id="fig:management-organization-ex"></span>
<p class="caption marginnote shownote">
Figure 13.4: Sample top level folder structure for a project. From Klein et al., 2018. Original visible on the <a href="https://osf.io/xf6ug/">Open Science Framework</a>.
</p>
<img src="images/management/org-ex.png" alt="Sample top level folder structure for a project. From Klein et al., 2018. Original visible on the [Open Science Framework](https://osf.io/xf6ug/)." width="\linewidth"  />
</div>
<p>There‚Äôs no single established way to organize the sub-folders of a research project, but the broad categories of materials, data, analysis, and writing are typically present. In some projects ‚Äì such as those involving multiple experiments or complex data types ‚Äì you may have to adopt a more complex structure. In our projects, it‚Äôs not uncommon to find paths like <code>/data/raw_data/exp1/demographics</code>. The key principle here is to create a hierarchical structure in which subfolders uniquely identify the part of the broader space of research products that are found inside them ‚Äì that is, <code>/data/raw_data/exp1</code> contains all the raw data from Experiment 1, and <code>/data/raw_data/exp1/demographics</code> contains all the raw <em>demographics</em> data from that particular experiment.<a href="E-instructors.html#fn198" class="footnote-ref" id="fnref198"><sup>198</sup></a></p>
</div>
<div id="versioning" class="section level3" number="13.1.2">
<h3><span class="header-section-number">13.1.2</span> Versioning</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:git"></span>
<img src="images/management/git.png" alt="Visualisation of Git version control. Source: https://www.nobledesktop.com/learn/git/git-branches." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 13.5: Visualisation of Git version control. Source: <a href="https://www.nobledesktop.com/learn/git/git-branches" class="uri">https://www.nobledesktop.com/learn/git/git-branches</a>.<!--</p>-->
<!--</div>--></span>
</p>
<p>Probably everyone who has ever collaborated electronically has experienced the frustration of editing a document, only to find out that you are editing the wrong version ‚Äì perhaps some of the problems you are working on have already been corrected, or perhaps the section you are adding has already been written by someone else. A second source of frustration comes when you take a wrong turn in a project, perhaps by reorganizing a manuscript in a way that doesn‚Äôt work or refactoring code in a way that turns out to be short-sighted.</p>
<!-- [TH NOTE - potentially controversial opinion but I think Git is a pretty grim experience for collaborative manuscript writing and inferior to Google Docs. I've never had to "merge changes by hand" on Google Docs and the commenting functionality is far superior - for example, see this comment you are currently reading :) Additionally, Docs automatically stores a version history, no manual commits necessary. On this basis, I propose that we do not recommend it for manuscript writing] -->
<p>These two classes of problems are solved effectively by modern version control systems. Here we focus on the use of git, which is perhaps the most widely used version control system. Git is a great general solution for version control, but many people ‚Äì including several of us ‚Äì don‚Äôt love it for collaborative manuscript writing. We‚Äôll introduce git and its principles here, while noting that online collaboration tools like Google Docs and Overleaf<a href="E-instructors.html#fn199" class="footnote-ref" id="fnref199"><sup>199</sup></a> can be easier for writing; we cover this topic in a bit more depth in Chapter <a href="15-writing.html#writing">15</a>.</p>
<p>Git is a tool for creating and managing projects, which are called <strong>repositories</strong>. A Git repository is a directory whose revision history is tracked via a series of <strong>commits</strong> ‚Äì snapshots of the state of the project. These commits can form a tree with different <strong>branches</strong>, as when two contributors to the project are working on two different parts simultaneously. These branches can later be <strong>merged</strong> either automatically or via manual intervention in the case of conflicting changes.</p>
<p>Commonly, Git repositories are hosted by an online service like <a href="http://github.com">Github</a> to facilitate collaboration. With this workflow. a user makes changes to a local version of the repository on their own computer and <strong>pushes</strong> those changes to the online repository. Another user can then <strong>pull</strong> those changes from the online repository to their own local version. The online ‚Äúorigin‚Äù copy is always the definitive copy of the project and a record is kept of all changes. Appendix <a href="A-git.html#git">A</a> provides a practical introduction to Git and Github, and there are a variety of good tutorials available online and in print <span class="citation">(<a href="#ref-blischak2016" role="doc-biblioref">Blischak et al., 2016</a>)</span>.</p>
<p>Collaboration using version control tools is designed to solve many of the problems we‚Äôve been discussing:</p>
<ul>
<li>A remotely hosted Git repository is a cloud-based backup of your work, meaning it is less vulnerable to accidental erasure.<a href="E-instructors.html#fn200" class="footnote-ref" id="fnref200"><sup>200</sup></a></li>
<li>By virtue of having versioning history, you have access to previous drafts in case you find you have been following a blind alley and want to roll back your changes.</li>
<li>By creating new branches, you can create another, parallel history for your project, so that you can try out major changes or additions without disturbing the main branch in the process.</li>
<li>A project‚Äôs commit history is labeled with each commit‚Äôs author and date, facilitating record keeping and collaboration.</li>
<li>Automatic merging can allow synchronous editing of different parts of a manuscript or codebase.<a href="E-instructors.html#fn201" class="footnote-ref" id="fnref201"><sup>201</sup></a></li>
</ul>
<p>Organizing a project repository for collaboration and hosting on a remote platform is an important first step towards sharing! Many of our projects (like this book) are actually ‚Äúborn open‚Äù in the sense that we do all of our work on a publicly hosted repository for everyone to see <span class="citation">(<a href="#ref-rouder2015" role="doc-biblioref">Rouder, 2015</a>)</span>. This philosophy of ‚Äòworking in the open‚Äô encourages good organization practices from the beginning. It can feel uncomfortable at first, but this discomfort soon vanishes as you realize that no one is actively looking at your in-progress project.<a href="E-instructors.html#fn202" class="footnote-ref" id="fnref202"><sup>202</sup></a>), ‚ÄúThe thing that matters the least is being scooped. The thing that matters the most is being ignored.‚Äù On the other hand, if you are in an area of research that you perceive to be competitive, or where there is some significant risk of this kind of shenanigans, it‚Äôs very easy to keep part, or all, of a repository, private among your collaborators until you are ready to share more widely. All of the benefits we described still accrue. For an appropriately organized and hosted project, often the only steps required to share materials, data, and code is to make the hosted repository public and link it to an archival storage platform like the Open Science Framework.]</p>
</div>
<div id="file-names" class="section level3" number="13.1.3">
<h3><span class="header-section-number">13.1.3</span> File names</h3>
<p>As <a href="https://www.karlton.org/2017/12/naming-things-hard/">Phil Karlton reportedly said</a>, ‚ÄúThere are only two hard things in Computer Science: cache invalidation and naming things.‚Äù What‚Äôs true for computer science is true for research in general.<a href="E-instructors.html#fn203" class="footnote-ref" id="fnref203"><sup>203</sup></a> Naming files is hard! Some very organized people survive on systems like <code>info-r1-draft-2020-07-13-js.docx</code> - meaning, ‚Äúthe info project revision 1 draft of July 13th, 2020, with edits by JS.‚Äù But this kind of system needs a lot of rules and discipline, and it requires everyone in a project to buy in completely.</p>
<p>On the other hand, if you are naming a file in a hierarchically organized version control repository, the naming problem gets dramatically easier. All of a sudden, you have a context in which names make sense. <code>data.csv</code> is a terrible name for a data file on its own. But the name is actually perfectly informative ‚Äì in the context of a project repository with a README that states that there is only a single experiment, a repository structure such that the file lives in a folder called <code>raw_data</code>, and a commit history that indicates the file‚Äôs commit date and author.</p>
<p>As this example shows, naming is hard <em>out of context</em>. So here‚Äôs our rule: name a file with what it contains. Don‚Äôt use the name to convey the context of who edited it, when, or where it should go in a project.</p>
</div>
</div>
<div id="data-management" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Data Management</h2>
<p>We‚Äôve just discussed how to manage projects in general; in this section we zoom in on datasets specifically. Data are often the most valuable research product because they represent the evidence generated by our research. We maximize the value of the evidence when other scientists can reuse it for independent verification or generation of novel discoveries. Yet lots of research data are not reusable, even when they are shared. In Chapter <a href="3-replication.html#replication">3</a>, we discussed <span class="citation">Hardwicke et al. (<a href="#ref-hardwicke2018b" role="doc-biblioref">2018</a>)</span>‚Äôs study of analytic reproducibility. But before we were able to even try and reproduce the analytic results we found that only 64% of shared datasets were both complete and understandable.</p>
<p>How can you make sure that your data are managed so as to enable effective sharing? We make four primary recommendations. First, save your raw data! Second, document your data collection process. Third, organize your raw data for later analysis ‚Äì we provide guidance on organization for both spreadsheets and for data retrieved from software platforms, like Qualtrics. Fourth and finally, document your data using a codebook or other appropriate metadata.</p>
<div id="save-your-raw-data" class="section level3" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Save your raw data</h3>
<p>Raw data take many forms. For many of us, the raw data are those returned by the experimental software; for others, the raw data are videos of the experiment being carried out. Regardless of the form of these data, save them! They are often the only way to check issues in whatever processing pipeline brings these data from their initial state to the form you analyze. They also can be invaluable for addressing critiques or questions about your methods or results later in the process. If you need to correct something about your raw data, <em>do not alter the original files</em>. Make a copy, and make a note about how the copy differs from the original.<a href="E-instructors.html#fn204" class="footnote-ref" id="fnref204"><sup>204</sup></a></p>
<p>Raw data are often not anonymized or anonymizable. Anonymizing them sometimes means altering them (e.g., in the case of downloaded logs from a service that might include IDs or IP addresses). Or in some cases, anonymization is difficult or impossible without significant effort and loss of some value from the data, e.g.¬†for video data or MRI data <span class="citation">(<a href="#ref-bischoff-grethe2007" role="doc-biblioref">Bischoff-Grethe et al., 2007</a>)</span>. Unless you have specific permission for broad distribution of these identifiable data, the raw data may then need to be stored in a different way. In these cases, we recommend saving your raw data in a separate repository with the appropriate permissions. For example, in the ManyBabies 1 study we described above, the public repository does not contain the raw data contributed by participating labs, which the team could not guarantee was anonymized; these data are instead stored in a private repository.<a href="E-instructors.html#fn205" class="footnote-ref" id="fnref205"><sup>205</sup></a></p>
<p>You can use your repository‚Äôs README to describe what is and is not shared. For example, a README might state that ‚ÄúWe provide anonymized versions of the files originally downloaded from Qualtrics‚Äù or ‚ÄúParticipants did not provide permission for public distribution of raw video recordings, which are retained on a secure university server.‚Äù Critically, if you still share the derived tabular data, it should still be possible to reproduce the analytic results in your paper, even if checking the provenance of those numbers from the raw data is not possible for every reader.</p>
<!-- [TH - for my projects, I have three sub-folders in my data directory /data/raw/ /data/primary/ /data/processed and scripts in my analysis directory that document any changes between the three. The raw folder is always in .gitignore and never gets shared. Should we recommend a similar scheme here?] -->
<div class="figure"><span id="fig:management-mb-datafiles"></span>
<p class="caption marginnote shownote">
Figure 13.6: Example participant (top) and trial (bottom) level data from the ManyBabies (2020) case study.
</p>
<img src="images/management/mb-combined.png" alt="Example participant (top) and trial (bottom) level data from the ManyBabies (2020) case study." width="\linewidth"  />
</div>
<p>One common practice is the use of participant identifiers to link specific experimental data ‚Äì which, if they are responses on standardized measures, rarely pose a significant identifiability risk ‚Äì to demographic data sheets that might include more sensitive and potentially identifiable data.<a href="E-instructors.html#fn206" class="footnote-ref" id="fnref206"><sup>206</sup></a> Depending on the nature of the analyses being reported, the experimental data can then be shared with limited risk. Then a selected set of demographic variables ‚Äì for example, those that do not increase privacy risks but are necessary for particular analyses ‚Äì can be distributed as a separate file and joined back into the data later.</p>
</div>
<div id="document-your-data-collection-process" class="section level3" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Document your data collection process</h3>
<p>In order to understand the meaning of the raw data, its helpful to share as much as possible about the context in which it was collected. This also helps communicate the experience that participants had in your experiment. Documentation of this experience can take many forms.</p>
<p>If the experimental experience was a web-based questionnaire, archiving this experience can be as simple as downloading the questionnaire source.<a href="E-instructors.html#fn207" class="footnote-ref" id="fnref207"><sup>207</sup></a> On the other hand, for many more involved studies it can be more difficult to reconstruct what participants went through. This kind of situation is where video data can shine <span class="citation">(<a href="#ref-gilmore2017" role="doc-biblioref">Gilmore &amp; Adolph, 2017</a>)</span>. A video recording of a typical experimental session can provide a valuable tutorial for other experimenters ‚Äì as well as good context for readers of your paper. This is doubly true if there is a substantial interactive element to your experimental experience, as is often the case for experiments with children. For example, the ManyBabies case study that we examined shared <a href="https://nyu.databrary.org/volume/896">‚Äúwalk through‚Äù videos of experimental sessions</a> for many of the participating labs, creating a repository of standard experiences for infant development studies. If nothing else, a video of an experimental session can sometimes be a very nice archive of a particular context.<a href="E-instructors.html#fn208" class="footnote-ref" id="fnref208"><sup>208</sup></a></p>
<p>Regardless of what other documentation you keep, it‚Äôs critical to create some record linking your data to the particular documentation you have. For a questionnaire study, for example, this documentation might be as simple as a README that says that the data in the <code>raw_data</code> directory were collected on a particular date using the file named <code>experiment1.qsf</code>. This kind of ‚Äúconnective tissue‚Äù linking data to materials can be very important when you return to a project with questions. If you spot a potential error in your data, you will want to be able to examine the precise version of the materials that you used to gather those data in order to identify the source of the problem.</p>
</div>
<div id="organize-your-data-for-later-analysis-spreadsheet-version" class="section level3" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Organize your data for later analysis (spreadsheet version)</h3>
<p>Data come in many forms, but chances are that at some point during your project you will end up with a spreadsheet full of information. Well-organized spreadsheets cam mean the difference between project success and failure! A wonderful article by <span class="citation">Broman &amp; Woo (<a href="#ref-broman2018" role="doc-biblioref">2018</a>)</span> gives a guide to spreadsheet organization that lays out the principles of good spreadsheet design. We highlight some of their principles here (with our own, opinionated ordering):</p>
<div class="figure"><span id="fig:management-broman-nonrect"></span>
<p class="caption marginnote shownote">
Figure 13.7: Examples of non-rectangular spreadsheet formats that are likely to cause problems in analysis. From Broman and Woo (2018).
</p>
<img src="images/management/broman2018.png" alt="Examples of non-rectangular spreadsheet formats that are likely to cause problems in analysis. From Broman and Woo (2018)." width="\linewidth"  />
</div>
<ol style="list-style-type: decimal">
<li><p><em>Make it a rectangle</em><a href="E-instructors.html#fn209" class="footnote-ref" id="fnref209"><sup>209</sup></a>. Nearly all data analysis software, like SPSS, Stata, and JASP (and many R packages), require data to be in a tabular format.<a href="E-instructors.html#fn210" class="footnote-ref" id="fnref210"><sup>210</sup></a> If you are used to analyzing data exclusively in a spreadsheet, this kind of tabular data isn‚Äôt quite as readable, but readable formatting gets in the way of almost any analysis you want to do. Figure <a href="13-management.html#fig:management-broman-nonrect">13.7</a> gives some examples of non-rectangular spreadsheets. All of these will cause any analytic package to choke because of inconsistencies in how rows and columns are used!</p></li>
<li><p><em>Choose good names for your variables</em>. No one convention for name formatting is best, but it‚Äôs important to be consistent. We tend to follow the <a href="https://style.tidyverse.org">tidyverse style guide</a> and use lowercase words separated by underscores (<code>_</code>). It‚Äôs also helpful to give units where these are available, e.g., are reaction times in seconds or milliseconds. Table <a href="13-management.html#tab:management-broman-ex">13.1</a> gives some examples of good and bad variable names.</p></li>
</ol>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:management-broman-ex">Table 13.1: </span>Examples of good and bad variable names. Adapted from Broman and Woo (2018).</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">Good name</th>
<th align="left">Good alternative</th>
<th align="left">Avoid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">subject_id</td>
<td align="left">SubID</td>
<td align="left">subject #</td>
</tr>
<tr class="even">
<td align="left">sex</td>
<td align="left">female</td>
<td align="left">M/F</td>
</tr>
<tr class="odd">
<td align="left">rt_msec</td>
<td align="left">reaction_time_ms</td>
<td align="left">reaction time (millisec.)</td>
</tr>
</tbody>
</table>
<ol start="3" style="list-style-type: decimal">
<li><em>Be consistent with your cell formatting</em>. Each column should have one <em>kind</em> of thing in it. For example, if you have a column of numerical values, don‚Äôt all of a sudden introduce text data like ‚Äúmissing‚Äù into one of the cells. This kind of mixing of data types can cause havoc down the road. Mixed or multiple entries also don‚Äôt work, so don‚Äôt write ‚Äú0 (missing)‚Äù as the value of a cell. Leaving cells blank is also risky because its ambiguous.</li>
</ol>
<p>Most software packages have a standard value for missing data (e.g.¬†<code>NA</code> is what R uses). If you are writing dates, please be sure to use the ‚Äúglobal standard‚Äù (ISO 8601), which is YYYY-MM-DD. Anything else can be misinterpreted easily. Dates in Excel deserve special mention as a source of terribleness. Excel has an unfortunate habit of interpreting information that has nothing to do with dates as dates, destroying the original content in the process.<a href="E-instructors.html#fn211" class="footnote-ref" id="fnref211"><sup>211</sup></a></p>
<ol start="4" style="list-style-type: decimal">
<li><p><em>Decoration isn‚Äôt data</em>. Decorating your data with bold headings or highlighting may seem useful for humans, but it isn‚Äôt uniformly interpreted or even recognized by analysis software (e.g., reading an Excel spreadsheet into R will scrub all your beautiful highlighting and artistic fonts) so do not rely on it.</p></li>
<li><p><em>Save data in plain text files</em>. The CSV (comma-delimited) file format is a common standard for data that is uniformly understood by most analysis software (it is an ‚Äúinteroperable‚Äù file format).<a href="E-instructors.html#fn212" class="footnote-ref" id="fnref212"><sup>212</sup></a> The advantage of CSVs is that they are not proprietary to Microsoft or another tech company, can be inspected in a text editor, but be careful: they do not preserve Excel formulas or formatting!</p></li>
</ol>
<p>Given the points above, we recommend that you avoid analyzing your data in Excel. If it is necessary to analyze your data in a spreadsheet program, we urge you to save the raw data as a separate CSV and then create distinct analysis spreadsheets so as to be sure to retain the raw data unaltered by your (or Excel‚Äôs) manipulations.</p>
</div>
<div id="organize-your-data-for-later-analysis-software-version" class="section level3" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Organize your data for later analysis (software version)</h3>
<p>Many researchers do not create data by manually entering information into a spreadsheet. Instead they receive data as the output from a web platform, software package, or device. These tools typically provide researchers limited control over the format of the resulting tabular data export. Case in point is the survey platform Qualtrics, which provides data with not one but two header rows, complicating import into almost all analysis software!<a href="E-instructors.html#fn213" class="footnote-ref" id="fnref213"><sup>213</sup></a></p>
<p>That said, if your platform <em>does</em> allow you to control what comes out, you can try to use the principles of good tabular data design outlined above. For example, try to give your variables (e.g., questions in Qualtrics) sensible names!</p>
<div class="accident-report">
<p>‚ö†Ô∏è Accident report: Bad variable naming!</p>
<p>In our methods class, students often try to reproduce the original analyses from a published study before attempting to replicate the results in a new sample of participants. When Kengthsagn Louis looked at the code for the study she was interested in, she noticed that the variables in the analysis code were unnamed (presumably because they were output this way by the survey software). For example, one piece of Stata code looked like this!</p>
<pre verbatim="TRUE"><code>gen recall1=.
replace recall1=0 if Q21==1 
replace recall1=1 if Q21==3 | Q21==5 | Q21==6
replace recall1=2 if Q21==2 | Q21==4 | Q21==7 | Q21==8
replace recall1=0 if Q69==1 
replace recall1=1 if Q69==3 | Q69==5 | Q69==6
replace recall1=2 if Q69==2 | Q69==4 | Q69==7 | Q69==8
ta recall1</code></pre>
<p>In the process of translating this code into R in order to reproduce the analyses, Kengthsagn and a course teaching assistant, Andrew Lampinen, noticed that some participant responses had been assigned to the wrong variables. Because the variable names were not human-readable, this error was almost impossible to detect. After being made aware of the problem, the article‚Äôs author ‚Äì to their credit ‚Äì issued an immediate correction since the problem affected some of the inferential conclusions of the article <span class="citation">(<a href="#ref-petersen2019" role="doc-biblioref">Petersen, 2019</a>)</span>.</p>
<p>The moral of the story: obscure variable names can hide existing errors and create opportunities for further error! Sometimes you can adjust these within your experimental software, avoiding the issue. If not, make sure to create a ‚Äúkey‚Äù and translate the names immediately, double checking after you are done.</p>
</div>
</div>
<div id="document-the-format-of-your-data" class="section level3" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Document the format of your data</h3>
<p>Even the best-organized tabular data are not always easy to understand by other researchers, or even yourself, especially after some time has passed. For that reason, best practices for data sharing include making a <strong>codebook</strong> (also known as a <strong>data dictionary</strong>) that explicitly documents what each variable is. Figure <a href="13-management.html#fig:management-mb-codebook">13.8</a> shows an example codebook for the trial-level data in the bottom of Figure <a href="13-management.html#fig:management-mb-datafiles">13.6</a>. Each row represents one variable in the associated dataset. Codebooks often describe what type of variable a column is (e.g., numeric, string), and what values can appear in that column. A human-readable explanation is often given as well, providing providing units (e.g., ‚Äúseconds‚Äù) and a translation of numeric codes (e.g., ‚Äútest condition is coded as 1‚Äù) where relevant.</p>
<div class="figure"><span id="fig:management-mb-codebook"></span>
<p class="caption marginnote shownote">
Figure 13.8: Codebook for trial-level data (see above) from the ManyBabies (2020) case study.
</p>
<img src="images/management/mb1-codebook.png" alt="Codebook for trial-level data (see above) from the ManyBabies (2020) case study." width="\linewidth"  />
</div>
<p>Creating a codebook need not require a lot of work. Almost any documentation is better than nothing! There are also several R packages that can automatically generate a codebook for you, for example <code>codebook</code>, <code>dataspice</code>, and <code>dataMaid</code> <span class="citation">(<a href="#ref-arslan2019" role="doc-biblioref">Arslan, 2019</a>)</span>. Adding a codebook can substantially increase the reuse value of the data and prevent hours of frustration as future-you and others try to decode your variable names and assumptions.</p>
</div>
</div>
<div id="sharing-research-products" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Sharing Research Products</h2>
<p>As we‚Äôve been discussing throughout this chapter, if you‚Äôve managed your research products effectively, sharing them with others is a far less daunting prospect, and usually just requires uploading them to an online repository like the Open Science Framework. This section discusses where and how to share research products and addresses some potential limitations on sharing that you should bear in mind.</p>
<div id="where-and-how-to-share" class="section level3" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Where and how to share</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:hamilton"></span>
<img src="images/management/margaret-hamilton.jpg" alt="Before digital code and online services like the Open Science Framework, sharing computer code was pretty impractical! Margaret Hamilton, software engineer, with the computer code she and her MIT team wrote for the Apollo space mission (1969). Source: MIT Museum: https://news.mit.edu/2016/scene-at-mit-margaret-hamilton-apollo-code-0817" width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 13.9: Before digital code and online services like the Open Science Framework, sharing computer code was pretty impractical! Margaret Hamilton, software engineer, with the computer code she and her MIT team wrote for the Apollo space mission (1969). Source: MIT Museum: <a href="https://news.mit.edu/2016/scene-at-mit-margaret-hamilton-apollo-code-0817" class="uri">https://news.mit.edu/2016/scene-at-mit-margaret-hamilton-apollo-code-0817</a><!--</p>-->
<!--</div>--></span>
</p>
<p>For shared research products<a href="E-instructors.html#fn214" class="footnote-ref" id="fnref214"><sup>214</sup></a> to be usable by others, they should meet a set of standards known as ‚ÄòFAIR‚Äô: Findable, Accessible, Interoperable, and Reusable <span class="citation">(<a href="#ref-wilkinson2016" role="doc-biblioref">Wilkinson et al., 2016</a>)</span>. Findable products are easily discoverable to both humans and machines. That means linking to them in research reports using unique persistent identifiers (e.g.¬†a digital object identifier [DOI]).<a href="E-instructors.html#fn215" class="footnote-ref" id="fnref215"><sup>215</sup></a> and attaching them with meta-data describing what they are so they can be indexed by search engines. Accessibility means that research products need to be preserved across the long-term and are retrievable via their standardized identifier. Interoperability means that the research products needs to be in a format that people and machines (e.g., search engines and analysis software) can understand. Reusable means that the research products need to be well organized, documented, and licensed so that others know how to use them.</p>
<p>If you‚Äôve followed the guidance in the rest of this chapter, then you will already be well on your way to making your research products FAIR. There are a few final steps to consider. An important decision is where you are going to share the research products. We recommend uploading the files to a repository that‚Äôs designed according to support FAIR principles. Personal websites don‚Äôt cut it, since these sites tend to go out of date and disappear. There‚Äôs also no easy way to find research products on personal sites unless you know who created them. Github, though it‚Äôs a great platform for collaboration, isn‚Äôt a FAIR repository ‚Äì for one thing, products there don‚Äôt have DOIs ‚Äì and there are no archival guarantees on files that are shared there. And ‚Äì perhaps surprisingly for some researchers ‚Äì journal supplementary materials are also not a great place to put research products. Often they have no unique DOI or metadata, and they often change their URLS, leading data becoming unavailable <span class="citation">(<a href="#ref-evangelou2005" role="doc-biblioref">Evangelou et al., 2005</a>)</span>.</p>
<p>Fortunately, there are many repositories that help you conform to FAIR standards. Zenodo, Figshare, the Open Science Framework (OSF), and the various Dataverse sites are designed for this purpose, though there are many other domain-specific repositories that are particularly relevant for different research fields. We usually use the OSF as it makes it easy to share all research products connected to a project in one place. OSF is FAIR compatible and allows users to assign DOIs to their data and provide appropriate metadata.</p>
<p>We also recommend you attach a license to your research products. Academic culture is (usually) unburdened by discussion of intellectual property and legal rights and instead relies on scholarly norms about citation and attribution. The basic expectation is that if you rely on someone else‚Äôs research, you explicitly acknowledge the relevant journal article through a citation.</p>
<p>Although norms are still evolving, using research products created by others generally adheres to the same scholarly principle. However, research products can also be useful in non-academic contexts. Perhaps you created software that a company would like to use. Maybe a pediatrician would like to use a research instrument you‚Äôve been working on to assess their patients. These applications (and many other reuses of the data) require a legal license. In practice, there are a number of simple, open source licenses that permit reuse. We tend to favor <a href="https://creativecommons.org">Creative Commons licenses</a>, which come in a variety of flavors such as
<a href="https://creativecommons.org/share-your-work/public-domain/cc0/">CC0</a> (which allows all reuse),
<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a> (which allows reuse as long as there is attribution), and <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-NC</a> (which only allows attributed, non-commercial reuse).<a href="E-instructors.html#fn216" class="footnote-ref" id="fnref216"><sup>216</sup></a> Regardless of what license you choose, having a license means that your products won‚Äôt be in a ‚Äúnot sure what I‚Äôm allowed to do with this‚Äù limbo for others who are interested in reusing them.</p>
<p>As we have discussed, you may want to consider working in the open from the outset. If you are using Github to manage your project, you can link the Git repository to the Open Science Framework so it automatically syncs. This provides a valuable incentive to organize your work properly throughout your project and makes sharing super easy, because you‚Äôve already done it! On the other hand, this way of working can feel exposed for some researchers, and it does carry some risks, however small, of ‚Äúscooping‚Äù or pre-emption by other groups working in the same space. Fortunately you can set up the same Git-OSF workflow and keep it private until your ready to make it public later on. The next stage at which you should consider sharing your research products is when you submit your study to a journal. If you‚Äôre still hesitant to make the project entirely public, many repositories (including OSF) will allow you to create special links that facilitate limited access to, for example, reviewers and editors. In general, the earlier you share your research products the better because there are more opportunities for others to learn from, build on, and verify your research.<a href="E-instructors.html#fn217" class="footnote-ref" id="fnref217"><sup>217</sup></a></p>
</div>
<div id="what-you-can-and-cant-share" class="section level3" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> What you can and can‚Äôt share</h3>
<p>We‚Äôve been advocating that you share all of your research products, especially your data; however, in practice there can be some obstacles to sharing, especially if your research involves sensitive information. The most important of these is <strong>participant privacy</strong>. Unless they explicitly waive these rights, participants in psychology experiments have the expectation of privacy ‚Äì that is, no one should be able to identify them from the data they have provided. Protecting participant privacy is an important part of researchers‚Äô ethical responsibilities <span class="citation">(<a href="#ref-ross2018" role="doc-biblioref">M. W. Ross et al., 2018</a>)</span>, and needs to be balanced against the ethical imperatives to share (see Chapter <a href="4-ethics.html#ethics">4</a>).<a href="E-instructors.html#fn218" class="footnote-ref" id="fnref218"><sup>218</sup></a></p>
<p>Furthermore, there are legal regulations that protect participants‚Äô data, though these vary from country to country. In the US, the relevant regulation is <strong>HIPAA</strong>, the Health Insurance Portability and Accountability Act, which limits disclosures of private health information (<strong>PHI</strong>). In the European Union, the relevant regulation is the European GDPR (General Data Protection Regulation). It‚Äôs beyond the scope of this book to give a full treatment of these regulatory frameworks; you should consult with your local IRB regarding compliance, but here is the way we have navigated this situation while still sharing data.</p>
<p>Under both frameworks, <strong>anonymization</strong> (or equivalently <strong>de-identification</strong>) of data is a key concept, such that data sharing is generally just fine if the data meet the relevant standard. Under USguidelines, researchers can follow the ‚Äúsafe harbor‚Äù standard<a href="E-instructors.html#fn219" class="footnote-ref" id="fnref219"><sup>219</sup></a> under which data are considered to be anonymized if they do not contain identifiers like names, telephone numbers, email addresses, social security numbers, dates of birth, faces, etc. Thus, data that only contain participant IDs and nothing from this list can typically be shared without participant consent without a problem.<a href="E-instructors.html#fn220" class="footnote-ref" id="fnref220"><sup>220</sup></a></p>
<p>The EU‚Äôs GDPR also allows fully anonymized data sharing, with one big complication. Putting anonymous identifiers in a data file and removing identifiable fields does not itself suffice for GDPR anonymization if the data are still <strong>in-principle re-identifiable</strong> because you have maintained documentation linking IDs to identifiable data like names or email addresses. Only when the key linking identifiers to data has been destroyed are the data truly de-identified according to this standard.</p>
<p>De-identification is not always enough. As datasets get richer, <strong>statistical reidentification risks</strong> go up substantially such that, with a little bit of outside information, data can be matched with a unique individual. These risks are especially high with linguistic, physiological, and geospatial data, but they can be present even for simple behavioral experiments. In one influential demonstration, knowing a person‚Äôs location on two occasions was often enough to identify their data uniquely in a huge database of credit card transactions <span class="citation">(<a href="#ref-de-montjoye2015" role="doc-biblioref">De Montjoye et al., 2015</a>)</span>.<a href="E-instructors.html#fn221" class="footnote-ref" id="fnref221"><sup>221</sup></a> Thus, simply removing fields from the data is a good starting point, but if you are collecting richer data about participants‚Äô behavior you may need to consult an expert.</p>
<div class="ethics-box">
<p>üåø Ethics box: Really anonymous?</p>
<p>When we first began teaching Psych 251, our experimental methods course at Stanford, one of the biggest contributions of the course was simply showing students how to do experiments online. Amazon‚Äôs Mechanical Turk crowdsourcing service was relatively new, and our IRB did not have a good sense of what this service really was. We proposed that we would share data from the class and received approval for this practice. Our datasets were downloaded directly from Mechanical Turk and included participants‚Äô MTurk IDs (long alphanumeric strings that seemed completely anonymous). Several experiences caused us to reconsider this practice!</p>
<p>First, we discovered that MTurk IDs were in some cases linked to study participants‚Äô public Amazon ‚Äúwish lists,‚Äù which could both inadvertently provide information about the participant and also even potentially provide a basis for reidentification (in rare cases). This discovery led us to consult with our IRB and provide more explicit consent language in our class experiments, linking to instructions for making Amazon profiles private.</p>
<p>Then, a little later we received an irate email from an MTurk participant who had discovered their data on github via a search for their MTurk ID. Although they were not identified in this dataset, it convinced us that at least some participants would not like this ID shared. After another consultation with the IRB, we apologized to this individual and removed their and others‚Äô IDs from our github commit histories across that and other repositories. We now take care to anonymize IDs by creating a secret mapping between the IDs we post and the actual MTurk IDs prior to posting data.</p>
</div>
<div class="figure"><span id="fig:management-sharing-chart"></span>
<p class="caption marginnote shownote">
Figure 13.10: A decision flow chart for thinking about sharing research products. From Klein et al.¬†(2018).
</p>
<img src="images/management/kline1.png" alt="A decision flow chart for thinking about sharing research products. From Klein et al. (2018)." width="\linewidth"  />
</div>
<p>Privacy issues are ubiquitous in data sharing, and almost every experimental research project will need to solve them before sharing data. For simple projects, often these are the only issues that preclude data sharing. However, in more complex projects, other concerns can arise. Funders may have specific mandates regarding where your data should be shared. Data use agreements or collaborator preferences may restrict where and when you can share. And certain data types require much more sensitivity since they are more consequential than, say, the reaction times on a Stroop task. We include here a flow chart (Figure <a href="13-management.html#fig:management-sharing-chart">13.10</a>) that walks through some of the options and mentions relevant concerns. When in doubt, it‚Äôs often a good idea to consult with the relevant local authority, e.g.¬†your IRB for ethical issues or your research management office for regulatory issues.</p>
<!-- [TH NOTE - I think the content in this sub-section is solid, but I'm a bit worried that people get to the end of the chapter motivated to share and then we just drop a bunch of scary info on them - laws! Perhaps we could explore better ways to handle it - I think using a bit more informal language, more practical advice, and adding a bit of balance (e.g., highlighting that there is also an ethical prerogative to share) might help? This article might be helpful: https://doi.org/10.1177%2F2515245917747656] -->
</div>
</div>
<div id="chapter-summary-1" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Chapter summary</h2>
<p>All of the hard work you put into your experiments ‚Äì not to mention the contributions of your participants ‚Äì can be undermined by bad data and project management. As our accident reports and case study show, bad organizational practices can at a minimum cause huge headaches. Sometimes the consequences can be even worse. On the flip side, starting with a firm organizational foundation sets your experiment up for success. These practices also make it easier to share all of the products of your research, not just your findings. Such sharing is both useful for individual researchers and for the field as a whole.</p>
<!-- TODO: Barriers to adoption of transparent practices. -->
<!-- ::: {.accident-report} -->
<!-- ‚ö†Ô∏è Accident report: security practices for databases (how not to get hit by a ransomware attack) -->
<!-- ::: -->

</div>
</div>



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-arslan2019" class="csl-entry">
Arslan, R. C. (2019). How to automatically document data with the codebook package to facilitate data reuse. <em>Advances in Methods and Practices in Psychological Science</em>, <em>2</em>(2), 169‚Äì187.
</div>
<div id="ref-bischoff-grethe2007" class="csl-entry">
Bischoff-Grethe, A., Ozyurt, I. B., Busa, E., Quinn, B. T., Fennema-Notestine, C., Clark, C. P., Morris, S., Bondi, M. W., Jernigan, T. L., Dale, A. M.others. (2007). A technique for the deidentification of structural brain MR images. <em>Human Brain Mapping</em>, <em>28</em>(9), 892‚Äì903.
</div>
<div id="ref-blischak2016" class="csl-entry">
Blischak, J. D., Davenport, E. R., &amp; Wilson, G. (2016). A quick introduction to version control with git and GitHub. <em>PLoS Computational Biology</em>, <em>12</em>(1), e1004668.
</div>
<div id="ref-broman2018" class="csl-entry">
Broman, K. W., &amp; Woo, K. H. (2018). Data organization in spreadsheets. <em>The American Statistician</em>, <em>72</em>(1), 2‚Äì10.
</div>
<div id="ref-byers-heinlein2020" class="csl-entry">
Byers-Heinlein, K., Bergmann, C., Davies, C., Frank, M. C., Hamlin, J. K., Kline, M., Kominsky, J. F., Kosie, J. E., Lew-Williams, C., Liu, L.others. (2020). Building a collaborative psychological science: Lessons learned from ManyBabies 1. <em>Canadian Psychology/Psychologie Canadienne</em>, <em>61</em>(4), 349.
</div>
<div id="ref-de-montjoye2015" class="csl-entry">
De Montjoye, Y.-A., Radaelli, L., Singh, V. K.others. (2015). Unique in the shopping mall: On the reidentifiability of credit card metadata. <em>Science</em>, <em>347</em>(6221), 536‚Äì539.
</div>
<div id="ref-evangelou2005" class="csl-entry">
Evangelou, E., Trikalinos, T. A., &amp; Ioannidis, J. P. (2005). Unavailability of online supplementary scientific information from articles published in major journals. <em>The FASEB Journal</em>, <em>19</em>(14), 1943‚Äì1944.
</div>
<div id="ref-gilmore2017" class="csl-entry">
Gilmore, R. O., &amp; Adolph, K. E. (2017). Video can make behavioural science more reproducible. In <em>Nature Human Behaviour</em> (No. 7; Vol. 1).
</div>
<div id="ref-hardwicke2021d" class="csl-entry">
Hardwicke, T. E., Bohn, M., MacDonald, K., Hembacher, E., Nuijten, M. B., Peloquin, B. N., deMayo, B. E., Long, B., Yoon, E. J., &amp; Frank, M. C. (2021b). Analytic reproducibility in articles receiving open data badges at the journal <span>Psychological</span> <span>Science</span>: An observational study. <em>Royal Society Open Science</em>, <em>8</em>(1), 201494. <a href="https://doi.org/10.1098/rsos.201494">https://doi.org/10.1098/rsos.201494</a>
</div>
<div id="ref-hardwicke2018c" class="csl-entry">
Hardwicke, T. E., &amp; Ioannidis, J. P. A. (2018). Populating the <span>Data</span> <span>Ark</span>: <span>An</span> attempt to retrieve, preserve, and liberate data from the most highly-cited psychology and psychiatry articles. <em>PLOS ONE</em>, <em>13</em>(8), e0201856. <a href="https://doi.org/10.1371/journal.pone.0201856">https://doi.org/10.1371/journal.pone.0201856</a>
</div>
<div id="ref-hardwicke2018b" class="csl-entry">
Hardwicke, T. E., Mathur, M. B., MacDonald, K. E., Nilsonne, G., Banks, G. C., Kidwell, M., Mohr, A. H., Clayton, E., Yoon, E. J., Tessler, M. H., Lenne, R. L., Altman, S. K., Long, B., &amp; Frank, M. C. (2018). <em>Data availability, reusability, and analytic reproducibility: Evaluating the impact of a mandatory open data policy at the journal cognition</em>.
</div>
<div id="ref-houtkoop2018" class="csl-entry">
Houtkoop, B. L., Chambers, C., Macleod, M., Bishop, D. V. M., Nichols, T. E., &amp; Wagenmakers, E.-J. (2018). Data sharing in psychology: A survey on barriers and preconditions. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(1), 70‚Äì85. <a href="https://doi.org/10.1177/2515245917751886">https://doi.org/10.1177/2515245917751886</a>
</div>
<div id="ref-munafo2017" class="csl-entry">
Munaf√≤, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Percie du Sert, N., Simonsohn, U., Wagenmakers, E.-J., Ware, J. J., &amp; Ioannidis, J. P. A. (2017). A manifesto for reproducible science. <em>Nature Human Behaviour</em>, <em>1</em>(1), 1‚Äì9. <a href="https://doi.org/10.1038/s41562-016-0021">https://doi.org/10.1038/s41562-016-0021</a>
</div>
<div id="ref-nosek2015" class="csl-entry">
Nosek, B. A., Alter, G., Banks, G. C., Borsboom, D., Bowman, S. D., Breckler, S. J., Buck, S., Chambers, C. D., Chin, G., Christensen, G., Contestabile, M., Dafoe, A., Eich, E., Freese, J., Glennerster, R., Goroff, D., Green, D. P., Hesse, B., Humphreys, M., ‚Ä¶ Yarkoni, T. (2015). Promoting an open research culture. <em>Science</em>, <em>348</em>(6242), 1422‚Äì1425. <a href="https://doi.org/10.1126/science.aab2374">https://doi.org/10.1126/science.aab2374</a>
</div>
<div id="ref-petersen2019" class="csl-entry">
Petersen, M. B. (2019). <em>" healthy out-group members are represented psychologically as infected in-group members": corrigendum.</em>
</div>
<div id="ref-piwowar2013" class="csl-entry">
Piwowar, H. A., &amp; Vision, T. J. (2013). Data reuse and the open data citation advantage. <em>PeerJ</em>, <em>1</em>, e175.
</div>
<div id="ref-ross2018" class="csl-entry">
Ross, M. W., Iguchi, M. Y., &amp; Panicker, S. (2018). Ethical aspects of data sharing and research participant protections. <em>American Psychologist</em>, <em>73</em>(2), 138.
</div>
<div id="ref-rouder2015" class="csl-entry">
Rouder, J. N. (2015). The what, why, and how of born-open data. <em>Behavior Research Methods</em>, <em>48</em>(3), 1062‚Äì1069. <a href="https://doi.org/10.3758/s13428-015-0630-z">https://doi.org/10.3758/s13428-015-0630-z</a>
</div>
<div id="ref-simonsohn2013" class="csl-entry">
Simonsohn, U. (2013). Just post it: The lesson from two cases of fabricated data detected by statistics alone. <em>Psychological Science</em>, <em>24</em>(10), 1875‚Äì1888. <a href="https://doi.org/10.1177/0956797613480366">https://doi.org/10.1177/0956797613480366</a>
</div>
<div id="ref-tenopir2020" class="csl-entry">
Tenopir, C., Rice, N. M., Allard, S., Baird, L., Borycz, J., Christian, L., Grant, B., Olendorf, R., &amp; Sandusky, R. J. (2020). Data sharing, management, use, and reuse: Practices and perceptions of scientists worldwide. <em><span>PLOS</span> <span>ONE</span></em>, <em>15</em>(3), e0229003. <a href="https://doi.org/10.1371/journal.pone.0229003">https://doi.org/10.1371/journal.pone.0229003</a>
</div>
<div id="ref-manybabies2020" class="csl-entry">
The ManyBabies Consortium, Frank, M. C., Alcock, K. J., Arias-Trejo, N., Aschersleben, G., Baldwin, D., Barbu, S., Bergelson, E., Bergmann, C., Black, A. K., Blything, R., B√∂hland, M. P., Bolitho, P., Borovsky, A., Brady, S. M., Braun, B., Brown, A., Byers-Heinlein, K., Campbell, L. E., ‚Ä¶ Soderstrom, M. (2020). Quantifying sources of variability in infancy research using the <span>Infant-Directed-Speech</span> preference. In <em>Advances in Methods and Practices in Psychological Science</em> (No. 1; Vol. 3, pp. 24‚Äì52).
</div>
<div id="ref-voytek2016" class="csl-entry">
Voytek, B. (2016). The virtuous cycle of a data ecosystem. <em>PLOS Computational Biology</em>, <em>12</em>(8), e1005037. <a href="https://doi.org/10.1371/journal.pcbi.1005037">https://doi.org/10.1371/journal.pcbi.1005037</a>
</div>
<div id="ref-wilkinson2016" class="csl-entry">
Wilkinson, M. D., Dumontier, M., Aalbersberg, I. J. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., Silva Santos, L. B. da, Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., ‚Ä¶ Mons, B. (2016). The <span>FAIR</span> guiding principles for scientific data management and stewardship. <em>Sci Data</em>, <em>3</em>, 160018.
</div>
</div>
<p style="text-align: center;">
<a href="12-collection.html"><button class="btn btn-default">Previous</button></a>
<a href="14-viz.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<link href="www/global.css" rel="stylesheet">
<script src="www/global.js"></script>


</body>
</html>
