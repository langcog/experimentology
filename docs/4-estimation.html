<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 4 Estimation | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 4 Estimation | Experimentology">

<title>Chapter 4 Estimation | Experimentology</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>





<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="toc/toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#section"></a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-intro.html#intro"><span class="toc-section-number">1</span> Experiments and Theories</a></li>
<li><a href="2-replication.html#replication"><span class="toc-section-number">2</span> Replication and reproducibility</a></li>
<li><a href="3-ethics.html#ethics"><span class="toc-section-number">3</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="4-estimation.html#estimation"><span class="toc-section-number">4</span> Estimation</a></li>
<li><a href="5-inference.html#inference"><span class="toc-section-number">5</span> Inference</a></li>
<li><a href="6-models.html#models"><span class="toc-section-number">6</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="7-measurement.html#measurement"><span class="toc-section-number">7</span> Measurement</a></li>
<li><a href="8-design.html#design"><span class="toc-section-number">8</span> Design of experiments</a></li>
<li><a href="9-sampling.html#sampling"><span class="toc-section-number">9</span> Sampling</a></li>
<li><a href="10-prereg.html#prereg"><span class="toc-section-number">10</span> Preregistration</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="11-selection.html#selection"><span class="toc-section-number">11</span> Replicating or extending an existing study</a></li>
<li><a href="12-collection.html#collection"><span class="toc-section-number">12</span> Data collection</a></li>
<li><a href="13-management.html#management"><span class="toc-section-number">13</span> Project management and sharing</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="14-viz.html#viz"><span class="toc-section-number">14</span> Visualization</a></li>
<li><a href="15-eda.html#eda"><span class="toc-section-number">15</span> Exploratory data analysis</a></li>
<li><a href="16-writing.html#writing"><span class="toc-section-number">16</span> Reproducible writing</a></li>
<li><a href="17-meta.html#meta"><span class="toc-section-number">17</span> Meta-analysis</a></li>
<li><a href="18-conclusions.html#conclusions"><span class="toc-section-number">18</span> Conclusions</a></li>
<li class="part"><span><b>VI Appendices</b></span></li>
<li><a href="19-github.html#github"><span class="toc-section-number">19</span> Github Tutorial</a></li>
<li><a href="20-rmarkdown.html#rmarkdown"><span class="toc-section-number">20</span> R Markdown Tutorial</a></li>
<li><a href="21-tidyverse.html#tidyverse"><span class="toc-section-number">21</span> Tidyverse Tutorial</a></li>
<li><a href="22-ggplot.html#ggplot"><span class="toc-section-number">22</span> ggplot Tutorial</a></li>
<li><a href="23-instructors.html#instructors"><span class="toc-section-number">23</span> Instructorâ€™s Guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="estimation" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Estimation</h1>
<p>Idea of a sampling distribution</p>
<div id="meta-notes" class="section level2">
<h2><span class="header-section-number">4.1</span> Meta-notes</h2>
<div id="topics-not-yet-covered" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Topics not yet covered</h3>
</div>
<div id="not-sure-if-there-should-be-covered" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Not sure if there should be covered</h3>
<ul>
<li>Measures of effect-size for binary outcomes (maybe a brief mention?)</li>
</ul>
</div>
</div>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">4.2</span> Introduction</h2>
<!-- ::: {.case-study} -->
<!-- ğŸ”¬ Case study: The lady tasting tea -->
</div>
<div id="running-example-the-lady-tasting-tea" class="section level2">
<h2><span class="header-section-number">4.3</span> Running example: The lady tasting tea</h2>
<p>The birth of modern statistical inference came from a single, epochal act of mansplaining.<label for="tufte-sn-1" class="margin-toggle sidenote-number">1</label><input type="checkbox" id="tufte-sn-1" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">1</span> An important piece of context for the work of Ronald Fisher, Karl Pearson, and other early pioneers of statistical inference is that they were all strong proponents of eugenics. Fisher was the founding Chairman of the Cambridge Eugenics Society. Pearson was perhaps even worse, an avowed Social Darwinist who believed fervently in Eugenic legislation. These views are repugnant.</span> Sir Ronald Fisher was apparently at a party when a lady declared that she could tell the difference between cups when the tea was added to the milk vs.Â the milk to the tea. Rather than taking her at her word, Fisher devised an experimental and data analysis procedure to test her claim.<label for="tufte-sn-2" class="margin-toggle sidenote-number">2</label><input type="checkbox" id="tufte-sn-2" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">2</span> If youâ€™re interested in this history, we recommend <span class="citation">Salsburg (<label for="tufte-mn-1" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-1" class="margin-toggle">2001<span class="marginnote">Salsburg, David. 2001. <em>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</em>. Macmillan.</span>)</span>â€™s delightful book, â€œThe Lady Tasting Tea,â€ about the origins of modern statistics.</span></p>
<p>The basic schema of the experiment was that the lady would have to judge a set of new cups of tea and sort them into milk-first vs.Â tea-first sets. Her data would then be analyzed to determine whether her level of correct choice exceeded that expected by chance. While this process now sounds like a quotidian experiment that might be done on a cooking reality show, in fact this is one of those touchstones that feels unremarkable because it literally established the way science was done for the next century.</p>
<p>The first element of the experiment that was unusual was its treatment of design confounds such as pouring order or cup material. Prior experimental practice would have been to try to equate all of the cups as closely as possible, decreasing the influence of confounders. Fisher recognized that this strategy was insufficient and that random assignment was critical for making strong causal inferences about the treatment (milk then tea vs.Â tea then milk).<label for="tufte-sn-3" class="margin-toggle sidenote-number">3</label><input type="checkbox" id="tufte-sn-3" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">3</span> We discussed the causal power of random assignment in Chapter <a href="1-intro.html#intro">1</a> but hereâ€™s where this idea originates!</span><label for="tufte-sn-4" class="margin-toggle sidenote-number">4</label><input type="checkbox" id="tufte-sn-4" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">4</span> MM: Minor, but there were written records of RCTs well before this (e.g., to investigate scurvy treatments in the 18th c.).</span></p>
<p>With apologies to Fisher, for our example, weâ€™ll design a slightly more modern version of his experiment using a forced-choice judgment measure. We present participants with 50 cups of tea (in random order, of course). Half are prepared milk-first, half tea-first. Then the participant must give an independent judgment about each by rating the tea on a scale from 0 (horrible) to 10 (perfect).</p>
<p>Our task in this chapter will be to estimate the quality of the tea when it is milk-first. More formally, we want to use our <strong>sample</strong> of 50 tea judgments to estimate a <strong>population parameter</strong> that we canâ€™t directly observe, namely the true perceived quality of all possible milk-first cups.<label for="tufte-sn-5" class="margin-toggle sidenote-number">5</label><input type="checkbox" id="tufte-sn-5" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">5</span> MM: This example is perhaps a little confusing for showing the sample vs.Â population parameter because the population here is a bit hard to conceptualize. Also, I worry that readers will be mislead into thinking that itâ€™s the subjectivity in tea ratings that causes statistical uncertainty, rather than the finite sample size. An easier example for this chapter might be something like estimating the mean height of students at College X, where itâ€™s more clear that there is no subjectivity involved and that the population is the mean height if we were to measure every student at College X rather than just a sample.</span> We will use <span class="math inline">\(\mu\)</span> to denote the parameter we want to estimate (the â€œestimandâ€) and <span class="math inline">\(\widehat{\mu}\)</span> its sample estimate.<label for="tufte-sn-6" class="margin-toggle sidenote-number">6</label><input type="checkbox" id="tufte-sn-6" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">6</span> It is common practice to use hats to denote sample estimates.</span></p>
</div>
<div id="maximum-likelihood-estimation-fitting-a-model-to-the-data" class="section level2">
<h2><span class="header-section-number">4.4</span> Maximum likelihood estimation: Fitting a model to the data</h2>
<p>[Here I would suggest that we ramp up more slowly to Bayes by simply estimating the mean in one sample.]</p>
<p>Taking the sample mean as our estimate <span class="math inline">\(\widehat{\mu}\)</span> is an example of an estimation approach called <strong>maximum likelihood estimation</strong>. In general terms, maximum likelihood estimation is a two-step process. First, we assume a model for how the data were generated. This model is specified in terms of certain population parameters. In our example, the â€œmodelâ€ is as simple as they come: we just assume the data have some unknown mean <span class="math inline">\(\mu\)</span>. (In other problems, like multivariable regression, the model is more complicated, for example involving more than one regression coefficient.)</p>
<p>Second, we try to find the values of the population parameters that make our observed data as likely as possible. For example, if our sample mean is <span class="math inline">\(\widehat{\mu} = 3.45\)</span>, what underlying value of <span class="math inline">\(\mu\)</span> would make these data most likely to occur? Well, suppose the underlying parameter were <span class="math inline">\(\mu=10\)</span>. Then it would be pretty unlikely that our sample mean would be so much smaller. So <span class="math inline">\(\mu=10\)</span> is a poor guess for the population parameter based on these data. Conversely, if the parameter were <span class="math inline">\(\mu=-10\)</span>, it would pretty unlikely that our sample mean would be so much <em>larger</em>. The value of <span class="math inline">\(\mu\)</span> that makes these data most likely is just 3.45 itself: the sample mean! That is why the sample mean in this case is the maximum likelihood estimate.</p>
</div>
<div id="bayesian-estimation-incorporating-prior-beliefs" class="section level2">
<h2><span class="header-section-number">4.5</span> Bayesian estimation: Incorporating prior beliefs</h2>
<p>[Here I would suggest transitioning by saying that what we did above makes sense if the only criterion for what constitutes a good guess is the data themselves. "But what if we had some background knowledge about heights in this college? For example, we have data from the US Census on adult heights, so weâ€™d probably expect college students to be roughly similar.]</p>
<p>[EXISTING TEXT BELOW]</p>
<p>Letâ€™s say we want to estimate some quantity, weâ€™ll call it <span class="math inline">\(h\)</span> â€“ our belief about the participantâ€™s accuracy.<label for="tufte-sn-7" class="margin-toggle sidenote-number">7</label><input type="checkbox" id="tufte-sn-7" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">7</span> You canâ€™t get away from measurement and psychometrics! We said we were really interested in the effect of tea ordering on tea perception. But this number that weâ€™re estimating is something more like this particular participantâ€™s accuracy, and thatâ€™s not the same thing that we actually wanted. To get from what weâ€™re estimating to our effect of interest, weâ€™d need to establish some <strong>linking hypotheses</strong> about how the participantâ€™s accuracy can be derived from the participantâ€™s perception and the properties of the stimulus. Thatâ€™s perhaps not worth doing in this toy example, but more generally itâ€™s a critical part of getting from your measure to your construct of interest!</span> We observe some data <span class="math inline">\(d\)</span>, consisting of the set of correct and incorrect responses in the experiment. Now we can use <strong>Bayesâ€™ rule</strong>, a tool from basic probability theory, to estimate this number.</p>
<p>Bayesâ€™ rule says:</p>
<p><span class="math display">\[
\color{purple}{p(h | d)} = \frac{\color{red}{p(d | h)} \color{blue}{p(h)}}{\color{black}{p(d)}}.
\]</span> Each part of this equation has a name, and itâ€™s worth becoming familiar with them. The thing we want to compute (<span class="math inline">\(p(h|d)\)</span>) is called the <strong>posterior probability</strong> â€“ it tell us what we should believe about the participantâ€™s ability given the data we observed. We then break that down into two terms in the numerator.<label for="tufte-sn-8" class="margin-toggle sidenote-number">8</label><input type="checkbox" id="tufte-sn-8" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">8</span> Weâ€™re making the posterior <span style="color: purple;">purple</span> to indicate the combination of likelihood (<span style="color: red;">red</span>) and prior (<span style="color: blue;">blue</span>).</span></p>
<p>The first part of the numerator is <span class="math inline">\(p(d|h)\)</span>, the probability of the data we observed given our hypothesis about the participantâ€™s ability. This part is called the <strong>likelihood</strong>.<label for="tufte-sn-9" class="margin-toggle sidenote-number">9</label><input type="checkbox" id="tufte-sn-9" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">9</span> Speaking informally, â€œlikelihoodâ€ is just a synonym for probability, but this is a technical meaning for the term, which can get a bit confusing.</span> This term tells us about the relationship between our hypothesis and the data we observed â€“ so if we think the participant has high ability (say <span class="math inline">\(h = .9\)</span>) then the probability of a bunch of low accuracy observations will be fairly low.</p>
<p>The second term in the numerator, <span class="math inline">\(p(h)\)</span>, is called the <strong>prior</strong>. This term encodes our beliefs about how likely our participant is to have different levels of ability. Intuitively, if we think that they are very unlikely to have high tea discrimination ability, we should require more evidence to convince us of a particular level of discrimination. In contrast, if we think they are likely to have this ability, we should be easier to convince.</p>
<div class="figure"><span style="display:block;" id="fig:inference-bayes-demo"></span>
<p class="caption marginnote shownote">
Figure 4.1: Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior.
</p>
<img src="experimentology_files/figure-html/inference-bayes-demo-1.png" alt="Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior." width="\linewidth"  />
</div>
<p>Figure <a href="4-estimation.html#fig:inference-bayes-demo">4.1</a> gives an example of the combination of prior and data.<label for="tufte-sn-10" class="margin-toggle sidenote-number">10</label><input type="checkbox" id="tufte-sn-10" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">10</span> The model we use for this example is called a <strong>Beta-Binomial conjugate model</strong> and is a very convenient model for working with count data representing successes and failures.</span> For the sake of this example, we assume that we have run 12 tea discrimination trials and observed 9 successes and 3 failures. The evidence alone â€“ with no prior â€“ suggests a discrimination estimate of <span class="math inline">\(9/12 = .75\)</span>.<label for="tufte-sn-11" class="margin-toggle sidenote-number">11</label><input type="checkbox" id="tufte-sn-11" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">11</span> Technically this is known as the <strong>maximum a posteriori</strong> estimate, or the MAP. We wonâ€™t use that term though. (MM: Iâ€™d rephrase. This sounds like â€œMAPâ€ = â€œMLEâ€.)</span> When we use a flat prior, we get the same estimate of 0.75.<label for="tufte-sn-12" class="margin-toggle sidenote-number">12</label><input type="checkbox" id="tufte-sn-12" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">12</span> MM: I think it may be illuminating to say more explicitly that Bayes estimates and frequentist estimates will exactly coincide either under a flat prior or as <span class="math inline">\(n \to \infty\)</span>.</span> In contrast, if we go in assuming that discrimination is likely to be absent or weak, we are biased downward in our eventual estimate of 0.69; if we go in assuming good discrimination, we end up biased upwards to 0.78.</p>
<p>Fisherâ€™s original framework for significance testing focused only on the <strong>null hypothesis</strong> of no discrimination. In contrast, the Bayesian estimation method here focuses on the magnitude of accuracy.<sup>[IfÂ youâ€™reÂ readingÂ carefully,Â youÂ mightÂ haveÂ noticedÂ thatÂ weÂ <em>could</em>Â haveÂ discoveredÂ thatÂ theÂ estimateÂ ofÂ accuracyÂ wasÂ veryÂ similarÂ toÂ chanceÂ â€“Â moreÂ aboutÂ thisÂ below.][</sup>MM: I entirely agree with the spirit of this, but I worry about framing this as â€œFisherian NHST vs.Â Bayesian estimationâ€ when the issue really is â€œFisherian NHSTâ€ vs â€œany form of estimation with continuous inferenceâ€. We wouldnâ€™t want to inadvertently reinforce the misconception that Bayesian methods <em>inherently</em> alleviate the central issues with NHST, even though Bayesian methods of course have numerous important merits.] The intuition weâ€™d like you to get is that, if you are an experimentalist who cares about the magnitude of causal relationships (and we hope you are), then Fisherâ€™s statistical approach isnâ€™t ideally suited to your goals.[^MM: Yes, I like this framing in the final sentence much better.]</p>
<!-- TODO: HERE WOULD BE A GREAT PLACE FOR AN INTERACTIVE -->
</div>
<div id="measures-of-effect-size" class="section level2">
<h2><span class="header-section-number">4.6</span> Measures of effect size</h2>
<p>With all our talk about estimation above, we didnâ€™t say much about what precisely was being estimated. Often, researchers seek out some sort of common standardized way for describing the relationships they observe in the study.</p>
<p>For example, imagine that Mika and Nicholas are interested in examining whether a dog-petting intervention can reduce depression relative to a placebo. They use the same self-report depression measure, but Mika decides to make it a 10-point self-report scale (0 = â€œI feel blissfulâ€ to 10 = â€œI feel extremely depressedâ€), whereas Nicholas decides to make it a 100-point scale (1 = â€œI feel blissfulâ€ to 100 = â€œI feel extremely depressedâ€). Observing that the intervention led to a 1-point decrease in Mikaâ€™s scale is quite impressive. But observing a 1-point decrease in Nicholasâ€™ scale? Not so much!</p>
<p>To ensure that we have a common currency, many researchers describe their observations using standardized metrics. A common example of a such a metric is Cohenâ€™s <em>d</em>, which provides a standardized estimate of the difference between two means. There are many different ways to calculate Cohenâ€™s <em>d</em> (Lakens, 2013), but there usually some variant of the following formula:</p>
<p><span class="math display">\[d = \frac{M_1- M_2}{SD_1}\]</span></p>
<p>In the above example, <span class="math inline">\(M_1\)</span> could be the depression scores of patients who were assigned to pet dogs, whereas <span class="math inline">\(M_2\)</span> would be the scores of patients who were assigned to a placebo condition. <span class="math inline">\(SD_1\)</span> refers refers to standard deviation of the participants who were randomly assigned to pet dogs. Note: researchers usually seek to pool the standard deviations of <em>both</em> groups, but (for simplicity) we will assume that both groups have the same standard deviation (and thus <span class="math inline">\(SD_1 = SD_2 = SD_{pooled}\)</span>).</p>
<p>Because Mika and Nicholas used different scales, they will nature observe different amount of variability. For example, if all participants indicate that they are between 2-8 on a 10-point scale, this should translate to a range of 20-80 on a 100-point scale. Similarly, a standard deviation of 2 on Mikaâ€™s scale should correspond to a standard deviation of 20 on Nicholasâ€™ scale.</p>
<p>So letâ€™s compare their results, assuming that participants in the placebo groups have a mean depression score at the center of the scale (5 out of 10; 50 out of 100) and that both Mika and Nicholas observe a 1-point decrease is depression in the dog-petting group.</p>
<p><span class="math display">\[{d_{Mika}} = \frac{M_1- M_2}{SD_1} = \frac{5- 4}{2} = \frac{1}{2} = 0.5\]</span></p>
<p><span class="math display">\[{d_{Nicholas}} = \frac{M_1- M_2}{SD_1} = \frac{50- 49}{20} = \frac{1}{20} =  .05\]</span></p>
<p>When using Cohenâ€™s d, a value of .50 is often considered a strong effect, whereas a value of .05 would often be considered negligible (at least in the context of an intervention designed to improve depression).</p>
<p>Of course, there are many different standardized effect sizes that researchers can use. Although we described a common standardized effect size to describe differences in means, there are also standardized effect sizes for describing the amount of variance explained (e.g., Pearsonâ€™s <em>r</em>, R<sup>2</sup>, and <span class="math inline">\(\eta^2\)</span>) or relationships involving categorical variables (e.g., Odds Ratio). For a review, seeâ€¦ (Any recommendations?)</p>
<div id="pros-and-cons-of-standardization" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Pros and cons of standardization</h3>
<p>Pro: comparability across studies (e.g., school interventions to improve achievement?). Useful for meta-analysis (e.g., MA of facial feedback, which used a lot of different measures of emotion; infant consonant discrimination (cross method comparison)). Useful for a lot of power analysis software and packages (e.g., GPower and many packages in R).</p>
<p>Con: loss of information about measures and real-world predictions; dependence on baseline variability. Power analysis can only be done via annoying simulations. Not related to any real units. Often not very intuitive (have fun trying to explain what Cohenâ€™s <em>d</em> is to a very curious non-scientist. Fun fact: the Wikipedia article on effect sizes has been flagged as â€œtoo technical for most readers to understandâ€ since 2014!)</p>
<p>[STILL VERBATIM FROM MRM]
Standardized effect-size measures have limitations. For example, if two interventions produce the same absolute change in the same outcome measure, but are studied in different populations in which the variability on the outcome differs substantially, the interventions would produce different standardized mean differences.  When meta-analyzing studies that measure the outcome on the same scale (e.g., blood pressure in terms of mmHg), it may often be preferable to use raw mean differences. However, in many scientific fields, studies do not measure outcomes on exactly the same scale, as in both applied examples provided here; in such cases, using standardized mean differences may enable some approximate comparison and synthesis of effect sizes across studies. Additionally, when outcomes use arbitrary or unitless raw measures (e.g., points on a Likert scale), expressing effect sizes using standardized mean differences may provide some sense of effect sizes relative to variability in that sample, similar to measures of genetic heritability. </p>
<!-- ::: {.interactive} -->
<!-- âŒ¨ï¸ Interactive box: non-parametric simulations where you can shuffle data across groups a bunch of times and see what kind of distribution it produces by chance -->
<!-- ::: -->

</div>
</div>
</div>
<p style="text-align: center;">
<a href="3-ethics.html"><button class="btn btn-default">Previous</button></a>
<a href="5-inference.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="toc/toc.js"></script>


</body>
</html>
