<!DOCTYPE html>
<html lang xmlLang><head><link rel="stylesheet" type="text/css" href="/assets/static/index.page.client.425ab545.css"><link rel="preload" href="/assets/static/SourceSansPro-Regular.71d10a86.ttf" as="font" type="font/ttf" crossorigin><meta charSet="utf-8"/><meta name="generator" content="pandoc"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta property="og:title" content="Chapter 2 Theories | Experimentology"/><meta property="og:type" content="book"/><meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams"/><script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><meta name="description" content="Chapter 2 Theories | Experimentology"/><title>Chapter 2 Theories | Experimentology</title><link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet"/><link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet"/><link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet"/><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet"/><style type="text/css">code{white-space: pre;}</style><style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style><style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style></head><body>



<div class="row">
<div class="col-sm-12">
<div island></div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="theories" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Theories</h1>
<div island></div>
<p>When you do an experiment, sometimes you just want to see what happens, like a kid knocking down a tower made of blocks. And sometimes you want to know the answer to a specific applied question, like “will giving a midterm vs. weekly quizzes lead students in a class to perform better on the final?” But more often, our goal is to create <strong>theories</strong> that help us explain and predict new observations.</p>
<p>What is a theory? We’ll argue here that we should think of psychological theories as sets of proposed relationships among <strong>constructs</strong>, which are variables that we think play causal roles in determining behavior. In this conception of theories, the role of causality is central: theories are guesses about the causal structure of the mind and about the causal relationships between the mind and the world. This definition doesn’t include everything that gets called a “theory” in psychology. We describe the continuum between theories and <strong>frameworks</strong> – broad sets of ideas that guide research but don’t make specific contact with particular empirical observations.</p>
<p>We begin this chapter by talking about the specific enterprise of constructing psychological theories. We’ll then discuss how theories make contact with data, reviewing a bit of the philosophy of science, and give some guidance on how to construct experiments that test theories. We end by discussing the relationship between theories and quantitative models.</p>
<div id="what-is-a-psychological-theory" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> What is a psychological theory?</h2>
<p>The definition we just gave for a psychological theory is that it is a proposed set of causal relationships among constructs that helps us explain behavior. Let’s look at the ingredients of a theory: the constructs and the relationships between them. Then we can ask about how this definition relates to other things that get called “theories” in psychology.</p>
<div id="psychological-constructs" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Psychological constructs</h3>
<p>Constructs are the psychological variables that we want our theory to describe, like “money” and “happiness” in the example from last chapter. At first glance, it might seem odd that we need a specific name for these variables. But in probing the relationship between money and happiness, we will have to figure out a way to measure happiness. Let’s say we just ask people to answer the question “how happy are you?” by giving ratings on a 1 (miserable) to 10 (elated) scale.</p>
<p>Now say someone in the study reports they are an 8 on this scale. Is this <em>really</em> how happy they are? What if they weren’t concentrating very hard on the rating, or if they thought the researcher wanted them to be happy? What if they act much less happy in their interactions with family and friends?</p>
<p>We resolve this dilemma by saying that the self-report ratings we collect are only a <strong>measure</strong> of a <strong>latent</strong> construct, happiness. The construct is latent because we can never see it directly, but we think it has a causal influence on the measure: happier people should, on average, provide higher ratings. But many other factors can lead to noise or bias in the measurement, so we shouldn’t mistake those ratings as actually <em>being</em> the construct.</p>
<p>The particular question “how happy are you?” is one way of going from the general construct to a specific measure. The general process of going from construct to a specific instantiation that can be measured or manipulated is called <strong>operationalization</strong>. Happiness can be operationalized by self-report, but it can also be operationalized many other ways, for example through a measure like the use of positive language in a personal essay, or by ratings by friends, family, or a clinician. These decisions about how to operationalize a construct with a particular measure are tricky and consequential, and we discuss them extensively in Chapter <a href="8-measurement.html#measurement">8</a>. Each different operationalization might be appropriate for a specific study, yet it would require some justification and argument to connect each one to the others.</p>
<p>Proposing a particular construct is a very important part of making a theory. For example, a researcher might worry that self-reported happiness is very different than someone’s well-being as observed by the people around them, and assert that happiness is not a single construct but rather a group of distinct constructs. This researcher would then be surprised to know that self-reports of happiness relate very highly to others’ perceptions of a person’s well-being <span class="citation">(<a href="#ref-sandvik1993" role="doc-biblioref">Sandvik, Diener, and Seidlitz 1993</a>)</span>.<label for="tufte-sn-14" class="margin-toggle sidenote-number">14</label><input type="checkbox" id="tufte-sn-14" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">14</span> Sometimes positing the construct <em>is</em> the key part of a theory. <em>g</em> (general intelligence) is the classic psychological example of a single-construct theory. The idea behind <em>g</em> theory is that the best measure of general intelligence is the shared variance between a wide variety of different tests. The decision to theorize about and measure a single unified construct for intelligence – rather than say, many different separate kinds of intelligence – is itself a controversial move.</span></p>
<p>Even external, apparently non-psychological variables like money don’t have direct effects on people, but rather operate through psychological constructs. People studying money seriously as a part of psychological theories think about perceptions of money in different ways depending on the context. For example, researchers have written about the importance of how much money you have on hand based on when in the month your paycheck arrives <span class="citation">(<a href="#ref-ellwood-lowe2022" role="doc-biblioref">Ellwood-Lowe, Foushee, and Srinivasan 2022</a>)</span>, but have also considered perceptions of long-term accumulation of wealth as a way of conceptualizing people’s understanding of the different resources available to White and Black families <span class="citation">(<a href="#ref-kraus2019" role="doc-biblioref">Kraus et al. 2019</a>)</span>.</p>
<p>Finally, a construct can be operationalized through a manipulation: in our money-happiness example, we operationalized “more money” in our theory with a gift of a specific amount of cash. We hope you see through these examples that operationalization is a huge part of the craft of being a psychology researcher – taking a set of abstract constructs that you’re interested in and turning them into a specific experiment with a manipulation and a measure that tests your causal theory. We’ll have a lot more to say about how this is done in Chapter <a href="9-design.html#design">9</a>.</p>
</div>
<div id="the-relationships-between-constructs" class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> The relationships between constructs</h3>
<p>Constructs gain their meaning in part via their own definitions and operationalizations, but also in part through their causal relationships to other constructs. Figure <a href="2-theories.html#fig:theory-nomological-net">2.1</a> shows a schematic of what this kind of theory might look like – as you can see, it looks a lot like the DAGs that we introduced in the last chapter! That’s no accident. The arrows here also describe hypothesized causal links.<label for="tufte-sn-15" class="margin-toggle sidenote-number">15</label><input type="checkbox" id="tufte-sn-15" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">15</span> Sometimes these kind of diagrams are used in the context of a statistical method called Structural Equation Modeling, where circles represent constructs and lines represent their relationships with one another. Confusingly, structural equation models are also used by many researchers to describe psychological theories. The important point for now is that they are one particular statistical formalism, not a general tool for theory building – the points we are trying to make here are more general.</span></p>
<div class="figure"><span style="display:block;" id="fig:theory-nomological-net"></span>
<p class="caption marginnote shownote">
Figure 2.1: A schematic of what a theory might look like.
</p>
<img src="images/theory/nomological-net.png" alt="A schematic of what a theory might look like." width="\linewidth"/>
</div>
<p>This web of constructs and assumptions is what <span class="citation">Cronbach and Meehl (<a href="#ref-cronbach1955" role="doc-biblioref">1955</a>)</span> referred to as a “nomological network” – a set of proposals about how different entities are connected to one another. The tricky part is that the key constructs are never observed directly. They are in people’s heads.<label for="tufte-sn-16" class="margin-toggle sidenote-number">16</label><input type="checkbox" id="tufte-sn-16" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">16</span> We’re not saying these should correspond to specific brain structures. They could, but most likely they won’t. The idea that psychological constructs are not the same as any particular brain state (and especially not any particular brain region) is called “multiple realizability” by philosophers, who mostly agree that psychological states can’t be reduced to brain states, as much as philosophers agree on anything <span class="citation">(<a href="#ref-block1972" role="doc-biblioref">Block and Fodor 1972</a> et seq.)</span>.</span> So researchers only get to probe them by measuring them through specific operationalizations.</p>
<p>One poetic way of thinking about this idea is that the theoretical system of constructs “floats… above the plane of observation and is anchored to it by the rules of <a href="8-measurement.html#measurement">measurement</a>.” <span class="citation">(<a href="#ref-hempel1952" role="doc-biblioref">Hempel 1952</a>)</span>. So, even if your theory posits that two constructs (say, money and happiness) are directly related, the best you can do is manipulate one operationalization and measure another operationalization. If this manipulation doesn’t produce any effect, it’s possible that you are wrong and money does not cause happiness – but it is also possible that your operationalizations are poor.</p>
<p>Here’s a slightly different way of thinking about a theory. A theory provides a <strong>compression</strong> of potentially complex data into much a smaller set of general factors. If you have a long sequence of numbers, say [2 4 8 16 32 64 128 256 …], then the expression <span class="math inline">\(2^n\)</span> serves as a compression of this sequence – it’s a short expression that tells you what numbers are in vs. out of the sequence. In the same way, a theory can compress a large set of observations (maybe data from many experiments) into a small set of relationships between constructs. Now, if your data are noisy, say [2.2 3.9 8.1 16.1 31.7 … ], then the theory will not be a perfect representation of the data. But it will still be useful.</p>
<p>In particular, having a theory allows you to <strong>explain</strong> observed data and <strong>predict</strong> new data. Both of these are good things for a theory to do. For example, if it turned out that the money causes happiness theory was true, we could use it to explain observations such as greater levels of happiness among wealthy people. We could also make predictions about the effects of policies like giving out a universal basic income on overall happiness.<label for="tufte-sn-17" class="margin-toggle sidenote-number">17</label><input type="checkbox" id="tufte-sn-17" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">17</span> The relationship between money and happiness is actually much more complicated than what we’re assuming here. For example, <span class="citation">Killingsworth, Kahneman, and Mellers (<a href="#ref-killingsworth2023" role="doc-biblioref">2023</a>)</span> describes a collaboration between two sets of researchers that had different viewpoints on the connection between money and happiness.</span></p>
<p>Explanation is an important feature of good theories, but it’s also easy to trick yourself by using a vague theory to explain a finding <strong>post-hoc</strong> (after the fact). Thus, the best test of a theory is typically a new prediction, as we discuss below.</p>
</div>
<div id="specific-theories-vs.-general-frameworks" class="section level3" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Specific theories vs. general frameworks</h3>
<p>You may be thinking, “psychology is full of theories but they don’t look that much like the ones you’re talking about!” Very few of the theories that bear that label in psychology describe causal relationships linking clearly defined and operationalized constructs. You also don’t see that many DAGs, though these are getting (slightly) more common lately <span class="citation">(<a href="#ref-rohrer2018" role="doc-biblioref">J. M. Rohrer 2018</a>)</span>.</p>
<p>Here’s an example of something that gets called a theory yet doesn’t share the components described above. <span class="citation">Bronfenbrenner (<a href="#ref-bronfenbrenner1992" role="doc-biblioref">1992</a>)</span>’s Ecological Systems Theory (EST) is pictured in Figure <a href="2-theories.html#fig:theory-bronfenbrenner">2.2</a>. The key thesis of this theory is that children’s development occurs in a set of nested contexts that each affect one another and in turn affect the child. This theory has been immensely influential. Yet if it’s read as a causal theory, it’s almost meaningless: nearly everything connects to everything in both directions and the constructs are not operationalized – it’s very hard to figure out what kind of predictions it makes!</p>
<p>
<span class="marginnote shownote">
<span style="display:block;" id="fig:theory-bronfenbrenner"></span>
<img src="images/theory/bronfenbrenner2.png" alt="The diagram often used to represent Bronfenbrenner's ecological systems theory. Note that circles no longer denote discrete constructs; arrows can be interpreted as causal relationships, but all constructs are assumed to be fully connected." width="\linewidth"/>
Figure 2.2: The diagram often used to represent Bronfenbrenner’s ecological systems theory. Note that circles no longer denote discrete constructs; arrows can be interpreted as causal relationships, but all constructs are assumed to be fully connected.
</span>
</p>
<p>EST is not really a theory in the sense that we are advocating for in this chapter (and the same goes for many other very interesting ideas in psychology). It’s not a set of causal relationships between constructs that allow specific predictions about future observations. EST is instead a broad set of ideas about what sorts of theories are more likely to explain specific phenomena. For example, it helps remind us that a child’s behavior is likely to be influenced by a huge range of factors, such that any individual theory cannot just focus on an individual factor and hope to provide a full explanation. In this sense, EST is a <strong>framework</strong>: it guides and inspires specific theories – in the sense we’ve discussed here, namely a set of causal relationships between constructs – without being a theory itself.</p>
<p>Frameworks are often incredibly important. Ideas like EST have inspired huge amounts of interesting research. They can also make a big difference to practice. For example, EST supports a model in social work in which children’s needs are considered not only as the expression of specific internal developmental issues but also as stemming from a set of overlapping contextual factors <span class="citation">(<a href="#ref-ungar2002" role="doc-biblioref">Ungar 2002</a>)</span>. Concretely, a therapist might be more likely to examine family, peer, and school environments when analyzing a child’s situation through the lens of EST.</p>
<p>There’s a continuum between precisely specified theories and broad frameworks. Some theories propose interconnected constructs but don’t specify the relationships between them, or don’t specify how those constructs should be operationalized. So when you read a paper that says it proposes a “theory,” it’s a good idea to to ask whether it describes specific relations between operationalized constructs. If it doesn’t that, it may be more of a framework than a theory.</p>
<div island></div>
</div>
</div>
<div id="how-do-we-test-theories" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> How do we test theories?</h2>
<p>Our view of psychological theories is that they describe a set of relationships between different constructs. How can we test theories and decide which one is best? We’ll first describe <strong>falsificationism</strong>, a historical viewpoint on this issue that has been very influential in the past and that connects to ideas about statistical inference presented in Chapter <a href="6-inference.html#inference">6</a>. We’ll then turn to a more modern viewpoint, <strong>holism</strong>, that recognizes the interconnections between theory and measurement.</p>
<div id="falsificationism" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Falsificationism</h3>
<p>One historical view that resonates with many scientists is the philosopher Karl Popper’s falsificationism. For Popper, a scientific theory is a set of hypotheses about the world that instantiate claims like the connection between money and happiness.<label for="tufte-sn-18" class="margin-toggle sidenote-number">18</label><input type="checkbox" id="tufte-sn-18" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">18</span> Earlier we treated the claim that money caused happiness as a theory. It is one! It’s just a very simple theory that has only one hypothesized connection in it.</span> What makes a statement a <em>scientific</em> hypothesis is that it can be disproved (i.e., it is <strong>falsifiable</strong>) by an observation that contradicts it. For example, observing a lottery winner who immediately becomes depressed would falsify the hypothesis that receiving money makes you happier.</p>
<p>On Popper’s view, theories are never <strong>confirmed</strong>. The hypotheses that made up his theories were universal statements. You could never prove them right; you could only fail to find falsifying evidence. Seeing hundreds of people get happier when they received money would not prove that the money-happiness hypothesis was universally true. There could always be a counter-example around the corner.</p>
<p>Popper’s theory doesn’t really describe how scientists work. For example, scientists like to say that their evidence “supports” or “confirms” their theory, and Popper’s falsificationism rejects this kind of talk. A falsificationist says that confirmation is an illusion; that the theory is simply surviving to be tested another day. This strict falsificationist perspective is unpalatable to many scientists. After all, if we observe that hundreds of people get happier when they receive money, it seems like this should at least slightly increase our confidence that money causes happiness!<label for="tufte-sn-19" class="margin-toggle sidenote-number">19</label><input type="checkbox" id="tufte-sn-19" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">19</span> An alternative perspective comes from the Bayesian tradition that we’ll learn more about in Chapters <a href="5-estimation.html#estimation">5</a> and <a href="6-inference.html#inference">6</a>. In a nutshell, Bayesians propose that our subjective belief in a particular hypothesis can be captured by a probability, and that our scientific reasoning can then be described by a process of normative probabilistic reasoning <span class="citation">(<a href="#ref-strevens2006" role="doc-biblioref">Strevens 2006</a>)</span>. The Bayesian scientist distributes probability across a wide range of alternative hypotheses; observations that are more consistent with a hypothesis increase the hypothesis’s probability <span class="citation">(<a href="#ref-sprenger2019" role="doc-biblioref">Sprenger and Hartmann 2019</a>)</span>.</span></p>
</div>
<div id="a-holistic-viewpoint-on-theory-testing" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> A holistic viewpoint on theory testing</h3>
<p>The key issue that leads us to reject strict falsificationism is the observation that no individual hypothesis (a part of a theory) can be falsified independently. Instead, a large series of what are called <strong>auxiliary assumptions</strong> (or auxilliary hypotheses) are usually necessary to link an observation to a theory <span class="citation">(<a href="#ref-lakatos1976" role="doc-biblioref">Lakatos 1976</a>)</span>. For example, if giving some individual person money didn’t change their happiness, we wouldn’t immediately throw out our theory that money causes happiness. Instead, the fault might be in any one of our auxiliary assumptions, like our measurement of happiness, or our choice of how much money to give or when to give it. The idea that individual parts of a theory can’t be falsified independently is sometimes called <strong>holism</strong>.</p>
<p>One consequence of holism is that the relationship between data and theory isn’t always straightforward. An unexpected observation may not cause us to give up on a main hypothesis in our theory – but it will often cause us to question our auxiliary assumptions instead (e.g., how we operationalize our constructs). Thus, before abandoning our theory of money causing happiness, we might want to try several happiness questionnaires!</p>
<p>The broader idea of holism is supported by historical and sociological studies of how science progresses, especially in the work of <span class="citation">Kuhn (<a href="#ref-kuhn1962" role="doc-biblioref">1962</a>)</span>. Examining historical evidence, Kuhn found that scientific revolutions didn’t seem to be caused by the falsification of a theoretical statement via an incontrovertible observation. Instead, Kuhn described scientists as mostly working within <strong>paradigms</strong>: sets of questions, assumptions, methods, phenomena, and explanatory hypotheses.</p>
<p>Paradigms allow for activities Kuhn described as <strong>normal science</strong> – that is, testing questions within the paradigm, explaining new observations or modifying theory to fit these paradigms. But normal science is punctuated by periods of <strong>crisis</strong> when scientists begin to question their theory and their methods. Crises don’t happen just because a single observation is inconsistent with the current theory. Rather, there will often be a holistic transition to a new paradigm, typically because of a striking explanatory or predictive success – often one that’s outside the scope of the current working theory entirely.</p>


<p>In sum, the lesson of holism is that we can’t just put our theories in direct contact with evidence and think that they will be supported or overturned. Instead, we need to think about the scope of our theory (in terms of the phenomena and measures it is meant explain), as well as the auxiliary hypotheses – operationalizations – that link it to specific observations.</p>
</div>
</div>
<div id="designing-experiments-to-test-theory" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Designing experiments to test theory</h2>
<p>One way of looking at theories is that they let us make <em>bets</em>. If we bet on a spin of the roulette wheel in Figure <a href="2-theories.html#fig:theory-roulette">2.3</a> that it will show us red as opposed to black, we have almost a 50% chance of winning the bet. Winning such a bet is not impressive. But if we call a particular number, the bet is riskier because we have a much smaller chance of being right. Cases where a theory has many chances to be wrong are called <strong>risky tests</strong> <span class="citation">(<a href="#ref-meehl1978" role="doc-biblioref">Meehl 1978</a>)</span>.<label for="tufte-sn-20" class="margin-toggle sidenote-number">20</label><input type="checkbox" id="tufte-sn-20" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">20</span> Even if you’re not a <em>falsificationist</em> like Popper, you can still think it’s useful to try and falsify theories! Although a single observation is not always enough to overturn a theory, it’s still a great research strategy to look for those observations that are most inconsistent with the theory.</span></p>
<p>
<span class="marginnote shownote">
<span style="display:block;" id="fig:theory-roulette"></span>
<img src="images/theory/roulette2.png" alt="A roulette wheel. Betting on red is not that risky, but betting all your chips on a particular value (*) is much riskier." width="\linewidth"/>
Figure 2.3: A roulette wheel. Betting on red is not that risky, but betting all your chips on a particular value (*) is much riskier.
</span>
</p>
<p>Much psychology consists of verbal theories. Verbal theories make only qualitative predictions, so it is hard convincingly show them to be wrong <span class="citation">(<a href="#ref-meehl1990" role="doc-biblioref">Meehl 1990</a>)</span>. In our discussion of money and happiness, we just expected happiness to go up as money increased. We would have accepted <em>any</em> increase in happiness (even if very small) as evidence confirming our hypothesis. Predicting that it does is a bit like betting on red with the roulette wheel – it’s not surprising or impressive when you win. And in psychology, verbal theories often predict that multiple factors interact with one another. With these theories, it’s easy to say that one or the other was “dominant” in a particular situation, meaning you can predict almost any direction of effect.</p>
<p>To test theories, we should design experiments to test conditions where our theories make “risky” predictions. A stronger version of the money-happiness theory might suggest that happiness increases linearly in the logarithm of income <span class="citation">(<a href="#ref-killingsworth2023" role="doc-biblioref">Killingsworth, Kahneman, and Mellers 2023</a>)</span>. This specific mathematical form for the relationship – as well as the more specific operationalization of money as income – creates opportunities for making much riskier bets about new experiments. This kind of case is more akin to betting on a specific number on the roulette wheel: when you win this bet, it is quite surprising!<label for="tufte-sn-21" class="margin-toggle sidenote-number">21</label><input type="checkbox" id="tufte-sn-21" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">21</span> Theories are often developed iteratively. It’s common to start with a theory that is less precise and hence, that has fewer opportunities for risky tests. But by collecting data and testing different alternatives, it’s often possible to refine the theory so that it is more specific and allows riskier tests. As we discuss below, formalizing theories using mathematical or computational models is one important route to making more specific predictions and creating riskier tests.</span></p>
<p>Testing theoretical predictions also requires precise experimental measurements. As we start to measure the precision of our experimental estimates in Chapter <a href="6-inference.html#inference">6</a>, we’ll see that the more precise our estimate is, the more values are inconsistent with it. In this sense, a risky test of a theory requires both a very specific prediction and a precise measurement. (Imagine spinning the roulette wheel but seeing such a blurry image of the result that you can’t really tell where the ball is. Not very useful.)</p>
<p>Even when theories make precise predictions, they can still be too flexible to be tested. When a theory has many <strong>free parameters</strong> – numerical values that can be fit to a particular dataset, changing the theories predictions on a case-by-case basis – then it can often predict a wide range of possible results. This kind of flexibility reduces the value of any particular experimental test, because the theorist can always say after the fact that the parameters were wrong but not the theory itself <span class="citation">(<a href="#ref-roberts2000" role="doc-biblioref">Roberts and Pashler 2000</a>)</span>.</p>
<p>One important way to remove this kind of flexibility is to make predictions in advance, holding all parameters constant. A preregistration is a great way to do this – the experimenter derives predictions and specifies in advance how they will be compared to the results of the experiment. We’ll talk much more about the process of preregistration in Chapter <a href="11-prereg.html#prereg">11</a>.</p>
<p>Finally, we’ve been focusing mostly on testing a single theory. But the best state of affairs is if a theory can make a very specific prediction that other theories don’t make. If competing theories both predict that money increases happiness to the same extent, then data consistent with that predicted relationship don’t differentiate between the theories, no matter how specific the prediction might be. The experiment that teaches us the most is going to be the one where a very specific pattern of data is predicted according to one theory and another.<label for="tufte-sn-22" class="margin-toggle sidenote-number">22</label><input type="checkbox" id="tufte-sn-22" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">22</span> We can use this idea, which comes from Bayesian statistics, to try to figure out what the <em>right</em> experiment is by considering which specific experimental conditions derive differences between theories. In fact, the idea of choosing experiments based on the predictions that different theories make has a long history in statistics <span class="citation">(<a href="#ref-lindley1956" role="doc-biblioref">Lindley 1956</a>)</span>; it’s now called <strong>optimal experiment design</strong> <span class="citation">(<a href="#ref-myung2013" role="doc-biblioref">Myung, Cavagnaro, and Pitt 2013</a>; <a href="#ref-ouyang2018" role="doc-biblioref">Ouyang et al. 2018</a>)</span>. The idea is, if you have two or more theories spelled out mathematically or computationally, you can simulate their predictions across a lot of conditions and pick the most informative conditions to run as an actual experiment.</span></p>
</div>
<div id="formalizing-theories" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Formalizing theories</h2>
<p>Say we have a set of constructs we want to theorize about. How do we describe our ideas about the relationships between them so that we can make precise predictions that can be compared with other theories? As one writer noted, mathematics is “unreasonably effective” as a vocabulary for the sciences <span class="citation">(<a href="#ref-wigner1990" role="doc-biblioref">Wigner 1990</a>)</span>. Indeed, there have been calls for greater formalization of theory in psychology for at least the last 50 years <span class="citation">(<a href="#ref-harris1976" role="doc-biblioref">Harris 1976</a>)</span>.</p>

<div island></div>
<p>There is no one approach that will be right for theorizing across all areas of psychology <span class="citation">(<a href="#ref-oberauer2019" role="doc-biblioref">Oberauer and Lewandowsky 2019</a>; <a href="#ref-smaldino2020" role="doc-biblioref">Smaldino 2020</a>)</span>. Mathematical theories like <span class="citation">Shepard (<a href="#ref-shepard1987" role="doc-biblioref">1987</a>)</span> (see Depth box) have long been one tool that allows for precise statements of particular relationships.</p>
<p>Computational or formal artifacts are not themselves psychological theories, but they can be used to create psychological theories via the mapping of constructs onto entities in the model and the use of the principles of the formalism to instantiate psychological hypotheses or assumptions <span class="citation">(<a href="#ref-guest2021" role="doc-biblioref">Guest and Martin 2021</a>)</span>.<label for="tufte-sn-23" class="margin-toggle sidenote-number">23</label><input type="checkbox" id="tufte-sn-23" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">23</span> This book won’t go into more details about routes to building computational theories, but if you are interested, we encourage you to explore these frameworks as a way to deepen your theoretical contributions and to sharpen your experimental choices.</span> Yet stating such clear and general laws feels out of reach in many cases. If we had more Shepard-style theorists or theories, perhaps we’d be in a better place. Or perhaps such “universal laws” are simply out of reach for most of human behavior.</p>
<p>An alternative approach creates statistical models of data that incorporate substantive assumptions about the structure of the data. We use such models all the time for data analysis. The trouble is, we often don’t interpret them as having substantive assumptions about the structure of the data, even when they do <span class="citation">(<a href="#ref-fried2020" role="doc-biblioref">Fried 2020</a>)</span>! But if we examine these assumptions explicitly, even the simplest statistical models can be productive tools for building theories.</p>
<p>For example, if we set up a simple linear regression model to estimate the relationship between money and happiness, we’d be positing a linear relationship between the two variables – that an increase in one would always lead to a proportional increase in the other.<label for="tufte-sn-24" class="margin-toggle sidenote-number">24</label><input type="checkbox" id="tufte-sn-24" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">24</span> Linear models are ubiquitous in the social sciences because they are convenient to fit, but as theoretical models they are deeply impoverished. There is a lot you can do with a linear regression, but in the end, most interesting processes are not linear combinations of factors!</span> If we fit the model to a particular dataset, we could then look at the weights of the model. Our theory might then then be something like “giving people $100 causes .2 points of increase in happiness on a self-report scale.”</p>
<p>Obviously, this regression model is not a very good theory of the broader relationship between money and happiness, since it posits that everyone’s happiness would be at the maximum on the 10 point scale if you gave them (at most) $4500. It also doesn’t tell us how this theory would generalize to other people, other measures of happiness, or other aspects of the psychological representation of money such as income or wealth.</p>
<p>From our viewpoint, these sorts of questions are not distractions – they are the critical work of moving from experiment to theory <span class="citation">(<a href="#ref-smaldino2020" role="doc-biblioref">Smaldino 2020</a>)</span>! In Chapter <a href="7-models.html#models">7</a>, we try to draw out this idea further, reconstruing common statistical tests as models that can be repurposed to express contentful scientific hypotheses while recognizing the limitations of their assumptions.</p>
<p>One of the strengths of modern cognitive science is that it provides a very rich set of tools for expressing more complex statistical models and linking them to data. For example, the modern Bayesian cognitive modeling tradition grew out of work like Shepard’s; in these models, a system of equations defines a probability distribution that can be used to estimate parameters, predict new data, or make other inferences <span class="citation">(<a href="#ref-probmods2" role="doc-biblioref">N. D. Goodman, Tenenbaum, and Contributors 2016</a>)</span>. And neural network models – which are now fueling innovations in artificial intelligence – have a long history of being used as substantive models of human psychology <span class="citation">(<a href="#ref-elman1996" role="doc-biblioref">Elman, Bates, and Johnson 1996</a>)</span>.</p>
<p>In our discussion, we’ve presented theories as static entities that are presented, tested, confirmed, and falsified. That’s a simplification that doesn’t take into account the ways that theories – especially when instantiated as formal models – can be flexibly adjusted to accommodate new data <span class="citation">(<a href="#ref-navarro2019" role="doc-biblioref">Navarro 2019</a>)</span>. Most modern computational theories are more like a combination of core principles, auxiliary assumptions, and supporting empirical assumptions. The best theories are always being enlarged and refined in response to new data.<label for="tufte-sn-25" class="margin-toggle sidenote-number">25</label><input type="checkbox" id="tufte-sn-25" class="margin-toggle"/><span class="sidenote"><span class="sidenote-number">25</span> In the thinking of the philosopher Imre Lakatos, a “productive” research program is one where the core principles are gradually supplemented with a limited set of additional assumptions to explain a growing base of observations. In contrast, a “degenerate” research program is one in which you are constantly making ad-hoc tweaks to the theory to explain each new datapoint <span class="citation">(<a href="#ref-lakatos1976" role="doc-biblioref">Lakatos 1976</a>)</span>.</span></p>
</div>
<div id="chapter-summary-theories" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Chapter summary: Theories</h2>
<p>In this chapter, we characterized psychological theories as a set of causal relationships between latent constructs. The role of experiments is to measure these causal relationships and to adjudicate between theories by identifying cases where different theories make different predictions about particular relationships.</p>
<div island></div>
<div island></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-block1972" class="csl-entry">
Block, Ned J, and Jerry A Fodor. 1972. <span>“What Psychological States Are Not.”</span> <em>The Philosophical Review</em> 81 (2): 159–81.
</div>
<div id="ref-bronfenbrenner1992" class="csl-entry">
Bronfenbrenner, Urie. 1992. <em>Ecological Systems Theory.</em> Jessica Kingsley Publishers.
</div>
<div id="ref-clarke1884" class="csl-entry">
Clarke, Edward H. 1884. <em>Sex in Education: Or, a Fair Chance for the Girl</em>. Boston: Houghton, Mifflin; Company.
</div>
<div id="ref-cronbach1955" class="csl-entry">
Cronbach, L J, and P E Meehl. 1955. <span>“Construct Validity in Psychological Tests.”</span> <em>Psychol. Bull.</em> 52 (4): 281–302.
</div>
<div id="ref-ellwood-lowe2022" class="csl-entry">
Ellwood-Lowe, Monica E, Ruthe Foushee, and Mahesh Srinivasan. 2022. <span>“What Causes the Word Gap? Financial Concerns May Systematically Suppress Child-Directed Speech.”</span> <em>Developmental Science</em> 25 (1): e13151.
</div>
<div id="ref-elman1996" class="csl-entry">
Elman, Jeffrey L, Elizabeth A Bates, and Mark H Johnson. 1996. <em>Rethinking Innateness: A Connectionist Perspective on Development</em>. Vol. 10. MIT press.
</div>
<div id="ref-fried2020" class="csl-entry">
Fried, Eiko I. 2020. <span>“Lack of Theory Building and Testing Impedes Progress in the Factor and Network Literature.”</span> <em>Psychological Inquiry</em> 31 (4): 271–88.
</div>
<div id="ref-probmods2" class="csl-entry">
Goodman, Noah D, Joshua B. Tenenbaum, and The ProbMods Contributors. 2016. <span>“<span class="nocase">Probabilistic Models of Cognition</span>.”</span> <a href="https://probmods.org/" class="uri">https://probmods.org/</a>.
</div>
<div id="ref-guest2021" class="csl-entry">
Guest, Olivia, and Andrea E Martin. 2021. <span>“How Computational Modeling Can Force Theory Building in Psychological Science.”</span> <em>Perspectives on Psychological Science</em> 16 (4): 789–802.
</div>
<div id="ref-harris1976" class="csl-entry">
Harris, Richard J. 1976. <span>“The Uncertain Connection Between Verbal Theories and Research Hypotheses in Social Psychology.”</span> <em>Journal of Experimental Social Psychology</em> 12 (2): 210–19.
</div>
<div id="ref-hempel1952" class="csl-entry">
Hempel, Carl G. 1952. <span>“Fundamentals of Concept Formation in Empirical Science, Vol. Ii. No. 7.”</span>
</div>
<div id="ref-killingsworth2023" class="csl-entry">
Killingsworth, Matthew A, Daniel Kahneman, and Barbara Mellers. 2023. <span>“Income and Emotional Well-Being: A Conflict Resolved.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (10): e2208661120.
</div>
<div id="ref-kraus2019" class="csl-entry">
Kraus, Michael W, Ivuoma N Onyeador, Natalie M Daumeyer, Julian M Rucker, and Jennifer A Richeson. 2019. <span>“The Misperception of Racial Economic Inequality.”</span> <em>Perspectives on Psychological Science</em> 14 (6): 899–921.
</div>
<div id="ref-kuhn1962" class="csl-entry">
Kuhn, Thomas. 1962. <em>The Structure of Scientific Revolutions</em>. Princeton University Press.
</div>
<div id="ref-lakatos1976" class="csl-entry">
Lakatos, Imre. 1976. <span>“Falsification and the Methodology of Scientific Research Programmes.”</span> In <em>Can Theories Be Refuted?</em>, 205–59. Springer.
</div>
<div id="ref-lindley1956" class="csl-entry">
Lindley, Dennis V. 1956. <span>“On a Measure of the Information Provided by an Experiment.”</span> <em>The Annals of Mathematical Statistics</em>, 986–1005.
</div>
<div id="ref-meehl1978" class="csl-entry">
Meehl, Paul E. 1978. <span>“Theoretical Risks and Tabular Asterisks: Sir Karl, Sir Ronald, and the Slow Progress of Soft Psychology.”</span> <em>J. Consult. Clin. Psychol.</em> 46 (4): 806–34.
</div>
<div id="ref-meehl1990" class="csl-entry">
———. 1990. <span>“Why Summaries of Research on Psychological Theories Are Often Uninterpretable.”</span> <em>Psychological Reports</em> 66 (1): 195–244.
</div>
<div id="ref-myung2013" class="csl-entry">
Myung, Jay I, Daniel R Cavagnaro, and Mark A Pitt. 2013. <span>“A Tutorial on Adaptive Design Optimization.”</span> <em>Journal of Mathematical Psychology</em> 57 (3-4): 53–67.
</div>
<div id="ref-navarro2019" class="csl-entry">
Navarro, Danielle J. 2019. <span>“Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection.”</span> <em>Computational Brain &amp; Behavior</em> 2 (1): 28–34.
</div>
<div id="ref-oberauer2019" class="csl-entry">
Oberauer, Klaus, and Stephan Lewandowsky. 2019. <span>“Addressing the Theory Crisis in Psychology.”</span> <em>Psychonomic Bulletin &amp; Review</em> 26 (5): 1596–1618.
</div>
<div id="ref-ouyang2018" class="csl-entry">
Ouyang, Long, Michael Henry Tessler, Daniel Ly, and Noah D Goodman. 2018. <span>“Webppl-Oed: A Practical Optimal Experiment Design System.”</span> In <em>CogSci</em>.
</div>
<div id="ref-roberts2000" class="csl-entry">
Roberts, Seth, and Harold Pashler. 2000. <span>“How Persuasive Is a Good Fit? A Comment on Theory Testing.”</span> <em>Psychological Review</em> 107 (2): 358.
</div>
<div id="ref-rohrer2018" class="csl-entry">
Rohrer, Julia M. 2018. <span>“Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 1 (1): 27–42.
</div>
<div id="ref-sandvik1993" class="csl-entry">
Sandvik, Ed, Ed Diener, and Larry Seidlitz. 1993. <span>“Subjective Well-Being: The Convergence and Stability of Self-Report and Non-Self-Report Measures.”</span> <em>Journal of Personality</em> 61 (3): 317–42.
</div>
<div id="ref-shepard1987" class="csl-entry">
Shepard, Roger N. 1987. <span>“Toward a Universal Law of Generalization for Psychological Science.”</span> <em>Science</em> 237 (4820): 1317–23.
</div>
<div id="ref-smaldino2020" class="csl-entry">
Smaldino, Paul E. 2020. <span>“How to Translate a Verbal Theory into a Formal Model.”</span> <em>Social Psychology</em>.
</div>
<div id="ref-sprenger2019" class="csl-entry">
Sprenger, Jan, and Stephan Hartmann. 2019. <em>Bayesian Philosophy of Science</em>. Oxford University Press.
</div>
<div id="ref-strevens2006" class="csl-entry">
Strevens, Michael. 2006. <span>“The Bayesian Approach to the Philosophy of Science.”</span>
</div>
<div id="ref-tenenbaum2000" class="csl-entry">
Tenenbaum, Joshua B. 2000. <span>“Rules and Similarity in Concept Learning.”</span> <em>Advances in Neural Information Processing Systems</em> 12: 59–65.
</div>
<div id="ref-ungar2002" class="csl-entry">
Ungar, Michael. 2002. <span>“A Deeper, More Social Ecological Social Work Practice.”</span> <em>Social Service Review</em> 76 (3): 480–97.
</div>
<div id="ref-wigner1990" class="csl-entry">
Wigner, Eugene P. 1990. <span>“The Unreasonable Effectiveness of Mathematics in the Natural Sciences.”</span> In <em>Mathematics and Science</em>, 291–306. World Scientific.
</div>
</div>
<p style="text-align:center;">
<a href="1-experiments.html"><button class="btn btn-default">Previous</button></a>
<a href="3-replication.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



<script type="module" src="/assets/entries/entry-server-routing.9e7d4451.js" defer></script><link rel="modulepreload" href="/assets/entries/src_index.page.client.bea4ffd1.js" as="script" type="text/javascript"><link rel="modulepreload" href="/assets/chunks/chunk-e54b7259.js" as="script" type="text/javascript"><script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/src/index","islands":[{"name":"TOC","props":{"name":"Experimentology: An Open Science Approach to Experimental Psychology Methods","items":[{"name":"Foundations","items":[{"name":"Experiments","href":"1-experiments"},{"name":"Theories","href":"2-theories"},{"name":"Replication","href":"3-replication"},{"name":"Ethics","href":"4-ethics"}]},{"name":"Statistics","items":[{"name":"Estimation","href":"5-estimation"},{"name":"Inference","href":"6-inference"},{"name":"Models","href":"7-models"}]},{"name":"Design","items":[{"name":"Measurement","href":"8-measurement"},{"name":"Design","href":"9-design"},{"name":"Sampling","href":"10-sampling"}]},{"name":"Execution","items":[{"name":"Preregistration","href":"11-prereg"},{"name":"Data collection","href":"12-collection"},{"name":"Project management","href":"13-management"}]},{"name":"Reporting","items":[{"name":"Writing","href":"14-writing"},{"name":"Visualization","href":"15-viz"},{"name":"Meta-analysis","href":"16-meta"},{"name":"Conclusions","href":"17-conclusions"}]},{"name":"Appendices","items":[{"name":"GitHub","href":"A-git"},{"name":"R Markdown","href":"B-rmarkdown"},{"name":"Tidyverse","href":"C-tidyverse"},{"name":"ggplot","href":"D-ggplot"},{"name":"Instructor’s guide","href":"E-instructors"}]}]}},{"name":"Box","props":{"children":["\n",{"type":"ul","props":{"children":["\n",{"type":"li","props":{"children":"Define theories and their components"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":523},"\n",{"type":"li","props":{"children":"Contrast different philosophical views on scientific theories"},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":524},"\n",{"type":"li","props":{"children":"Analyze features of an experiment that can lead to strong tests of theory"},"key":5,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":525},"\n",{"type":"li","props":{"children":"Discuss the role of formalization in theory development"},"key":7,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":526},"\n"]},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":527},"\n"],"className":"box","data-box":"learning_goals"}},{"name":"Box","props":{"children":["\n",{"type":"p","props":{"children":"Theory development isn’t just about knowledge for knowledge’s sake – it has implications for the technologies and policies built off the theories."},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":627},"\n",{"type":"p","props":{"children":["One case study comes from Edward Clarke’s infamous theory regarding the deleterious effects of education for women ",{"type":"span","props":{"className":"citation","children":["(",{"type":"a","props":{"href":"#ref-clarke1884","role":"doc-biblioref","children":"E. H. Clarke 1884"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":628},")"]},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":629},". Clarke posited that (1) cognitive and reproductive processes relied on the same fixed pool of energy, (2) relative to men, women’s reproductive processes required more energy, and that (3) expending too much energy on cognitive tasks like education depleted women of the energy needed to maintain a healthy reproductive system. Based on case studies, Clarke suggested that education was causing women to become ill, experience fertility issues, and birth weaker offspring. He thus concluded that “boys must study and work in a boy’s way, and girls in a girl’s way” (p. 18)."]},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":630},"\n",{"type":"p","props":{"children":"Clarke’s work is a chilling example of the implication of a poorly-developed theory. In this scenario, Clarke had neither instruments that allowed him to measure his constructs or experiments to measure the causal connections between them. Instead, he merely highlighted case studies that were consistent with his idea (while simultaneously dismissing cases that were inconsistent). His ideas eventually lost favor – especially as they were subjected to more rigorous tests. But Clarke’s arguments were used to attempt to dissuade women from pursuing higher education and hindered educational policy reform."},"key":5,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":631},"\n"],"className":"box","data-box":"ethical_considerations"}},{"name":"Box","props":{"children":["\n",{"type":"p","props":{"children":"How do you take what you know and apply it to a new situation? One answer is that you use the same answer that has worked in similar situations. To do this kind of extrapolation, however, you need a notion of similarity. Early learning theorists tried to measure similarity by creating an association between a stimulus – say a projected circle of light of a particular size – and a reward by repeatedly presenting them together. After this association was learned, they would test generalization by showing circles of different sizes and measuring the strength of the expectation for a reward. These experiments yielded generalization curves: the more similar the stimulus, the more people and other animals would give the same response, signaling generalization."},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":738},"\n",{"type":"p","props":{"children":[{"type":"span","props":{"className":"citation","children":["Shepard (",{"type":"a","props":{"href":"#ref-shepard1987","role":"doc-biblioref","children":"1987"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":739},")"]},"key":0,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":740}," was interested in unifying the results of these different experiments. The first step in this process was establishing a ",{"type":"strong","props":{"children":"stimulus space"},"key":2,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":741},". He used a procedure called “multidimensional scaling” to infer how close stimuli were to each other on the basis of how strong the generalization between them was. When he plotted the strength of the generalization by the distance between stimuli within this space (their similarity), he found an incredibly consistent pattern: generalization decreased exponentially as similarity decreased."]},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":742},"\n",{"type":"p","props":{"children":["He argued that this described a “universal law” that governed the relationship between similarity and generalization for almost any stimulus, whether it was the size of circles, the color of patches of light, or the similarity between speech sounds. Later work has even extended this same framework to highly abstract dimensions such as the relationships between numbers of different types [e.g., being even, being powers of 2, etc.; ",{"type":"span","props":{"className":"citation","children":["Tenenbaum (",{"type":"a","props":{"href":"#ref-tenenbaum2000","role":"doc-biblioref","children":"2000"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":743},")"]},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":744},"]."]},"key":5,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":745},"\n",{"type":"div","props":{"className":"figure","children":[{"type":"span","props":{"style":{"display":"block"},"id":"fig:theory-shepard","children":null},"key":0,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":746},"\n",{"type":"p","props":{"className":"caption marginnote shownote","children":"\nFigure 2.4: The causal theory of similarity and generalization posited by Shepard (1987).\n"},"key":2,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":747},"\n",{"type":"img","props":{"src":"images/theory/shepard_network3.png","alt":"The causal theory of similarity and generalization posited by Shepard (1987).","width":"\\linewidth","children":null},"key":4,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":748},"\n"]},"key":7,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":749},"\n",{"type":"p","props":{"children":["The pattern shown in Shepard’s work is an example of ",{"type":"strong","props":{"children":"inductive theory building"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":750},". In the vocabulary we’re developing, Shepard ran (or obtained the data from) randomized experiments in which the manipulation was stimulus dimension (e.g., circle size) and the measure was generalization strength. Then the theory that Shepard proposed was that manipulations of stimulus dimension acted to change the perceived similarity between the stimuli. His theory thus linked two constructs: stimulus similarity and generalization strength (Figure ",{"type":"a","props":{"href":"2-theories.html#fig:theory-shepard","children":"2.4"},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":751},"). Critically the causal relationship he described was not just a qualitative relationship but instead a specific mathematical form."]},"key":9,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":752},"\n",{"type":"p","props":{"children":"Shepard wrote in the conclusion of his 1987 paper, “Possibly, behind the diverse behaviors of humans and animals, as behind the various motions of planets and stars, we may discern the operation of universal laws.” While Shepard’s dream is an ambitious one, it defines an ideal for psychological theorizing."},"key":11,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":753},"\n"],"className":"box","data-box":"depth","data-title":"A universal law of generalization?"}},{"name":"Box","props":{"children":["\n",{"type":"ol","props":{"style":{"listStyleType":"decimal"},"children":["\n",{"type":"li","props":{"children":"Identify an influential theory in your field or sub-field. Can you draw the “nomological network” for it? What are the key constructs and how are they measured? Are the links between constructs just directional links or is there additional information about what type of relationship exists? Or does our description of a theory in this chapter not fit your example?"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":799},"\n",{"type":"li","props":{"children":"Can you think of an experiment that falsified a theory in your area of psychology? To what extent is falsification possible for the kinds of theories that you are interested in studying?"},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":800},"\n"]},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":801},"\n"],"className":"box","data-box":"discussion_questions"}},{"name":"Box","props":{"children":["\n",{"type":"ul","props":{"children":["\n",{"type":"li","props":{"children":{"type":"p","props":{"children":"A fabulous introduction to issues in the philosophy of science can be found in: Godfrey-Smith, P. (2009). Theory and reality. University of Chicago Press."},"key":"!undefined","ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":803}},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":804},"\n",{"type":"li","props":{"children":{"type":"p","props":{"children":["Bayesian modeling has been very influential in cognitive science and neuroscience. A good introduction in cognitive science comes from: Lee, M. D. & Wagenmakers, E. J. (2013). ",{"type":"em","props":{"children":"Bayesian Cognitive Modeling: A Practical Course"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":805},". Cambridge University Press. Much of the book is available free online at ",{"type":"a","props":{"href":"https://faculty.sites.uci.edu/mdlee/bgm/","className":"uri","children":"https://faculty.sites.uci.edu/mdlee/bgm/"},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":806},"."]},"key":"!undefined","ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":807}},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":808},"\n",{"type":"li","props":{"children":{"type":"p","props":{"children":["A recent introduction to Bayesian modeling with a neuroscience focus: Ma, W. J., Kording, K. P., & Goldreich, D. (2022). ",{"type":"em","props":{"children":"Bayesian models of perception and action: An introduction"},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":809},". MIT Press. Free online at ",{"type":"a","props":{"href":"https://www.cns.nyu.edu/malab/bayesianbook.html","className":"uri","children":"https://www.cns.nyu.edu/malab/bayesianbook.html"},"key":3,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":810},"."]},"key":"!undefined","ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":811}},"key":5,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":812},"\n"]},"key":1,"ref":"!undefined","__k":null,"__":null,"__b":0,"__e":null,"__d":"!undefined","__c":null,"__h":null,"constructor":"!undefined","__v":813},"\n"],"className":"box","data-box":"readings"}}]}}</script></body></html>
