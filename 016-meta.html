<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>16&nbsp; Meta-analysis – Experimentology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./017-conclusion.html" rel="next">
<link href="./015-viz.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-659MTW4XZ4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-659MTW4XZ4', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./014-writing.html">Reporting</a></li><li class="breadcrumb-item"><a href="./016-meta.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Meta-analysis</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Experimentology</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/langcog/experimentology" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Experimentology.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001-experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002-theories.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Theories</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003-replication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Replication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Planning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008-measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Measurement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010-sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sampling</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Execution</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011-prereg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Preregistration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Data collection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Project management</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Reporting</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014-writing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Writing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016-meta.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Meta-analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017-conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100-instructors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Instructor’s guide</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./101-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git and GitHub</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./102-rmarkdown.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">R Markdown and Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./103-tidyverse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Tidyverse</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./104-ggplot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">ggplot</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<p>© 2024. This work is openly licensed via <a href="https://creativecommons.org/licenses/by-nc/4.0">CC BY NC 4.0</a>.</p>
</div></div></nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-basics-of-evidence-synthesis" id="toc-the-basics-of-evidence-synthesis" class="nav-link active" data-scroll-target="#the-basics-of-evidence-synthesis"><span class="header-section-number">16.1</span> The basics of evidence synthesis</a>
  <ul class="collapse">
  <li><a href="#how-not-to-synthesize-evidence" id="toc-how-not-to-synthesize-evidence" class="nav-link" data-scroll-target="#how-not-to-synthesize-evidence"><span class="header-section-number">16.1.1</span> How not to synthesize evidence</a></li>
  <li><a href="#fixed-effects-meta-analysis" id="toc-fixed-effects-meta-analysis" class="nav-link" data-scroll-target="#fixed-effects-meta-analysis"><span class="header-section-number">16.1.2</span> Fixed-effects meta-analysis</a></li>
  <li><a href="#limitations-of-fixed-effects-meta-analysis" id="toc-limitations-of-fixed-effects-meta-analysis" class="nav-link" data-scroll-target="#limitations-of-fixed-effects-meta-analysis"><span class="header-section-number">16.1.3</span> Limitations of fixed-effects meta-analysis</a></li>
  <li><a href="#random-effects-meta-analysis" id="toc-random-effects-meta-analysis" class="nav-link" data-scroll-target="#random-effects-meta-analysis"><span class="header-section-number">16.1.4</span> Random-effects meta-analysis</a></li>
  </ul></li>
  <li><a href="#bias-in-meta-analysis" id="toc-bias-in-meta-analysis" class="nav-link" data-scroll-target="#bias-in-meta-analysis"><span class="header-section-number">16.2</span> Bias in meta-analysis</a>
  <ul class="collapse">
  <li><a href="#within-study-biases" id="toc-within-study-biases" class="nav-link" data-scroll-target="#within-study-biases"><span class="header-section-number">16.2.1</span> Within-study biases</a></li>
  <li><a href="#across-study-biases" id="toc-across-study-biases" class="nav-link" data-scroll-target="#across-study-biases"><span class="header-section-number">16.2.2</span> Across-study biases</a></li>
  <li><a href="#across-study-bias-correction" id="toc-across-study-bias-correction" class="nav-link" data-scroll-target="#across-study-bias-correction"><span class="header-section-number">16.2.3</span> Across-study bias correction</a></li>
  </ul></li>
  <li><a href="#chapter-summary-meta-analysis" id="toc-chapter-summary-meta-analysis" class="nav-link" data-scroll-target="#chapter-summary-meta-analysis"><span class="header-section-number">16.3</span> Chapter summary: Meta-analysis</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/langcog/experimentology/blob/main/016-meta.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/langcog/experimentology/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./014-writing.html">Reporting</a></li><li class="breadcrumb-item"><a href="./016-meta.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Meta-analysis</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-meta" class="quarto-section-identifier"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Meta-analysis</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled" title="learning goals">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
learning goals
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li>Discuss the benefits of synthesizing evidence across studies</li>
<li>Conduct a simple fixed-effects or random-effects meta-analysis</li>
<li>Reason about the role of within-study and across-study biases in meta-analysis</li>
</ul>
</div>
</div>
</div>
<p>Throughout this book, we have focused on how to design individual experiments that maximize <span class="smallcaps">measurement precision</span> and minimize bias. But even when we do our best to get a precise, unbiased estimate in an individual experiment, one study can never be definitive. Variability in participant demographics, stimuli, and experimental methods may limit the <span class="smallcaps">generalizability</span> of our findings. Additionally, even well-powered individual studies have some amount of statistical error, limiting their precision. Synthesizing evidence across studies is critical for developing a balanced and appropriately evolving view of the overall evidence on an effect of interest and for understanding sources of variation in the effect.</p>
<p>Synthesizing evidence rigorously takes more than putting a search term into Google Scholar, downloading articles that look topical or interesting, and qualitatively summarizing your impressions of those studies. While this ad hoc method can be an essential first step in performing a literature review <span class="citation" data-cites="grant2009typology">(<a href="#ref-grant2009typology" role="doc-biblioref">Grant and Booth 2009</a>)</span>, it is not systematic and doesn’t provide a <em>quantitative</em> summary of a particular effect. Further, it doesn’t tell you anything about potential biases in the literature—for example, a bias for the publication of positive effects.</p>
<p>To address these issues, a more systematic, quantitative review of the literature is often more informative. This chapter focuses on a specific type of quantitative review called <strong>meta-analysis</strong>: a method for combining effect sizes across different studies. (If you need a refresher on effect size, see <a href="005-estimation.html" class="quarto-xref"><span>chapter 5</span></a>, where we introduce the concept.)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> We incude a chapter on meta-analysis in <em>Experimentology</em> because we believe it’s an important tool that can focus experimental researchers on issues of <span class="smallcaps">measurement precision</span> and <span class="smallcaps">bias reduction</span>, two of our key themes.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;We’ll primarily be using Cohen’s <span class="math inline">\(d\)</span>, the standardized difference between means, which we introduced in <a href="005-estimation.html" class="quarto-xref"><span>chapter 5</span></a>. There are many more varieties of effect size available, but we focus here on <span class="math inline">\(d\)</span> because it’s common and easy to reason about in the context of the statistical tools we introduced in the earlier sections of the book.</p></div></div><p>By combining information from multiple studies, meta-analysis often provides more precise estimates of an effect size than any single study. In addition, meta-analysis also allows the researcher to look at the extent to which an effect varies across studies. If an effect does vary across studies, meta-analysis also can be used to test whether certain study characteristics systematically produce different results (e.g., whether an effect is larger in certain populations).</p>
<div class="callout callout-style-default callout-note callout-titled" title="case study">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
case study
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<section id="towel-reuse-by-hotel-guests" class="level3 unnumbered callout-body-container callout-body">
<h3 class="unnumbered anchored" data-anchor-id="towel-reuse-by-hotel-guests">Towel reuse by hotel guests</h3>
<p>Imagine you are staying in a hotel and you have just taken a shower. Do you throw the towels on the floor or hang them back up again? In a widely cited study on the power of social norms, <span class="citation" data-cites="goldstein2008room">Goldstein, Cialdini, and Griskevicius (<a href="#ref-goldstein2008room" role="doc-biblioref">2008</a>)</span> manipulated whether a sign encouraging guests to reuse towels focused on environmental impacts (e.g., “help reduce water use”) or social norms (e.g., “most guests reuse their towels”). Across two studies, they found that guests were significantly more likely to reuse their towels after receiving the social norm message (Study 1: odds ratio [OR] = 1.46, 95% CI [1.00, 2.16], <span class="math inline">\(p = 0.05\)</span>; Study 2: OR = 1.35, 95% CI [1.04, 1.77], <span class="math inline">\(p = 0.03\)</span>).</p>
<p>However, five subsequent studies by other researchers did not find significant evidence that social norm messaging increased towel reuse. (ORs ranged from 0.22 to 1.34, and no hypothesis-consistent <span class="math inline">\(p\)</span>-value was less than 0.05). This caused many researchers to wonder if there is any effect at all. To examine this question, <span class="citation" data-cites="scheibehenne2016">Scheibehenne, Jamil, and Wagenmakers (<a href="#ref-scheibehenne2016" role="doc-biblioref">2016</a>)</span> statistically combined evidence across the studies via meta-analysis. This meta-analysis indicated that using social norm messages did significantly increase hotel towel reuse, on average (OR = 1.26, 95% CI [1.07, 1.46], <span class="math inline">\(p &lt; 0.005\)</span>). This case study demonstrates an important strength of meta-analysis: by pooling evidence from multiple studies, meta-analysis can generate more powerful insights than any one study alone. We will also see how meta-analysis can be used to assess variability in effects across studies.</p>
</section>
</div>
</div>
<!-- All ES's come from Wagenmakers et al. SI -->
<p>Meta-analysis often teaches us something about a body of evidence that we do not intuitively grasp when we casually read through a bunch of articles. In the above case study, merely reading the individual studies might give the impression that social norm messages do not increase hotel towel reuse. But meta-analysis indicated that the average effect is beneficial, although there might be substantial variation in effect sizes across studies.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Given the billions of hotel bookings worldwide every year, even a small effect might have lead to a substantial environmental impact!</p></div></div><section id="the-basics-of-evidence-synthesis" class="level2 page-columns page-full" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="the-basics-of-evidence-synthesis"><span class="header-section-number">16.1</span> The basics of evidence synthesis</h2>
<p>As we explore the details of conducting a meta-analysis, we’ll turn to another running example: a meta-analysis of studies investigating the “contact hypothesis” on intergroup relations.</p>
<p>According to the contact hypothesis, prejudice toward members of minority groups can be reduced through intergroup contact interventions, in which members of majority and minority groups work together to pursue a common goal <span class="citation" data-cites="allport1954nature">(<a href="#ref-allport1954nature" role="doc-biblioref">Allport, Clark, and Pettigrew 1954</a>)</span>. To aggregate the evidence on the contact hypothesis, <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> meta-analyzed studies that tested the effects of randomized intergroup contact interventions on long-term prejudice-related outcomes.</p>
<p>Using a systematic literature search, <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> searched for all papers that tested these effects and then extracted effect size estimates from each paper.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Because not every paper reports standardized effect sizes—or even means and standard deviations for every group—this process can often involve scraping information from plots, tables, and statistical tests to try to reconstruct effect sizes.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;This book will not cover the process of conducting a systematic literature search and extracting effect sizes, but these topics are critical to understand if you plan to conduct a meta-analysis or other evidence synthesis. Our experience is that extracting effect sizes from papers with inconsistent reporting standards can be especially tricky, so it can be helpful to talk to someone with experience in meta-analysis to get advice about this.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;For example, if the outcome variable is continuous, we could estimate Cohen’s <span class="math inline">\(d\)</span> from group means and standard deviations reported in the paper, even without having access to raw data.</p></div></div><p>Following best practices for meta-analysis (where there are almost never privacy concerns to worry about), <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> shared their data openly. The first few lines are shown in <a href="#tbl-meta-dataset" class="quarto-xref">table&nbsp;<span>16.1</span></a>. We’ll use these data as our running example throughout.</p>
<div class="cell">
<div id="tbl-meta-dataset" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-meta-dataset-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;16.1: The first few lines of extracted effect sizes (d) and their variances (var_d) in the Paluck, Green, and Green (2019) meta-analysis.
</figcaption>
<div aria-describedby="tbl-meta-dataset-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="kable-table">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">name</th>
<th style="text-align: right;">pub_date</th>
<th style="text-align: left;">target</th>
<th style="text-align: right;">n_total</th>
<th style="text-align: right;">d</th>
<th style="text-align: right;">var_d</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Boisjoly 06 B</td>
<td style="text-align: right;">2006</td>
<td style="text-align: left;">race</td>
<td style="text-align: right;">1243</td>
<td style="text-align: right;">0.030</td>
<td style="text-align: right;">0.006</td>
</tr>
<tr class="even">
<td style="text-align: left;">Sorensen 10</td>
<td style="text-align: right;">2010</td>
<td style="text-align: left;">race</td>
<td style="text-align: right;">597</td>
<td style="text-align: right;">0.302</td>
<td style="text-align: right;">0.007</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Scacco 18</td>
<td style="text-align: right;">2018</td>
<td style="text-align: left;">religion</td>
<td style="text-align: right;">474</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">0.010</td>
</tr>
<tr class="even">
<td style="text-align: left;">Finseraas 2017</td>
<td style="text-align: right;">2017</td>
<td style="text-align: left;">foreigners</td>
<td style="text-align: right;">577</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">0.011</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sheare 74</td>
<td style="text-align: right;">1974</td>
<td style="text-align: left;">disability</td>
<td style="text-align: right;">400</td>
<td style="text-align: right;">1.059</td>
<td style="text-align: right;">0.011</td>
</tr>
<tr class="even">
<td style="text-align: left;">Barnhardt 09</td>
<td style="text-align: right;">2009</td>
<td style="text-align: left;">religion</td>
<td style="text-align: right;">312</td>
<td style="text-align: right;">0.395</td>
<td style="text-align: right;">0.015</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>As we’ve seen throughout this book, visualizing data before and after analysis helps benchmark and check our intuitions about the formal statistical results. In a meta-analysis, a common way to plot effect sizes is the <strong>forest plot</strong>, which depicts individual studies’ estimates and confidence intervals. In the forest plot in <a href="#fig-meta-forest" class="quarto-xref">figure&nbsp;<span>16.1</span></a>,<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> the larger squares correspond to more precise studies; notice how much narrower their confidence intervals are than the confidence intervals of less precise studies.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;You can ignore for now the final line, “RE Model”; we will return to this later.</p></div></div><div class="cell page-columns page-full" data-cap-location="margin">
<div class="cell-output-display page-columns page-full">
<div id="fig-meta-forest" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" alt="A forest plot with estimated standardized mean difference points and 95% confidence interval error bars for each study." data-cap-location="margin">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-meta-forest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="016-meta_files/figure-html/fig-meta-forest-1.png" class="img-fluid figure-img" style="width:80.0%" alt="A forest plot with estimated standardized mean difference points and 95% confidence interval error bars for each study.">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-meta-forest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.1: A forest plot for <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> meta-analysis. Studies are ordered from smallest to largest standard error.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In this chapter, we use the wonderful <code>metafor</code> package <span class="citation" data-cites="viechtbauer2010">(<a href="#ref-viechtbauer2010" role="doc-biblioref">Viechtbauer 2010</a>)</span>. With this package, you must first fit your meta-analytic model. But once you’ve fit your model <code>mod</code>, you can simply call <code>forest(mod)</code> to create a plot like the one above.</p>
</div>
</div>
</div>
<!-- Cohen's $d$---which, if you recall from @sec-estimation, represents the standardized mean difference---was used as the effect size index. As we show in the remainder of the chapter, the meta-analytic tools @paluck2019contact used provide several useful insights about this proposed prejudice-reduction intervention. -->
<section id="how-not-to-synthesize-evidence" class="level3" data-number="16.1.1">
<h3 data-number="16.1.1" class="anchored" data-anchor-id="how-not-to-synthesize-evidence"><span class="header-section-number">16.1.1</span> How not to synthesize evidence</h3>
<p>Many people’s first instinct in evidence synthesis is to count how many studies supported versus did not support the hypothesis under investigation. This technique usually amounts to counting the number of studies with “significant” <span class="math inline">\(p\)</span>-values, since—for better or for worse—“significance” is largely what drives the take-home conclusions researchers report <span class="citation" data-cites="mcshane2017statistical nelson1986interpretation">(<a href="#ref-mcshane2017statistical" role="doc-biblioref">McShane and Gal 2017</a>; <a href="#ref-nelson1986interpretation" role="doc-biblioref">Nelson, Rosenthal, and Rosnow 1986</a>)</span>. In meta-analysis, we call this practice of counting the number of significant <span class="math inline">\(p\)</span>-values <strong>vote-counting</strong> <span class="citation" data-cites="borenstein2021introduction">(<a href="#ref-borenstein2021introduction" role="doc-biblioref">Borenstein et al. 2021</a>)</span>. For example, in the <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> meta-analysis, almost all studies had a positive effect size, but only 12 of 27 were significant. So, based on this vote-count, we would have the impression that most studies do not support the contact hypothesis.</p>
<p>Many qualitative literature reviews use this vote-counting approach, although often not explicitly. Despite its intuitive appeal, vote-counting can be very misleading because it characterizes evidence solely in terms of dichotomized <span class="math inline">\(p\)</span>-values, while entirely ignoring effect sizes. In <a href="003-replication.html" class="quarto-xref"><span>chapter 3</span></a>, we saw how fetishizing statistical significance can mislead us when we consider individual studies. These problems also apply when considering multiple studies.</p>
<p>For example, small studies may consistently produce nonsignificant effects due to their limited power. But when many such studies are combined in a meta-analysis, the meta-analysis may provide strong evidence of a positive average effect. Inversely, many studies might have statistically significant effects, but if their effect sizes are small, then a meta-analysis might indicate that the average effect size is too small to be practically meaningful. In these cases, vote-counting based on statistical significance can lead us badly astray <span class="citation" data-cites="borenstein2021introduction">(<a href="#ref-borenstein2021introduction" role="doc-biblioref">Borenstein et al. 2021</a>)</span>. To avoid these pitfalls, meta-analysis combines the effect size estimates from each study (not just their <span class="math inline">\(p\)</span>-values), weighting them in a principled way.</p>
</section>
<section id="fixed-effects-meta-analysis" class="level3 page-columns page-full" data-number="16.1.2">
<h3 data-number="16.1.2" class="anchored" data-anchor-id="fixed-effects-meta-analysis"><span class="header-section-number">16.1.2</span> Fixed-effects meta-analysis</h3>
<p>If vote-counting is a bad idea, how should we combine results across studies? Another intuitive approach might be to average effect sizes from each study. For example, in Paluck et al.’s meta-analysis, the mean of the studies’ effect size estimates is 0.44. This averaging approach is a step in the right direction, but it has an important limitation: averaging effect size estimates gives equal weight to each study. A small study <span class="citation" data-cites="clunies1989changing">(e.g., <a href="#ref-clunies1989changing" role="doc-biblioref">Clunies-Ross and O’Meara 1989</a> with <span class="math inline">\(N = 30\)</span>)</span> contributes as much to the mean effect size as a large study <span class="citation" data-cites="boisjoly2006empathy">(e.g., <a href="#ref-boisjoly2006empathy" role="doc-biblioref">Boisjoly et al. 2006</a> with <span class="math inline">\(N = 1,243\)</span>)</span>. Larger studies provide more precise estimates of effect sizes than small studies, so weighting all studies equally is not ideal. Instead, larger studies should carry more weight in the analysis.</p>
<p>To address this issue, <strong>fixed-effects meta-analysis</strong> uses a <strong>weighted average</strong> approach. Larger, more precise studies are given more weight in the calculation of the overall effect size. Specifically, each study is weighted by the inverse of its variance (i.e., the inverse of its squared standard error). This makes sense because larger, more precise studies have smaller variances, and thus get more weight in the analysis.</p>
<p>In general terms, the fixed-effect pooled estimate is: <span class="math display">\[\widehat{\mu} = \frac{ \sum_{i=1}^k w_i \widehat{\theta}_i}{\sum_{i=1}^k w_i}\]</span> where <span class="math inline">\(k\)</span> is the number of studies, <span class="math inline">\(\widehat{\theta}_i\)</span> is the point estimate of the <span class="math inline">\(i^{th}\)</span> study, and <span class="math inline">\(w_i = 1/\widehat{\sigma}^2_i\)</span> is study <span class="math inline">\(i\)</span>’s weight in the analysis (i.e., the inverse of its variance).<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<!-- In Paluck et al.'s meta-analysis, we would calculate the fixed-effect estimate, $\widehat{\mu}$, as: -->
<!-- <!-- hard-coded from df$d[1:2] and df$se_d[1:2] -->
<!-- $$\widehat{\mu} = \frac{ \frac{\widehat{\theta}_{study1}}{\widehat{\sigma}^2_{study1}} + \frac{\widehat{\theta}_{study2}}{\widehat{\sigma}^2_{study2}} + \cdots}{ \frac{1}{\widehat{\sigma}^2_{study1}} + \frac{1}{\widehat{\sigma}^2_{study2}} + \cdots } = -->
<!-- \frac{ \frac{0.03}{0.08^2} + \frac{0.30}{0.08^2} + \cdots }{ \frac{1}{0.08^2} + \frac{1}{0.08^2} + \cdots }$$ -->
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;If you are curious, the standard error of the fixed-effect <span class="math inline">\(\widehat{\mu}\)</span> is <span class="math inline">\(\frac{1}{\sum_{i=1}^k w_i}\)</span>. This standard error can be used to construct a confidence interval or <span class="math inline">\(p\)</span>-value, as described in <a href="006-inference.html" class="quarto-xref"><span>chapter 6</span></a>.</p></div></div><p>Using the fixed-effects formula, we can estimate that the overall effect size in Paluck et al.’s meta-analysis is a standardized mean difference of <span class="math inline">\(\widehat{\mu}\)</span> = 0.28; 95% confidence interval [0.23, 0.34]; <span class="math inline">\(p &lt; 0.001\)</span>. Because Cohen’s <span class="math inline">\(d\)</span> is our effect size index, this estimate would suggest that intergroup contact decreased prejudice by 0.28 standard deviations.</p>
<div class="callout callout-style-default callout-note callout-titled" title="code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Fitting meta-analytic models in <code>metafor</code> is quite simple. For example, for the fixed-effects model above, we simply ran the <code>rma()</code> function and specified that we wanted a fixed-effects analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>fe_model <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> d, <span class="at">vi =</span> var_d, <span class="at">data =</span> paluck, <span class="at">method =</span> <span class="st">"FE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then <code>summary(fe_model)</code> gives us the relevant information about the fitted model.</p>
</div>
</div>
</div>
</section>
<section id="limitations-of-fixed-effects-meta-analysis" class="level3" data-number="16.1.3">
<h3 data-number="16.1.3" class="anchored" data-anchor-id="limitations-of-fixed-effects-meta-analysis"><span class="header-section-number">16.1.3</span> Limitations of fixed-effects meta-analysis</h3>
<p>One of the limitations of fixed-effect meta-analysis is that it assumes that the true effect size is, well, <em>fixed</em>! In other words, fixed-effect meta-analysis assumes that there is a single effect size that all studies are estimating. This is a stringent assumption. It’s easy to imagine that it could be violated. Imagine, for example, that intergroup contact decreased prejudice when the group succeeded at its joint goal but <em>increased</em> prejudice when the group failed. If we meta-analyzed two studies under these conditions—one in which intergroup contact substantially increased prejudice and one in which intergroup contact substantially decreased prejudice—it might appear that the true effect of intergroup contact was close to zero, when in fact both of the meta-analyzed studies had large effects.</p>
<p>In Paluck et al.’s meta-analysis, studies differed in several ways that could lead to different true effects. For example, some studies recruited adult participants while others recruited children. If intergroup contact is more or less effective for adults versus children, then it is misleading to talk about a single (i.e., “fixed”) intergroup contact effect. Instead, we would say that the effects of intergroup contact vary across studies, an idea called <strong>heterogeneity</strong>.</p>
<p>Does the concept of heterogeneity remind you of anything from when we analyzed repeated-measures data in <a href="007-models.html" class="quarto-xref"><span>chapter 7</span></a> on models? Recall that, with repeated-measures data, we had to deal with the possibility of heterogeneity across participants—and of the ways we did so was by introducing participant-level random intercepts to our regression model. It turns out that we can do a similar thing in meta-analysis to deal with heterogeneity across studies.</p>
</section>
<section id="random-effects-meta-analysis" class="level3 page-columns page-full" data-number="16.1.4">
<h3 data-number="16.1.4" class="anchored" data-anchor-id="random-effects-meta-analysis"><span class="header-section-number">16.1.4</span> Random-effects meta-analysis</h3>
<p>While fixed-effect meta-analysis essentially assumes that all studies in the meta-analysis have the same population effect size, <span class="math inline">\(\mu\)</span>, random-effects meta-analysis instead assumes that study effects come from a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\tau\)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> The larger the standard deviation, <span class="math inline">\(\tau\)</span>, the more heterogeneous the effects are across studies. A random-effects model then estimates both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>, for example by maximum likelihood <span class="citation" data-cites="dersimonian1986meta brockwell2001comparison">(<a href="#ref-dersimonian1986meta" role="doc-biblioref">DerSimonian and Laird 1986</a>; <a href="#ref-brockwell2001comparison" role="doc-biblioref">Brockwell and Gordon 2001</a>)</span>. <!-- ^[A confidence interval and $p$-value for the random-effects estimate $\widehat{\mu}$ can be obtained using standard theory for maximum likelihood estimates with an additional adjustment that helps account for uncertainty in estimating $\tau$ [@knapp2003improved].] --></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Technically, other specifications of random-effects meta-analysis are possible. For example, robust variance estimation does not require making assumptions about the distribution of effects across studies <span class="citation" data-cites="hedges2010robust">(<a href="#ref-hedges2010robust" role="doc-biblioref">Hedges, Tipton, and Johnson 2010</a>)</span>. These approaches also have other substantial advantages, like their ability to handle effects that are clustered, e.g., because some papers contribute multiple estimates <span class="citation" data-cites="hedges2010robust pustejovsky2021meta">(<a href="#ref-hedges2010robust" role="doc-biblioref">Hedges, Tipton, and Johnson 2010</a>; <a href="#ref-pustejovsky2021meta" role="doc-biblioref">Pustejovsky and Tipton 2021</a>)</span>, and their ability to provide better inference in meta-analyses with relatively few studies <span class="citation" data-cites="tipton2015small">(<a href="#ref-tipton2015small" role="doc-biblioref">Tipton 2015</a>)</span>. For these reasons, we often use these robust methods.</p></div></div><p>Like fixed-effect meta-analysis, the random-effects estimate of <span class="math inline">\(\widehat{\mu}\)</span> is still a weighted average of studies’ effect size estimates: <span class="math display">\[\widehat{\mu} = \frac{ \sum_{i=1}^k w_i \widehat{\theta}_i}{\sum_{i=1}^k w_i}\]</span> However, in random-effects meta-analysis, the inverse-variance weights now incorporate heterogeneity: <span class="math inline">\(w_i = 1/\left(\widehat{\tau}^2 + \widehat{\sigma}^2_i \right)\)</span>. Where before we had one term in our weights, now we have two. That is because these weights represent the inverse of studies’ <em>marginal</em> variances, taking into account both statistical error due to their finite sample sizes (<span class="math inline">\(\widehat{\sigma}^2_i\)</span> as before) and also genuine effect heterogeneity (<span class="math inline">\(\widehat{\tau}^2\)</span>). <!--^[The estimate of $\widehat{\tau}^2$ is a bit more complicated, but is essentially a weighted average of studies' squared residuals, $\widehat{\theta_i} - \widehat{\mu}$, while subtracting away variation due to statistical error, $\widehat{\sigma}^2_i$ [@dersimonian1986meta; @brockwell2001comparison].]  --></p>
<p>Conducting a random-effects meta-analysis of Paluck et al.’s dataset yields <span class="math inline">\(\widehat{\mu}\)</span> = 0.4; 95% confidence interval [0.2, 0.61]; <span class="math inline">\(p &lt; 0.001\)</span>. That is, <em>on average across studies</em>, intergroup contact was associated with a decrease in prejudice of 0.4 standard deviations, substantially larger than the estimate from the fixed-effects model. This meta-analytic estimate is shown as the bottom line of <a href="#fig-meta-forest" class="quarto-xref">figure&nbsp;<span>16.1</span></a>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Fitting a random-effects model requires only a small change to the methods argument of <code>rma()</code>. (We also include the <code>knha</code> flag that adds a correction to the computation of standard errors and p-values.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>re_model <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> d, <span class="at">vi =</span> var_d, <span class="at">data =</span> paluck, <span class="at">method =</span> <span class="st">"REML"</span>, <span class="at">knha =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-meta-densities" class="quarto-float quarto-figure quarto-figure-center anchored" alt="A plot where 2 bell curves representing observed &amp; estimated distributions of effect sizes are similar but not identical.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-meta-densities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="016-meta_files/figure-html/fig-meta-densities-1.png" class="img-fluid figure-img" alt="A plot where 2 bell curves representing observed &amp; estimated distributions of effect sizes are similar but not identical." width="1050">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-meta-densities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.2: Estimated distribution of population effects from random-effects meta-analysis of Paluck et. al’s dataset (heavy red curve) and estimated density of studies’ point estimates (thin black curve).
</figcaption>
</figure>
</div>
</div></div></div>
<p>Based on the random-effects model, intergroup contact effects appear to differ across studies. Paluck et al.&nbsp;estimated that the standard deviation of effects across studies was <span class="math inline">\(\widehat{\tau}\)</span> = 0.44 ; 95% confidence interval [0.25, 0.57]. This estimate indicates a substantial amount of heterogeneity! To visualize these results, we can plot the estimated density of the population effects, which is just a normal distribution with mean <span class="math inline">\(\widehat{\mu}\)</span> and standard deviation <span class="math inline">\(\widehat{\tau}\)</span> (<a href="#fig-meta-densities" class="quarto-xref">figure&nbsp;<span>16.2</span></a>).</p>
<p>This meta-analysis highlights an important point: that the overall effect size estimate <span class="math inline">\(\widehat{\mu}\)</span> represents only the <em>mean</em> population effect across studies. It tells us nothing about how much the effects <em>vary</em> across studies. Thus, we recommend always reporting the heterogeneity estimate <span class="math inline">\(\widehat{\tau}\)</span>, preferably along with other related metrics that help summarize the distribution of effect sizes across studies <span class="citation" data-cites="riley2011interpretation wang2019simple mathur_mam npphat">(<a href="#ref-riley2011interpretation" role="doc-biblioref">Riley, Higgins, and Deeks 2011</a>; <a href="#ref-wang2019simple" role="doc-biblioref">Wang and Lee 2019</a>; <a href="#ref-mathur_mam" role="doc-biblioref">Mathur and VanderWeele 2019</a>, <a href="#ref-npphat" role="doc-biblioref">2020a</a>)</span>. Reporting the heterogeneity helps readers know how consistent or inconsistent the effects are across studies, which may point to the need to investigate <em>moderators</em> of the effect (i.e., factors that are associated with larger or smaller effects, such as whether participants were adults or children).<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;One common approach to investigating moderators in meta-analysis is meta-regression, in which moderators are included as covariates in a random-effects meta-analysis model <span class="citation" data-cites="thompson2002should">(<a href="#ref-thompson2002should" role="doc-biblioref">Thompson and Higgins 2002</a>)</span>. As in standard regression, coefficients can then be estimated for each moderator, representing the mean difference in population effect between studies with versus without the moderator.</p></div></div><div class="callout callout-style-default callout-note callout-titled" title="depth">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
depth
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<section id="single-paper-meta-analysis-and-pooled-analysis" class="level3 unnumbered callout-body-container callout-body">
<h3 class="unnumbered anchored" data-anchor-id="single-paper-meta-analysis-and-pooled-analysis">Single-paper meta-analysis and pooled analysis</h3>
<p>Thus far, we have described meta-analysis as a tool for summarizing results reported across multiple papers. However, some people have argued that meta-analysis should also be used to summarize the results of multiple studies reported in a single paper <span class="citation" data-cites="goh2016mini">(<a href="#ref-goh2016mini" role="doc-biblioref">Goh, Hall, and Rosenthal 2016</a>)</span>. For instance, in a paper where you describe three different experiments on a hypothesis, you could (1) extract summary information (e.g., means and standard deviations) from each study, (2) compute the effect size, and then (3) combine the effect sizes in a meta-analysis.</p>
<p>Single-paper meta-analyses come with many of the same strengths and weaknesses we have discussed thus far. One unique weakness, though, is that having a small number of studies means that you typically have low power to detect heterogeneity and moderators. This lack of power sometimes leads researchers to claim that there are no significant differences between their studies. But an alternative explanation is that there simply wasn,t enough power to detect those differences!</p>
<p>As an alternative, you can also pool the actual data from the three studies, as opposed to just pooling summary statistics. For example, if you have data from 10 participants in each of the three experiments, you could pool them into a single dataset with 30 participants and include random effects of your condition manipulation across experiments (as described in <a href="007-models.html" class="quarto-xref"><span>chapter 7</span></a>). This strategy is often referred to as <strong>pooled</strong> or <strong>integrative</strong> data analysis (and occasionally as “mega-analysis,” which sounds cool).</p>
<div id="fig-meta-v-ipd" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Spreadsheets where: 3 studies each have 10 rows of data; pooled analysis has all 30 rows; meta-analysis has a row per study.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-meta-v-ipd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/meta/meta_v_ipd.png" class="img-fluid figure-img" alt="Spreadsheets where: 3 studies each have 10 rows of data; pooled analysis has all 30 rows; meta-analysis has a row per study.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-meta-v-ipd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.3: Meta-analysis vs pooled data analysis.
</figcaption>
</figure>
</div>
<p>One of the benefits of pooled data analysis is that it can give you more power to detect moderators. For instance, imagine that the effect of an intergroup contact treatment is moderated by age. If we performed a traditional meta-analysis, we would only have three observations in our data set, yielding very low power. However, we have many more observations (and much more variation in the moderator) in the pooled data analysis, which can lead to higher power (<a href="#fig-meta-v-ipd" class="quarto-xref">figure&nbsp;<span>16.3</span></a>).</p>
<p>Pooled data analysis is not without its own limitations <span class="citation" data-cites="cooper2009relative">(<a href="#ref-cooper2009relative" role="doc-biblioref">Cooper and Patall 2009</a>)</span>. And, of course, sometimes it doesn,t make as much sense to pool datasets (e.g., when measures are different from one another). Nonetheless, we believe that pooled data analysis and meta-analysis are both useful tools to keep in mind in a paper reporting multiple experiments!</p>
</section>
</div>
</div>
</section>
</section>
<section id="bias-in-meta-analysis" class="level2 page-columns page-full" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="bias-in-meta-analysis"><span class="header-section-number">16.2</span> Bias in meta-analysis</h2>
<p>Meta-analysis is a great tool for synthesizing evidence across studies, but the accuracy of a meta-analysis can be compromised by bias. We’ll talk about two categories of bias here: <strong>within-study</strong> and <strong>across-study</strong> biases. Either type can lead to meta-analytic estimates that are too large, too small, or even in the wrong direction altogether. <!-- We will now discuss examples of each type of bias as well as ways to address these biases when conducting a meta-analysis. This includes mitigating the biases at the outset through sound meta-analysis design and also assessing the robustness of the ultimate conclusions to possible remaining bias. --></p>
<section id="within-study-biases" class="level3 page-columns page-full" data-number="16.2.1">
<h3 data-number="16.2.1" class="anchored" data-anchor-id="within-study-biases"><span class="header-section-number">16.2.1</span> Within-study biases</h3>
<p>Within-study biases—such as demand characteristics, confounds, and order effects, all discussed in <a href="009-design.html" class="quarto-xref"><span>chapter 9</span></a>—not only impact the validity of individual studies but also any attempt to synthesize those studies. And of course, if individual study results are affected by analytic flexibility (<span class="math inline">\(p\)</span>-hacking), meta-analyzing these will result in inflated effect size estimates. In other words: garbage in, garbage out.</p>
<p>For example, <span class="citation" data-cites="paluck2019contact">Paluck, Green, and Green (<a href="#ref-paluck2019contact" role="doc-biblioref">2019</a>)</span> noted that early studies on intergroup contact almost exclusively used nonrandomized designs. Imagine a hypothetical study where researchers studied a completely ineffective intergroup contact intervention, and nonrandomly assigned low-prejudice people to the intergroup contact condition and high-prejudice people to the control condition. In a scenario like this, the researcher would of course find that the prejudice was lower in the intergroup contact condition. But the effect would not be a true contact intervention effect, but rather a spurious effect of nonrandom assignment (i.e., confounding). Now imagine meta-analyzing many studies with similarly poor designs. The meta-analyst might find impressive evidence of an intergroup contact effect, even if none existed.</p>
<p>To mitigate this problem, meta-analysts often exclude studies that may be especially affected by within-study bias. <span class="citation" data-cites="paluck2019contact">(For example, <a href="#ref-paluck2019contact" role="doc-biblioref">Paluck, Green, and Green 2019</a> excluded nonrandomized studies)</span>. Of course, these decisions can’t be made on the basis of their effects on the meta-analytic estimate or else this post hoc exclusion itself will lead to bias! For this reason, inclusion and exclusion criteria for meta-analyses should be preregistered whenever possible.</p>
<p>Sometimes certain sources of bias cannot be eliminated by excluding studies—often because studies in a particular domain share certain fundamental limitations (for example, attrition in drug trials). After data have been collected, meta-analysts should also assess studies’ risks of bias qualitatively using established rating tools <span class="citation" data-cites="sterne2016robins">(<a href="#ref-sterne2016robins" role="doc-biblioref">Sterne et al. 2016</a>)</span>. Doing so allows the meta-analyst to communicate how much within-study bias there may be.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <!-- @paluck2019contact did not use such tools, but they could have used it to communicate, for example, the extent to which participants might have differentially dropped out of the study.]  --></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;If you’re interested in assessing within-study bias, you can take a look at the Risk of Bias tool (<a href="https://sites.google.com/site/riskofbiastool/welcome/rob-2-0-tool" class="uri">https://sites.google.com/site/riskofbiastool/welcome/rob-2-0-tool</a>) developed by Cochrane, an organization devoted to evidence synthesis.</p></div></div><p>Meta-analysts can also conduct sensitivity analyses to assess how much results might be affected by different within-study biases or by excluding certain types of studies <span class="citation" data-cites="art">(<a href="#ref-art" role="doc-biblioref">Mathur and VanderWeele 2022</a>)</span>. For example, if nonrandom assignment is a concern, a meta-analyst may run the analyses including only randomized studies, versus including all studies, in order to determine how much including nonrandomized studies changes the meta-analytic estimate. These two options parallel our discussion of experimental preregistration in <a href="011-prereg.html" class="quarto-xref"><span>chapter 11</span></a>: to allay concerns about results-dependent meta-analysis, researchers can either preregister their analyses ahead of time or else be transparent about their choices after the fact. Sensitivity analyses can allay concerns that a specific choice of exclusion criteria is critically related to the reported results.</p>
</section>
<section id="across-study-biases" class="level3 page-columns page-full" data-number="16.2.2">
<h3 data-number="16.2.2" class="anchored" data-anchor-id="across-study-biases"><span class="header-section-number">16.2.2</span> Across-study biases</h3>
<p>Across-study biases occur if, for example, researchers <strong>selectively report</strong> certain types of findings or selectively publish certain types of findings (publication bias, as discussed in <a href="003-replication.html" class="quarto-xref"><span>chapter 3</span></a> and <a href="011-prereg.html" class="quarto-xref"><span>chapter 11</span></a>). Often, these across-study biases favor statistically significant positive results, which means the meta-analytic estimate based on those studies will be inflated relative to the true effect.</p>
<div class="callout callout-style-default callout-note callout-titled" title="accident report">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
accident report
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<section id="quantifying-publication-bias-in-the-social-sciences" class="level3 unnumbered callout-body-container callout-body">
<h3 class="unnumbered anchored" data-anchor-id="quantifying-publication-bias-in-the-social-sciences">Quantifying publication bias in the social sciences</h3>
<p>It’s typically very hard to quantify publication bias because you don’t know how many studies are out there in researchers’ “file drawers”—unpublished studies are by definition not available. But a recent study took advantage of a unique opportunity to try and quantify publication bias within a known pool of studies.</p>
<p>Time-sharing Experiments in the Social Sciences (TESS) is an innovative project that lets researchers apply to run experiments on nationally representative samples in the US. In 2014, <span class="citation" data-cites="franco2014">Franco, Malhotra, and Simonovits (<a href="#ref-franco2014" role="doc-biblioref">2014</a>)</span> and colleagues took advantage of this application process by examining the entire population of 221 studies conducted through TESS.</p>
<p>Using this information, Franco and colleagues examined the records of these studies to determine whether the researchers found statistically significant results, a mixture of statistically significant and nonsignificant results, or only nonsignificant results. Then, they examined the likelihood that these results were published in the scientific literature.</p>
<p>Over 60% of studies with statistically significant results were published, compared to a mere 25% of studies that produced only statistically nonsignificant results. This finding was important because it quantified how strong publication bias actually was, at least in one particular population of studies. This estimate may not be general: for example, perhaps TESS studies were easier to put in the file drawer because they cost nothing for the researchers to run. But even a lower level of publication bias can have a substantial effect on a meta-analysis, meaning that it is crucial to check for—and potentially, correct for—publication bias.</p>
</section>
</div>
</div>
<p>Like within-study biases, meta-analysts often try to mitigate across-study biases by being careful about what studies make it into the meta-analysis. Meta-analysts don’t only want to capture high-profile, published studies on their effect of interest but also studies published in low-profile journals and the so-called gray literature <span class="citation" data-cites="lefebvre2019searching">(i.e., unpublished dissertations and theses; <a href="#ref-lefebvre2019searching" role="doc-biblioref">Lefebvre et al. 2019</a>)</span>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;Evidence is mixed regarding whether including gray literature actually reduces across-study biases in meta-analysis <span class="citation" data-cites="tsuji2020addressing sapbe">(<a href="#ref-tsuji2020addressing" role="doc-biblioref">Tsuji et al. 2020</a>; <a href="#ref-sapbe" role="doc-biblioref">Mathur and VanderWeele 2021</a>)</span>, but it is still common practice to try to include this literature.</p></div></div><p>There are also statistical methods to help assess how robust the results may be to across-study biases. Among the most popular tools to assess and correct for publication bias is the <strong>funnel plot</strong> <span class="citation" data-cites="duval2000trim egger1997bias">(<a href="#ref-duval2000trim" role="doc-biblioref">Duval and Tweedie 2000</a>; <a href="#ref-egger1997bias" role="doc-biblioref">Egger et al. 1997</a>)</span>. A funnel plot shows the relationship between studies’ effect estimates and their precision (usually their standard error). These plots are called “funnel plots” because, if there is no publication bias, then as precision increases, the effects “funnel” toward the meta-analytic estimate. As the precision is smaller, they spread out more because of greater measurement error. <a href="#fig-meta-funnel-unbiased" class="quarto-xref">Figure&nbsp;<span>16.4</span></a>] is an example of one type of funnel plot <span class="citation" data-cites="sapb">(<a href="#ref-sapb" role="doc-biblioref">Mathur and VanderWeele 2020b</a>)</span> for a simulated meta-analysis of 100 studies with no publication bias.</p>
<div class="cell page-columns page-full" data-cap-location="margin">
<div class="cell-output-display page-columns page-full">
<div id="fig-meta-funnel-unbiased" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" alt="A plot showing a funnel-shaped distribution of observed effect sizes against their corresponding standard errors." data-cap-location="margin">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-meta-funnel-unbiased-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="016-meta_files/figure-html/fig-meta-funnel-unbiased-1.png" class="img-fluid figure-img" style="width:80.0%" alt="A plot showing a funnel-shaped distribution of observed effect sizes against their corresponding standard errors.">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-meta-funnel-unbiased-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.4: A significance funnel plot for a meta-analysis simulated to have no publication bias. Orange points: studies with <span class="math inline">\(p &lt; 0.05\)</span> and positive estimates. Grey points: studies with <span class="math inline">\(p\)</span> <span class="math inline">\(\ge\)</span> <span class="math inline">\(0.05\)</span> or negative estimates. Black diamond: random-effects estimate of <span class="math inline">\(\widehat{\mu}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="code">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
code
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For this plot, we use the <code>PublicationBias</code> package <span class="citation" data-cites="braginsky2023pubbias">(<a href="#ref-braginsky2023pubbias" role="doc-biblioref">Braginsky, Mathur, and VanderWeele 2023</a>)</span> and the <code>significance_funnel()</code> function. (An alternative function is the <code>metafor</code> function <code>funnel()</code>, which results in a more “classic” funnel plot.) We use our fitted model <code>re_model</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">significance_funnel</span>(<span class="at">yi =</span> re_model<span class="sc">$</span>yi, <span class="at">vi =</span> re_model<span class="sc">$</span>vi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because meta-analysis is such a well-established method, many of the relevant operations are “plug and play.”</p>
</div>
</div>
</div>
<div class="cell page-columns page-full" data-cap-location="margin">
<div class="cell-output-display page-columns page-full">
<div id="fig-meta-classic-funnel" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" alt="A plot showing an inverted funnel-shaped distribution of observed effect sizes against their corresponding standard errors." data-cap-location="margin">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-meta-classic-funnel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="016-meta_files/figure-html/fig-meta-classic-funnel-1.png" class="img-fluid figure-img" style="width:80.0%" alt="A plot showing an inverted funnel-shaped distribution of observed effect sizes against their corresponding standard errors.">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-meta-classic-funnel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.5: A classic funnel plot.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As implied by the “funnel” moniker, our plot looks a little like a funnel. Larger studies (those with smaller standard errors) cluster more closely around the mean of 0.34 than do smaller studies, but large and small studies alike have point estimates centered around the mean. That is, the funnel plot is symmetric.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;Classic funnel plots look more like <a href="#fig-meta-classic-funnel" class="quarto-xref">figure&nbsp;<span>16.5</span></a>). Our version is different in a couple of ways. Most prominently, we don’t have the vertical axis reversed (which we think is confusing). We also don’t have the left boundary highlighted, because we think folks don’t typically select for negative studies.</p></div></div><p>Not all funnel plots are symmetric! <a href="#fig-meta-funnel-biased" class="quarto-xref">figure&nbsp;<span>16.6</span></a> is what happens to our hypothetical meta-analysis if all studies with <span class="math inline">\(p&lt;0.05\)</span> and positive estimates are published, but only 10% of studies with <span class="math inline">\(p \ge 0.05\)</span> or with negative estimates are published. The introduction of publication bias dramatically inflates the pooled estimate from 0.34 to 1.15. Also, there appears to be a correlation between studies’ estimates and their standard errors, such that smaller studies tend to have larger estimates than do larger studies. This correlation is often called funnel plot asymmetry because the funnel plot starts to look like a right triangle rather than a funnel. Funnel plot asymmetry <em>can</em> be a diagnostic for publication bias, though it isn’t always a perfect indicator, as we’ll see in the next subsection.</p>
<div class="cell page-columns page-full" data-cap-location="margin">
<div class="cell-output-display page-columns page-full">
<div id="fig-meta-funnel-biased" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" alt="A plot showing a positively sloped linear distribution of observed effect sizes against their corresponding standard errors." data-cap-location="margin">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-meta-funnel-biased-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="016-meta_files/figure-html/fig-meta-funnel-biased-1.png" class="img-fluid figure-img" style="width:80.0%" alt="A plot showing a positively sloped linear distribution of observed effect sizes against their corresponding standard errors.">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-meta-funnel-biased-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.6: A significance funnel plot for the same simulated meta-analysis after publication bias has occurred. Orange points: studies with <span class="math inline">\(p &lt; 0.05\)</span> and positive estimates. Grey points: studies with <span class="math inline">\(p\)</span> <span class="math inline">\(\ge\)</span> <span class="math inline">\(0.05\)</span> or negative estimates. Black diamond: random-effects estimate of <span class="math inline">\(\widehat{\mu}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="across-study-bias-correction" class="level3 page-columns page-full" data-number="16.2.3">
<h3 data-number="16.2.3" class="anchored" data-anchor-id="across-study-bias-correction"><span class="header-section-number">16.2.3</span> Across-study bias correction</h3>
<p>How do we identify and correct bias across studies? Given that some forms of publication bias induce a correlation between studies’ point estimates and their standard errors, several popular statistical methods, such as trim-and-fill <span class="citation" data-cites="duval2000trim">(<a href="#ref-duval2000trim" role="doc-biblioref">Duval and Tweedie 2000</a>)</span> and Egger’s regression <span class="citation" data-cites="egger1997bias">(<a href="#ref-egger1997bias" role="doc-biblioref">Egger et al. 1997</a>)</span> are designed to quantify funnel plot asymmetry.</p>
<p>Funnel plot asymmetry does not always imply that there is publication bias, though. Nor does publication bias always cause funnel plot asymmetry. Sometimes funnel plot asymmetry is driven by genuine differences in the effects being studied in small and large studies <span class="citation" data-cites="egger1997bias lau2006case">(<a href="#ref-egger1997bias" role="doc-biblioref">Egger et al. 1997</a>; <a href="#ref-lau2006case" role="doc-biblioref">Lau et al. 2006</a>)</span>. For example, in a meta-analysis of intervention studies, if the most effective interventions are also the most expensive or difficult to implement, these highly effective interventions might be used primarily in the smallest studies (“small study effects”).</p>
<p>Funnel plots and related methods are best suited to detecting publication bias in which (1) small studies with large positive point estimates are more likely to be published than small studies with small or negative point estimates; and (2) the largest studies are published regardless of the magnitude of their point estimates. That model of publication bias is sometimes what is happening, but not always!</p>
<p>A more flexible approach for detecting publication bias uses <strong>selection models</strong>. These models can detect other forms of publication bias that funnel plots may not detect, such as publication bias that favors <em>significant</em> results. We won’t cover these methods in detail here, but we think they are a better approach to the question, along with related sensitivity analyses.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;High-level overviews of selection models are given in <span class="citation" data-cites="mcshane2016adjusting">McShane, Böckenholt, and Hansen (<a href="#ref-mcshane2016adjusting" role="doc-biblioref">2016</a>)</span> and <span class="citation" data-cites="smt">Maier, VanderWeele, and Mathur (<a href="#ref-smt" role="doc-biblioref">2022</a>)</span>. For more methodological detail, see <span class="citation" data-cites="hedges1984estimation">Hedges (<a href="#ref-hedges1984estimation" role="doc-biblioref">1984</a>)</span>, <span class="citation" data-cites="iyengar1988">Iyengar and Greenhouse (<a href="#ref-iyengar1988" role="doc-biblioref">1988</a>)</span>, and <span class="citation" data-cites="vevea1995">Vevea and Hedges (<a href="#ref-vevea1995" role="doc-biblioref">1995</a>)</span>. For a tutorial on fitting and interpreting selection models, see <span class="citation" data-cites="smt">Maier, VanderWeele, and Mathur (<a href="#ref-smt" role="doc-biblioref">2022</a>)</span>. For sensitivity analyses, see <span class="citation" data-cites="sapb">Mathur and VanderWeele (<a href="#ref-sapb" role="doc-biblioref">2020b</a>)</span>.</p></div></div><p>You may also have heard of “<span class="math inline">\(p\)</span>-methods” to detect across-study biases such as <span class="math inline">\(p\)</span>-curve and <span class="math inline">\(p\)</span>-uniform <span class="citation" data-cites="simonsohn2014p van2015meta">(<a href="#ref-simonsohn2014p" role="doc-biblioref">Simonsohn, Nelson, and Simmons 2014</a>; <a href="#ref-van2015meta" role="doc-biblioref">van Assen, Aert, and Wicherts 2015</a>)</span>. These methods essentially assess whether the significant <span class="math inline">\(p\)</span>-values “bunch up” just under 0.05, which is taken to indicate publication bias. These methods are increasingly popular in psychology and have their merits. However, they are actually simplified versions of selection models <span class="citation" data-cites="hedges1984estimation">(e.g., <a href="#ref-hedges1984estimation" role="doc-biblioref">Hedges 1984</a>)</span> that work only under considerably more restrictive settings than the original selection models <span class="citation" data-cites="mcshane2016adjusting">(for example, when there is not heterogeneity across studies; <a href="#ref-mcshane2016adjusting" role="doc-biblioref">McShane, Böckenholt, and Hansen 2016</a>)</span>. For this reason, it is usually (although not always) better to use selection models in place of the more restrictive <span class="math inline">\(p\)</span>-methods.</p>
<p>Going back to our running example, Paluck et al.&nbsp;used a regression-based approach to assess and correct for publication bias. This approach provided significant evidence of a relationship between the standard error and effect size (i.e., an asymmetric funnel plot). Again, this asymmetry could reflect publication bias or other sources of correlation between studies’ estimates and their standard errors. Paluck et al.&nbsp;also used this same regression-based approach to try to correct for potential publication bias. Results from this model indicated that the bias-corrected effect size estimate was close to zero. In other words, even though all studies estimated that intergroup contact decreased prejudice, it is still possible that there are unpublished studies that did not find this (or found that intergroup contact increased prejudice).</p>
<div class="callout callout-style-default callout-note callout-titled" title="accident report">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
accident report
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<section id="garbage-in-garbage-out-meta-analyzing-potentially-problematic-research" class="level3 unnumbered callout-body-container callout-body">
<h3 class="unnumbered anchored" data-anchor-id="garbage-in-garbage-out-meta-analyzing-potentially-problematic-research">Garbage in, garbage out? Meta-analyzing potentially problematic research</h3>
<p>Botox can help eliminate wrinkles. But some researchers have suggested that, when used to paralyze the muscles associated with frowning, Botox may also help treat clinical depression. As surprising as this claim may sound, a quick examination of the literature would lead many to conclude that this treatment works. Studies that randomly assign depressed patients to receive either Botox or saline injections do indeed find that Botox recipients show decreased depression. And when you combine all available evidence in a meta-analysis, you find that this effect is quite large: <em>d</em> = 0.83, 95% CI [0.52, 1.14].</p>
<p>As <span class="citation" data-cites="coles2019does">Coles et al. (<a href="#ref-coles2019does" role="doc-biblioref">2019</a>)</span> argued though, this estimated effect may be impacted by both within- and between-study bias. First, participants are not supposed to know whether they have been randomly assigned to receive Botox or a control saline injections. But only one of these treatments leads the upper half of your face to be paralyzed! After a couple weeks, you’re pretty likely to know whether you received the Botox treatment or control saline injection. Thus, the apparent effect of Botox on depression could instead be a placebo effect.</p>
<p>Second, only 50% of the outcomes that researchers measured were reported in the final publications, raising concerns about selective reporting. Perhaps researchers examining the effects of Botox on depression only reported the measures that showed a positive effect, not the ones that didn’t.</p>
<p>Taken together, these two criticisms suggest that, despite the impressive meta-analytic estimate, the effect of Botox on depression is far from certain.</p>
</section>
</div>
</div>
</section>
</section>
<section id="chapter-summary-meta-analysis" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="chapter-summary-meta-analysis"><span class="header-section-number">16.3</span> Chapter summary: Meta-analysis</h2>
<p>Taken together, Paluck and colleagues’ use of meta-analysis provided several important insights that would have been easy to miss in a nonquantitative review. First, despite a preponderance of nonsignificant findings, intergroup contact interventions were estimated to decrease prejudice by on average 0.4 standard deviations. On the other hand, there was considerable heterogeneity in intergroup contact effects, suggesting important moderators of the effectiveness of these interventions. And finally, publication bias was a substantial concern, indicating a need for follow-up research using a registered report format that will be published regardless of whether the outcome is positive (<a href="011-prereg.html" class="quarto-xref"><span>chapter 11</span></a>).</p>
<p>Overall, meta-analysis is a key technique for aggregating evidence across studies. Meta-analysis allows researchers to move beyond the bias of naive techniques like vote counting and toward a more quantitative summary of an experimental effect. Unfortunately, a meta-analysis is only as good as the literature it’s based on, so the aspiring meta-analyst must be aware of both within- and between-study biases!</p>
<div class="callout callout-style-default callout-note callout-titled" title="discussion questions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
discussion questions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Imagine that you read the following result in the abstract of a meta-analysis: “In 83 randomized studies of middle school children, replacing one hour of class time with mindfulness meditation significantly improved standardized test scores (standardized mean difference <span class="math inline">\(\widehat{\mu} = 0.05\)</span>; 95% confidence interval: [<span class="math inline">\(0.01, 0.09\)</span>]; <span class="math inline">\(p&lt;0.05\)</span>).” Why is this a problematic way to report on meta-analysis results? Suggest a better sentence to replace this one.</p></li>
<li><p>As you read the rest of the meta-analysis, you find that the authors conclude that “these findings demonstrate robust benefits of meditation for children, suggesting that test scores improve even when the meditation is introduced as a replacement for normal class time.” You recall that the heterogeneity estimate was <span class="math inline">\(\widehat{\tau} = 0.90\)</span>. Do you think that this result regarding the heterogeneity tends to support, or rather tends to undermine, the concluding sentence of the meta-analysis? Why?</p></li>
<li><p>What kinds of within-study biases would concern you in the meta-analysis described in the prior two questions? How might you assess the credibility of the meta-analyzed studies and of the meta-analysis as a whole in light of these possible biases?</p></li>
<li><p>Imagine you conduct a meta-analysis on a literature in which statistically significant results in either direction are much more likely to be published that nonsignificant results. Draw the funnel plot you would expect to see. Is the plot symmetric or asymmetric?</p></li>
<li><p>Why do you think small studies receive more weight in random-effects meta-analysis than in fixed-effects meta-analysis? Can you see why this is true mathematically based on the equations given above, and can you also explain the intuition in simple language?</p></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="readings">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
readings
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>A nice, free textbook with lots of good code examples: Harrer, Mathias, Pim Cuijpers, Furukawa Toshi A, and David D. Ebert <span class="citation" data-cites="harrer2021">(<a href="#ref-harrer2021" role="doc-biblioref">2021</a>)</span>. <em>Doing Meta-Analysis with R: A Hands-On Guide</em>. Chapman &amp; Hall/CRC Press. Available free online at <a href="https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R" class="uri">https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R</a>.</li>
</ul>
</div>
</div>
</div>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-allport1954nature" class="csl-entry" role="listitem">
Allport, Gordon Willard, Kenneth Clark, and Thomas Pettigrew. 1954. <em>The Nature of Prejudice</em>. Addison-Wesley.
</div>
<div id="ref-boisjoly2006empathy" class="csl-entry" role="listitem">
Boisjoly, Johanne, Greg J Duncan, Michael Kremer, Dan M Levy, and Jacque Eccles. 2006. <span>“Empathy or Antipathy? The Impact of Diversity.”</span> <em>American Economic Review</em> 96 (5): 1890–1905.
</div>
<div id="ref-borenstein2021introduction" class="csl-entry" role="listitem">
Borenstein, Michael, Larry V Hedges, Julian P T Higgins, and Hannah R Rothstein. 2021. <em>Introduction to Meta-Analysis</em>. John Wiley &amp; Sons.
</div>
<div id="ref-braginsky2023pubbias" class="csl-entry" role="listitem">
Braginsky, Mika, Maya Mathur, and Tyler J. VanderWeele. 2023. <em><span>PublicationBias</span>: Sensitivity Analysis for Publication Bias in Meta-Analyses</em>. <a href="https://CRAN.R-project.org/package=PublicationBias">https://CRAN.R-project.org/package=PublicationBias</a>.
</div>
<div id="ref-brockwell2001comparison" class="csl-entry" role="listitem">
Brockwell, Sarah E, and Ian R Gordon. 2001. <span>“A Comparison of Statistical Methods for Meta-Analysis.”</span> <em>Statistics in Medicine</em> 20 (6): 825–40.
</div>
<div id="ref-clunies1989changing" class="csl-entry" role="listitem">
Clunies-Ross, Graham, and Kris O’Meara. 1989. <span>“Changing the Attitudes of Students <span class="nocase">towards</span> Peers with Disabilities.”</span> <em>Australian Psychologist</em> 24 (2): 273–84.
</div>
<div id="ref-coles2019does" class="csl-entry" role="listitem">
Coles, Nicholas A, Jeff T Larsen, Joyce Kuribayashi, and Ashley Kuelz. 2019. <span>“Does Blocking Facial Feedback via Botulinum Toxin Injections Decrease Depression? A Critical Review and Meta-Analysis.”</span> <em>Emotion Review</em> 11 (4): 294–309.
</div>
<div id="ref-cooper2009relative" class="csl-entry" role="listitem">
Cooper, Harris, and Erika A Patall. 2009. <span>“The Relative Benefits of Meta-Analysis Conducted with Individual Participant Data Versus Aggregated Data.”</span> <em>Psychological Methods</em> 14 (2): 165–76. <a href="https://doi.org/10.1037/a0015565">https://doi.org/10.1037/a0015565</a>.
</div>
<div id="ref-dersimonian1986meta" class="csl-entry" role="listitem">
DerSimonian, Rebecca, and Nan Laird. 1986. <span>“Meta-Analysis in Clinical Trials.”</span> <em>Controlled Clinical Trials</em> 7 (3): 177–88.
</div>
<div id="ref-duval2000trim" class="csl-entry" role="listitem">
Duval, Sue, and Richard Tweedie. 2000. <span>“Trim and Fill: A Simple Funnel-Plot–Based Method of Testing and Adjusting for Publication Bias in Meta-Analysis.”</span> <em>Biometrics</em> 56 (2): 455–63. <a href="https://doi.org/10.1111/j.0006-341X.2000.00455.x">https://doi.org/10.1111/j.0006-341X.2000.00455.x</a>.
</div>
<div id="ref-egger1997bias" class="csl-entry" role="listitem">
Egger, Matthias, George Davey Smith, Martin Schneider, and Christoph Minder. 1997. <span>“Bias in Meta-Analysis Detected by a Simple, Graphical Test.”</span> <em>British Medical Journal</em> 315 (7109): 629–34. <a href="https://doi.org/10.1136/bmj.315.7109.629">https://doi.org/10.1136/bmj.315.7109.629</a>.
</div>
<div id="ref-franco2014" class="csl-entry" role="listitem">
Franco, Annie, Neil Malhotra, and Gabor Simonovits. 2014. <span>“Publication Bias in the Social Sciences: Unlocking the File Drawer.”</span> <em>Science</em> 345 (6203): 1502–5. <a href="https://doi.org/10.1126/science.1255484">https://doi.org/10.1126/science.1255484</a>.
</div>
<div id="ref-goh2016mini" class="csl-entry" role="listitem">
Goh, Jin X, Judith A Hall, and Robert Rosenthal. 2016. <span>“Mini Meta-Analysis of Your Own Studies: Some Arguments on Why and a Primer on How.”</span> <em>Social and Personality Psychology Compass</em> 10 (10): 535–49.
</div>
<div id="ref-goldstein2008room" class="csl-entry" role="listitem">
Goldstein, Noah J, Robert B Cialdini, and Vladas Griskevicius. 2008. <span>“A Room with a Viewpoint: Using Social Norms to Motivate Environmental Conservation in Hotels.”</span> <em>Journal of Consumer Research</em> 35 (3): 472–82.
</div>
<div id="ref-grant2009typology" class="csl-entry" role="listitem">
Grant, Maria J, and Andrew Booth. 2009. <span>“A Typology of Reviews: An Analysis of 14 Review Types and Associated Methodologies.”</span> <em>Health Information &amp; Libraries Journal</em> 26 (2): 91–108.
</div>
<div id="ref-harrer2021" class="csl-entry" role="listitem">
Harrer, Mathias, Pim Cuijpers, Furukawa Toshi A, and David D Ebert. 2021. <em>Doing Meta-Analysis with <span>R</span>: A Hands-on Guide</em>. Chapman &amp; Hall/CRC Press.
</div>
<div id="ref-hedges1984estimation" class="csl-entry" role="listitem">
Hedges, Larry V. 1984. <span>“Estimation of Effect Size <span class="nocase">under</span> Nonrandom Sampling: The Effects of Censoring Studies Yielding Statistically Insignificant Mean Differences.”</span> <em>Journal of Educational Statistics</em> 9 (1): 61–85. <a href="https://doi.org/10.3102/10769986009001061">https://doi.org/10.3102/10769986009001061</a>.
</div>
<div id="ref-hedges2010robust" class="csl-entry" role="listitem">
Hedges, Larry V, Elizabeth Tipton, and Matthew C Johnson. 2010. <span>“Robust Variance Estimation in Meta-Regression with Dependent Effect Size Estimates.”</span> <em>Research Synthesis Methods</em> 1 (1): 39–65.
</div>
<div id="ref-iyengar1988" class="csl-entry" role="listitem">
Iyengar, Satish, and Joel B Greenhouse. 1988. <span>“Selection Models and the File Drawer Problem.”</span> <em>Statistical Science</em>, 109–17.
</div>
<div id="ref-lau2006case" class="csl-entry" role="listitem">
Lau, Joseph, John P. A. Ioannidis, Norma Terrin, Christopher H Schmid, and Ingram Olkin. 2006. <span>“The Case of the Misleading Funnel Plot.”</span> <em>British Medical Journal</em> 333 (7568): 597–600. <a href="https://doi.org/10.1136/bmj.333.7568.597">https://doi.org/10.1136/bmj.333.7568.597</a>.
</div>
<div id="ref-lefebvre2019searching" class="csl-entry" role="listitem">
Lefebvre, Carol, Julie Glanville, Simon Briscoe, Anne Littlewood, Chris Marshall, Maria-Inti Metzendorf, Anna Noel-Storr, et al. 2019. <span>“Searching for and Selecting Studies.”</span> In <em>Cochrane Handbook for Systematic Reviews of Interventions</em>, edited by Julian P T Higgins, J. Thomas, M. Chandler, T. Cumpston, M. J. Page Li, and V. A. Welch, 67–107. Wiley-Blackwell. <a href="https://doi.org/10.1002/9781119536604.ch4">https://doi.org/10.1002/9781119536604.ch4</a>.
</div>
<div id="ref-smt" class="csl-entry" role="listitem">
Maier, Maximilian, Tyler J VanderWeele, and Maya B Mathur. 2022. <span>“Using Selection Models to Assess Sensitivity to Publication Bias: A Tutorial and Call for More Routine Use.”</span> <em>Campbell Systematic Reviews</em> 18 (3): e1256.
</div>
<div id="ref-mathur_mam" class="csl-entry" role="listitem">
Mathur, Maya B, and Tyler J VanderWeele. 2019. <span>“New Metrics for Meta-Analyses of Heterogeneous Effects.”</span> <em>Statistics in Medicine</em> 38 (8): 1336–42.
</div>
<div id="ref-npphat" class="csl-entry" role="listitem">
———. 2020a. <span>“Robust Metrics and Sensitivity Analyses for Meta-Analyses of Heterogeneous Effects.”</span> <em>Epidemiology</em> 31 (3): 356–58.
</div>
<div id="ref-sapb" class="csl-entry" role="listitem">
———. 2020b. <span>“Sensitivity Analysis for Publication Bias in Meta-Analyses.”</span> <em>Journal of the Royal Statistical Society: Series C</em> 5 (69): 1091–1119.
</div>
<div id="ref-sapbe" class="csl-entry" role="listitem">
———. 2021. <span>“Estimating Publication Bias in Meta-Analyses of Peer-Reviewed Studies: A Meta-Meta-Analysis <span class="nocase">across</span> Disciplines and Journal Tiers.”</span> <em>Research Synthesis Methods</em> 12 (2): 176–91.
</div>
<div id="ref-art" class="csl-entry" role="listitem">
———. 2022. <span>“Methods to Address Confounding and Other Biases in Meta-Analyses: Review and Recommendations.”</span> <em>Annual Review of Public Health</em> 1 (43).
</div>
<div id="ref-mcshane2016adjusting" class="csl-entry" role="listitem">
McShane, Blakeley B, Ulf Böckenholt, and Karsten T Hansen. 2016. <span>“Adjusting for Publication Bias in Meta-Analysis: An Evaluation of Selection Methods and Some Cautionary Notes.”</span> <em>Perspectives on Psychological Science</em> 11 (5): 730–49. <a href="https://doi.org/10.1177/1745691616662243">https://doi.org/10.1177/1745691616662243</a>.
</div>
<div id="ref-mcshane2017statistical" class="csl-entry" role="listitem">
McShane, Blakeley B, and David Gal. 2017. <span>“Statistical Significance and the Dichotomization of Evidence.”</span> <em>Journal of the American Statistical Association</em> 112 (519): 885–95. <a href="https://doi.org/10.1080/01621459.2017.1289846">https://doi.org/10.1080/01621459.2017.1289846</a>.
</div>
<div id="ref-nelson1986interpretation" class="csl-entry" role="listitem">
Nelson, Nanette, Robert Rosenthal, and Ralph L Rosnow. 1986. <span>“Interpretation of Significance Levels and Effect Sizes by Psychological Researchers.”</span> <em>American Psychologist</em> 41 (11): 1299–1301. <a href="https://doi.org/10.1037/0003-066X.41.11.1299">https://doi.org/10.1037/0003-066X.41.11.1299</a>.
</div>
<div id="ref-paluck2019contact" class="csl-entry" role="listitem">
Paluck, Elizabeth Levy, Seth A Green, and Donald P Green. 2019. <span>“The Contact Hypothesis Re-Evaluated.”</span> <em>Behavioural Public Policy</em> 3 (2): 129–58.
</div>
<div id="ref-pustejovsky2021meta" class="csl-entry" role="listitem">
Pustejovsky, James E, and Elizabeth Tipton. 2021. <span>“Meta-Analysis with Robust Variance Estimation: Expanding the Range of Working Models.”</span> <em>Prevention Science</em> 23 (2022): 425–38. <a href="https://doi.org/10.1007/s11121-021-01246-3">https://doi.org/10.1007/s11121-021-01246-3</a>.
</div>
<div id="ref-riley2011interpretation" class="csl-entry" role="listitem">
Riley, Richard D, Julian P T Higgins, and Jonathan J Deeks. 2011. <span>“Interpretation of Random Effects Meta-Analyses.”</span> <em>British Medical Journal</em> 342.
</div>
<div id="ref-scheibehenne2016" class="csl-entry" role="listitem">
Scheibehenne, Benjamin, Tahira Jamil, and Eric-Jan Wagenmakers. 2016. <span>“Bayesian Evidence Synthesis Can Reconcile Seemingly Inconsistent Results: The Case of Hotel Towel Reuse.”</span> <em>Psychological Science</em> 27 (7): 1043–46.
</div>
<div id="ref-simonsohn2014p" class="csl-entry" role="listitem">
Simonsohn, Uri, Leif D Nelson, and Joseph P Simmons. 2014. <span>“P-Curve: A Key to the File-Drawer.”</span> <em>Journal of Experimental Psychology: General</em> 143 (2): 534–47.
</div>
<div id="ref-sterne2016robins" class="csl-entry" role="listitem">
Sterne, Jonathan A C, Miguel A Hernán, Barnaby C Reeves, Jelena Savović, Nancy D Berkman, Meera Viswanathan, David Henry, et al. 2016. <span>“<span>ROBINS-I</span>: A Tool for Assessing Risk of Bias in Non-Randomised Studies of Interventions.”</span> <em>British Medical Journal</em> 355. <a href="https://doi.org/doi.org/10.1136/bmj.i4919">https://doi.org/doi.org/10.1136/bmj.i4919</a>.
</div>
<div id="ref-thompson2002should" class="csl-entry" role="listitem">
Thompson, Simon G, and Julian P T Higgins. 2002. <span>“How Should Meta-Regression Analyses Be Undertaken and Interpreted?”</span> <em>Statistics in Medicine</em> 21 (11): 1559–73.
</div>
<div id="ref-tipton2015small" class="csl-entry" role="listitem">
Tipton, Elizabeth. 2015. <span>“Small Sample Adjustments for Robust Variance Estimation with Meta-Regression.”</span> <em>Psychological Methods</em> 20 (3): 375–93. <a href="https://doi.org/10.1037/met0000011">https://doi.org/10.1037/met0000011</a>.
</div>
<div id="ref-tsuji2020addressing" class="csl-entry" role="listitem">
Tsuji, Sho, Alejandrina Cristia, Michael C Frank, and Christina Bergmann. 2020. <span>“Addressing Publication Bias in Meta-Analysis.”</span> <em>Zeitschrift f<span>ü</span>r Psychologie</em> 228 (1): 50–61. <a href="https://doi.org/10.1027/2151-2604/a000393">https://doi.org/10.1027/2151-2604/a000393</a>.
</div>
<div id="ref-van2015meta" class="csl-entry" role="listitem">
van Assen, Marcel A L M, Robbie van Aert, and Jelte M Wicherts. 2015. <span>“Meta-Analysis Using Effect Size Distributions of Only Statistically Significant Studies.”</span> <em>Psychological Methods</em> 20 (3): 293–309.
</div>
<div id="ref-vevea1995" class="csl-entry" role="listitem">
Vevea, Jack L, and Larry V Hedges. 1995. <span>“A General Linear Model for Estimating Effect Size in the Presence of Publication Bias.”</span> <em>Psychometrika</em> 60 (3): 419–35.
</div>
<div id="ref-viechtbauer2010" class="csl-entry" role="listitem">
Viechtbauer, Wolfgang. 2010. <span>“Conducting Meta-Analyses in <span>R</span> with the <span class="nocase">metafor</span> Package.”</span> <em>Journal of Statistical Software</em> 36 (3): 1–48. <a href="https://doi.org/10.18637/jss.v036.i03">https://doi.org/10.18637/jss.v036.i03</a>.
</div>
<div id="ref-wang2019simple" class="csl-entry" role="listitem">
Wang, Chia-Chun, and Wen-Chung Lee. 2019. <span>“A Simple Method to Estimate Prediction Intervals and Predictive Distributions: Summarizing Meta-Analyses <span class="nocase">beyond</span> Means and Confidence Intervals.”</span> <em>Research Synthesis Methods</em> 10 (2): 255–66.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./015-viz.html" class="pagination-link" aria-label="Visualization">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Visualization</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./017-conclusion.html" class="pagination-link" aria-label="Conclusion">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Conclusion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/langcog/experimentology/blob/main/016-meta.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/langcog/experimentology/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>