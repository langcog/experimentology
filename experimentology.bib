%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Mike Frank at 2021-08-21 15:52:02 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@article{fisher1956,
	author = {Fisher, Ronald A},
	date-added = {2021-08-21 15:44:58 -0700},
	date-modified = {2021-08-21 15:45:02 -0700},
	journal = {The world of mathematics},
	number = {part 8},
	pages = {1514--1521},
	publisher = {George Allen \& Unwin Sydney},
	title = {Mathematics of a lady tasting tea},
	volume = {3},
	year = {1956}}

@article{frank2016b,
	author = {Frank, Michael C and Sugarman, Elise and Horowitz, Alexandra C and Lewis, Molly L and Yurovsky, Daniel},
	date-added = {2021-08-21 10:09:21 -0700},
	date-modified = {2021-08-21 10:09:27 -0700},
	journal = {Journal of Cognition and Development},
	number = {1},
	pages = {1--17},
	publisher = {Taylor \& Francis},
	title = {Using tablets to collect data from young children},
	volume = {17},
	year = {2016}}

@article{marchman2008,
	author = {Marchman, Virginia A and Fernald, Anne},
	date-added = {2021-08-21 10:08:01 -0700},
	date-modified = {2021-08-21 10:08:03 -0700},
	journal = {Developmental science},
	number = {3},
	pages = {F9--F16},
	publisher = {Wiley Online Library},
	title = {Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood},
	volume = {11},
	year = {2008}}

@book{embretson2013,
	author = {Embretson, Susan E and Reise, Steven P},
	date-added = {2021-08-21 10:07:31 -0700},
	date-modified = {2021-08-21 10:07:33 -0700},
	publisher = {Psychology Press},
	title = {Item response theory},
	year = {2013}}

@article{bornstein1998,
	author = {Bornstein, Marc H and Haynes, O Maurice},
	date-added = {2021-08-21 10:06:57 -0700},
	date-modified = {2021-08-21 10:07:00 -0700},
	journal = {Child development},
	number = {3},
	pages = {654--671},
	publisher = {Wiley Online Library},
	title = {Vocabulary competence in early childhood: Measurement, latent construct, and predictive validity},
	volume = {69},
	year = {1998}}

@article{frank2017,
	author = {Frank, Michael C and Braginsky, Mika and Yurovsky, Daniel and Marchman, Virginia A},
	date-added = {2021-08-21 10:06:29 -0700},
	date-modified = {2021-08-21 10:06:33 -0700},
	journal = {Journal of child language},
	number = {3},
	pages = {677--694},
	publisher = {Cambridge University Press},
	title = {Wordbank: An open repository for developmental vocabulary data},
	volume = {44},
	year = {2017}}

@book{maxwell2017,
	author = {Maxwell, Scott E and Delaney, Harold D and Kelley, Ken},
	date-added = {2021-08-21 09:38:13 -0700},
	date-modified = {2021-08-21 09:38:15 -0700},
	publisher = {Routledge},
	title = {Designing experiments and analyzing data: A model comparison perspective},
	year = {2017}}

@article{dwan2008,
	author = {Dwan, Kerry and Altman, Douglas G and Arnaiz, Juan A and Bloom, Jill and Chan, An-Wen and Cronin, Eugenia and Decullier, Evelyne and Easterbrook, Philippa J and Von Elm, Erik and Gamble, Carrol and others},
	date-added = {2021-08-21 09:24:03 -0700},
	date-modified = {2021-08-21 09:24:05 -0700},
	journal = {PloS one},
	number = {8},
	pages = {e3081},
	publisher = {Public Library of Science San Francisco, USA},
	title = {Systematic review of the empirical evidence of study publication bias and outcome reporting bias},
	volume = {3},
	year = {2008}}

@article{herzog1981,
	author = {Herzog, A Regula and Bachman, Jerald G},
	date-added = {2021-08-21 09:19:35 -0700},
	date-modified = {2021-08-21 09:19:53 -0700},
	journal = {Public opinion quarterly},
	number = {4},
	pages = {549--559},
	publisher = {Oxford University Press},
	title = {Effects of questionnaire length on response quality},
	volume = {45},
	year = {1981}}

@article{johnson2017,
	author = {Johnson, David J and Hopwood, Christopher J and Cesario, Joseph and Pleskac, Timothy J},
	date-added = {2021-08-20 15:57:45 -0700},
	date-modified = {2021-08-20 15:57:51 -0700},
	journal = {Social Psychological and Personality Science},
	number = {4},
	pages = {413--423},
	publisher = {Sage Publications Sage CA: Los Angeles, CA},
	title = {Advancing research on cognitive processes in social and personality psychology: A hierarchical drift diffusion model primer},
	volume = {8},
	year = {2017}}

@article{greenwald1998,
	author = {Greenwald, Anthony G and McGhee, Debbie E and Schwartz, Jordan LK},
	date-added = {2021-08-20 15:48:08 -0700},
	date-modified = {2021-08-20 15:48:12 -0700},
	journal = {Journal of personality and social psychology},
	number = {6},
	pages = {1464},
	publisher = {American Psychological Association},
	title = {Measuring individual differences in implicit cognition: the implicit association test.},
	volume = {74},
	year = {1998}}

@article{elson2014,
	author = {Malte Elson and M. Rohangis Mohseni and Johannes Breuer and Michael Scharkow and Thorsten Quandt},
	date-added = {2021-08-20 14:24:03 -0700},
	date-modified = {2021-08-20 14:24:06 -0700},
	doi = {10.1037/a0035569},
	journal = {Psychological Assessment},
	month = {jun},
	number = {2},
	pages = {419--432},
	publisher = {American Psychological Association ({APA})},
	title = {Press {CRTT} to measure aggressive behavior: The unstandardized use of the competitive reaction time task in aggression research.},
	url = {https://doi.org/10.1037%2Fa0035569},
	volume = {26},
	year = 2014,
	Bdsk-Url-1 = {https://doi.org/10.1037%2Fa0035569},
	Bdsk-Url-2 = {https://doi.org/10.1037/a0035569}}

@article{rumelhart1982,
	author = {Rumelhart, David E and Norman, Donald A},
	date-added = {2021-08-20 13:52:57 -0700},
	date-modified = {2021-08-20 13:53:02 -0700},
	journal = {Cognitive science},
	number = {1},
	pages = {1--36},
	publisher = {Wiley Online Library},
	title = {Simulating a skilled typist: A study of skilled cognitive-motor performance},
	volume = {6},
	year = {1982}}

@article{kirsh2010,
	author = {Kirsh, David},
	date-added = {2021-08-20 13:51:18 -0700},
	date-modified = {2021-08-20 13:51:24 -0700},
	title = {Thinking with the body},
	year = {2010}}

@article{donders1969,
	author = {Donders, Franciscus Cornelis},
	date-added = {2021-08-20 13:41:28 -0700},
	date-modified = {2021-08-20 13:41:36 -0700},
	journal = {Acta psychologica},
	pages = {412--431},
	publisher = {Elsevier},
	title = {On the speed of mental processes},
	volume = {30},
	year = {1969}}

@article{payne2001,
	author = {Payne, B Keith},
	date-added = {2021-08-20 13:26:52 -0700},
	date-modified = {2021-08-20 13:26:56 -0700},
	journal = {Journal of personality and social psychology},
	number = {2},
	pages = {181},
	publisher = {American Psychological Association},
	title = {Prejudice and perception: the role of automatic and controlled processes in misperceiving a weapon.},
	volume = {81},
	year = {2001}}

@article{fiser2001,
	author = {Fiser, J{\'o}zsef and Aslin, Richard N},
	date-added = {2021-08-20 13:24:30 -0700},
	date-modified = {2021-08-20 13:24:32 -0700},
	journal = {Psychological science},
	number = {6},
	pages = {499--504},
	publisher = {SAGE Publications Sage CA: Los Angeles, CA},
	title = {Unsupervised statistical learning of higher-order spatial structures from visual scenes},
	volume = {12},
	year = {2001}}

@article{ratcliff2004,
	author = {Ratcliff, Roger and Gomez, Pablo and McKoon, Gail},
	date-added = {2021-08-20 13:21:30 -0700},
	date-modified = {2021-08-20 13:21:32 -0700},
	journal = {Psychological review},
	number = {1},
	pages = {159},
	publisher = {American Psychological Association},
	title = {A diffusion model account of the lexical decision task.},
	volume = {111},
	year = {2004}}

@article{warren2002,
	author = {Warren, Tessa and Gibson, Edward},
	date-added = {2021-08-20 13:20:51 -0700},
	date-modified = {2021-08-20 13:20:55 -0700},
	journal = {Cognition},
	number = {1},
	pages = {79--112},
	publisher = {Elsevier},
	title = {The influence of referential processing on sentence complexity},
	volume = {85},
	year = {2002}}

@article{voss2013,
	author = {Andreas Voss and Markus Nagler and Veronika Lerche},
	date-added = {2021-08-20 09:47:05 -0700},
	date-modified = {2021-08-20 09:47:08 -0700},
	doi = {10.1027/1618-3169/a000218},
	journal = {Experimental Psychology},
	month = {jan},
	number = {6},
	pages = {385--402},
	publisher = {Hogrefe Publishing Group},
	title = {Diffusion Models in Experimental Psychology},
	url = {https://doi.org/10.1027%2F1618-3169%2Fa000218},
	volume = {60},
	year = 2013,
	Bdsk-Url-1 = {https://doi.org/10.1027%2F1618-3169%2Fa000218},
	Bdsk-Url-2 = {https://doi.org/10.1027/1618-3169/a000218}}

@article{shafto2012,
	author = {Shafto, Patrick and Goodman, Noah D and Frank, Michael C},
	date-added = {2021-08-20 09:45:05 -0700},
	date-modified = {2021-08-20 09:45:07 -0700},
	journal = {Perspectives on Psychological Science},
	number = {4},
	pages = {341--351},
	publisher = {Sage Publications Sage CA: Los Angeles, CA},
	title = {Learning from others: The consequences of psychological reasoning for human learning},
	volume = {7},
	year = {2012}}

@article{kane1992,
	author = {Kane, Michael T},
	date-added = {2021-08-20 09:30:10 -0700},
	date-modified = {2021-08-20 09:30:42 -0700},
	journal = {Psychological Bulletin},
	number = {3},
	pages = {527},
	publisher = {American Psychological Association},
	title = {An argument-based approach to validity},
	volume = {112},
	year = {1992}}

@article{ross1989,
	author = {Ross, Hildy S and Lollis, Susan P},
	date-added = {2021-08-19 11:57:25 -0700},
	date-modified = {2021-08-19 11:57:27 -0700},
	journal = {Child Development},
	pages = {1082--1091},
	publisher = {JSTOR},
	title = {A social relations analysis of toddler peer relationships},
	year = {1989}}

@article{lieberman1999,
	author = {Lieberman, Joel D and Solomon, Sheldon and Greenberg, Jeff and McGregor, Holly A},
	date-added = {2021-08-19 11:55:51 -0700},
	date-modified = {2021-08-19 11:55:53 -0700},
	journal = {Aggressive Behavior: Official Journal of the International Society for Research on Aggression},
	number = {5},
	pages = {331--348},
	publisher = {Wiley Online Library},
	title = {A hot new way to measure aggression: Hot sauce allocation},
	volume = {25},
	year = {1999}}

@article{nieuwland2008,
	author = {Nieuwland, Mante S and Kuperberg, Gina R},
	date-added = {2021-08-18 21:29:12 -0700},
	date-modified = {2021-08-18 21:29:16 -0700},
	journal = {Psychological Science},
	number = {12},
	pages = {1213--1218},
	publisher = {SAGE Publications Sage CA: Los Angeles, CA},
	title = {When the truth is not too hard to handle: An event-related potential study on the pragmatics of negation},
	volume = {19},
	year = {2008}}

@article{krosnick2010,
	author = {Krosnick, Jon A and Presser, Stanley},
	date-added = {2021-08-18 20:36:13 -0700},
	date-modified = {2021-08-18 20:36:17 -0700},
	journal = {Handbook of Survey Research},
	pages = {263},
	publisher = {Emerald Group Publishing},
	title = {Question and Questionnaire Design},
	year = {2010}}

@article{flake2020,
	author = {Flake, Jessica Kay and Fried, Eiko I},
	date-added = {2021-08-18 16:26:48 -0700},
	date-modified = {2021-08-18 16:26:53 -0700},
	journal = {Advances in Methods and Practices in Psychological Science},
	number = {4},
	pages = {456--465},
	publisher = {Sage Publications Sage CA: Los Angeles, CA},
	title = {Measurement schmeasurement: Questionable measurement practices and how to avoid them},
	volume = {3},
	year = {2020}}

@article{sijtsma2009,
	author = {Sijtsma, Klaas},
	date-added = {2021-08-18 16:01:47 -0700},
	date-modified = {2021-08-18 16:01:50 -0700},
	journal = {Psychometrika},
	number = {1},
	pages = {107},
	publisher = {Springer},
	title = {On the use, the misuse, and the very limited usefulness of Cronbach's alpha},
	volume = {74},
	year = {2009}}

@article{zuo2019,
	author = {Xi-Nian Zuo and Ting Xu and Michael Peter Milham},
	date-added = {2021-08-18 15:37:38 -0700},
	date-modified = {2021-08-18 15:37:40 -0700},
	doi = {10.1038/s41562-019-0655-x},
	journal = {Nature Human Behaviour},
	month = {jun},
	number = {8},
	pages = {768--771},
	publisher = {Springer Science and Business Media {LLC}},
	title = {Harnessing reliability for neuroscience research},
	url = {https://doi.org/10.1038%2Fs41562-019-0655-x},
	volume = {3},
	year = 2019,
	Bdsk-Url-1 = {https://doi.org/10.1038%2Fs41562-019-0655-x},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41562-019-0655-x}}

@article{hedge2018,
	author = {Hedge, Craig and Powell, Georgina and Sumner, Petroc},
	date-added = {2021-08-18 15:36:59 -0700},
	date-modified = {2021-08-18 15:37:01 -0700},
	journal = {Behavior research methods},
	number = {3},
	pages = {1166--1186},
	publisher = {Springer},
	title = {The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences},
	volume = {50},
	year = {2018}}

@article{rodgers1988,
	author = {Lee Rodgers, Joseph and Nicewander, W Alan},
	date-added = {2021-08-18 14:01:01 -0700},
	date-modified = {2021-08-18 14:01:08 -0700},
	journal = {The American Statistician},
	number = {1},
	pages = {59--66},
	publisher = {Taylor \& Francis},
	title = {Thirteen ways to look at the correlation coefficient},
	volume = {42},
	year = {1988}}

@article{brandmaier2018,
	author = {Brandmaier, Andreas M and Wenger, Elisabeth and Bodammer, Nils C and K{\"u}hn, Simone and Raz, Naftali and Lindenberger, Ulman},
	date-added = {2021-08-18 13:02:39 -0700},
	date-modified = {2021-08-18 13:02:53 -0700},
	journal = {Elife},
	pages = {e35718},
	publisher = {eLife Sciences Publications Limited},
	title = {Assessing reliability in neuroimaging research through intra-class effect decomposition (ICED)},
	volume = {7},
	year = {2018}}

@book{xie2015,
	address = {Boca Raton, Florida},
	author = {Yihui Xie},
	edition = {2nd},
	note = {ISBN 978-1498716963},
	publisher = {Chapman and Hall/CRC},
	title = {Dynamic Documents with {R} and knitr},
	url = {http://yihui.org/knitr/},
	year = {2015},
	Bdsk-Url-1 = {http://yihui.org/knitr/}}

@unpublished{strand2020,
	abstract = {Admitting scientific errors is hard. It's also important.},
	author = {Strand, Julia Feld},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {PsyArXiv},
	keywords = {retraction; honest retraction; self-correction in science; authorship; open science; replication; programming bugs; psychology research; self-retraction; text},
	language = {en},
	month = mar,
	title = {When science needs self-correcting},
	year = 2020}

@article{frank2014,
	abstract = {Newborn babies look preferentially at faces and face-like
              displays, yet over the course of their first year much changes
              about both the way infants process visual stimuli and how they
              allocate their attention to the social world. Despite this
              initial preference for faces in restricted contexts, the amount
              that infants look at faces increases considerably during the
              first year. Is this development related to changes in attentional
              orienting abilities? We explored this possibility by showing 3-,
              6-, and 9-month-olds engaging animated and live-action videos of
              social stimuli and also measuring their visual search performance
              with both moving and static search displays. Replicating previous
              findings, looking at faces increased with age; in addition, the
              amount of looking at faces was strongly related to the youngest
              infants' performance in visual search. These results suggest that
              infants' attentional abilities may be an important factor in
              facilitating their social attention early in development.},
	author = {Frank, Michael C and Amso, Dima and Johnson, Scott P},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Exp. Child Psychol.},
	keywords = {Infancy; Eye tracking; Social attention; Visual search; Face perception; Visual attention},
	month = feb,
	pages = {13--26},
	title = {Visual search and attention to faces during early infancy},
	volume = 118,
	year = 2014}

@article{ebersole2016,
	abstract = {The university participant pool is a key resource for behavioral
              research, and data quality is believed to vary over the course of
              the academic semester. This crowdsourced project examined time of
              semester variation in 10 known effects, 10 individual
              differences, and 3 data quality indicators over the course of the
              academic semester in 20 participant pools (N=2696) and with an
              online sample (N=737). Weak time of semester effects were
              observed on data quality indicators, participant sex, and a few
              individual differences---conscientiousness, mood, and stress.
              However, there was little evidence for time of semester
              qualifying experimental or correlational effects. The generality
              of this evidence is unknown because only a subset of the tested
              effects demonstrated evidence for the original result in the
              whole sample. Mean characteristics of pool samples change
              slightly during the semester, but these data suggest that those
              changes are mostly irrelevant for detecting effects.},
	author = {Ebersole, Charles R and Atherton, Olivia E and Belanger, Aimee L and Skulborstad, Hayley M and Allen, Jill M and Banks, Jonathan B and Baranski, Erica and Bernstein, Michael J and Bonfiglio, Diane B V and Boucher, Leanne and Brown, Elizabeth R and Budiman, Nancy I and Cairo, Athena H and Capaldi, Colin A and Chartier, Christopher R and Chung, Joanne M and Cicero, David C and Coleman, Jennifer A and Conway, John G and Davis, William E and Devos, Thierry and Fletcher, Melody M and German, Komi and Grahe, Jon E and Hermann, Anthony D and Hicks, Joshua A and Honeycutt, Nathan and Humphrey, Brandon and Janus, Matthew and Johnson, David J and Joy-Gaba, Jennifer A and Juzeler, Hannah and Keres, Ashley and Kinney, Diana and Kirshenbaum, Jacqeline and Klein, Richard A and Lucas, Richard E and Lustgraaf, Christopher J N and Martin, Daniel and Menon, Madhavi and Metzger, Mitchell and Moloney, Jaclyn M and Morse, Patrick J and Prislin, Radmila and Razza, Timothy and Re, Daniel E and Rule, Nicholas O and Sacco, Donald F and Sauerberger, Kyle and Shrider, Emily and Shultz, Megan and Siemsen, Courtney and Sobocko, Karin and Weylin Sternglanz, R and Summerville, Amy and Tskhay, Konstantin O and van Allen, Zack and Vaughn, Leigh Ann and Walker, Ryan J and Weinberg, Ashley and Wilson, John Paul and Wirth, James H and Wortman, Jessica and Nosek, Brian A},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Exp. Soc. Psychol.},
	keywords = {Social psychology; Cognitive psychology; Replication; Participant pool; Individual differences; Sampling effects; Situational effects},
	month = nov,
	pages = {68--82},
	title = {Many Labs 3: Evaluating participant pool quality across the academic semester via replication},
	volume = 67,
	year = 2016}

@article{stodden2016,
	author = {Stodden, Victoria and McNutt, Marcia and Bailey, David H and Deelman, Ewa and Gil, Yolanda and Hanson, Brooks and Heroux, Michael A and Ioannidis, John P A and Taufer, Michela},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Science},
	language = {en},
	month = dec,
	number = 6317,
	pages = {1240--1241},
	title = {Enhancing reproducibility for computational methods},
	volume = 354,
	year = 2016}

@article{hilgard2021,
	abstract = {Effect sizes in social psychology are generally not large and are
              limited by error variance in manipulation and measurement. Effect
              sizes exceeding these limits are implausible and should be viewed
              with skepticism. Maximal positive controls, experimental
              conditions that should show an obvious and predictable effect,
              can provide estimates of the upper limits of plausible effect
              sizes on a measure. In this work, maximal positive controls are
              conducted for three measures of aggressive cognition, and the
              effect sizes obtained are compared to studies found through
              systematic review. Questions are raised regarding the
              plausibility of certain reports with effect sizes comparable to,
              or in excess of, the effect sizes found in maximal positive
              controls. Maximal positive controls may provide a means to
              identify implausible study results at lower cost than direct
              replication.},
	author = {Hilgard, Joseph},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Exp. Soc. Psychol.},
	keywords = {Violent video games; Aggression; Aggressive thought; Positive controls; Scientific self-correction},
	month = mar,
	pages = {104082},
	title = {Maximal positive controls: A method for estimating the largest plausible effect size},
	volume = 93,
	year = 2021}

@article{borsboom2006,
	abstract = {This paper analyzes the theoretical, pragmatic, and substantive
               factors that have hampered the integration between psychology
               and psychometrics. Theoretical factors include the
               operationalist mode of thinking which is common throughout
               psychology, the dominance of classical test theory, and the use
               of ``construct validity'' as a catch-all category for a range of
               challenging psychometric problems. Pragmatic factors include the
               lack of interest in mathematically precise thinking in
               psychology, inadequate representation of psychometric modeling
               in major statistics programs, and insufficient mathematical
               training in the psychological curriculum. Substantive factors
               relate to the absence of psychological theories that are
               sufficiently strong to motivate the structure of psychometric
               models. Following the identification of these problems, a number
               of promising recent developments are discussed, and suggestions
               are made to further the integration of psychology and
               psychometrics.},
	author = {Borsboom, Denny},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychometrika},
	language = {en},
	month = sep,
	number = 3,
	pages = {425--440},
	publisher = {Springer Nature},
	title = {The attack of the psychometricians},
	volume = 71,
	year = 2006}

@book{salsburg2001,
	abstract = {At a summer tea party in Cambridge, England, a lady states that
               tea poured into milk tastes differently than that of milk poured
               into tea. Her notion is shouted down by the scientific minds of
               the group. But one guest, by the name Ronald Aylmer Fisher,
               proposes to scientifically test the lady's hypothesis. There was
               no better person to conduct such a test. For Fisher had brought
               to the field of statistics an emphasis on controlling the
               methods for obtaining data and the importance of interpretation.
               He knew that how the data was gathered and applied was as
               important as the data themselves.In The Lady Tasting Tea,
               readers will encounter not only Ronald Fisher's theories (and
               their repercussions), but the ideas of dozens of men and women
               whose revolutionary work affects our everyday lives. Writing
               with verve and wit, author David Salsburg traces the rise and
               fall of Karl Pearson's theories, explores W. Edwards Deming's
               statistical methods of quality control (which rebuilt postwar
               Japan's economy), and relates the story of Stella Cunliff's
               early work on the capacity of small beer casks at the Guinness
               brewing factory. The Lady Tasting Tea is not a book of dry facts
               and figures, but the history of great individuals who dared to
               look at the world in a new way.},
	author = {Salsburg, David},
	date-modified = {2021-08-17 14:56:05 -0400},
	language = {en},
	month = apr,
	publisher = {Macmillan},
	title = {The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century},
	year = 2001}

@misc{walsh2003,
	author = {Walsh, C and Ross, L F},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {PEDIATRICS},
	number = 4,
	pages = {890--895},
	title = {Are Minority Children Under- or Overrepresented in Pediatric Research?},
	volume = 112,
	year = 2003}

@misc{frank2009b,
	author = {Frank, Michael C and Vul, Edward and Johnson, Scott P},
	date-modified = {2021-08-17 14:56:52 -0400},
	journal = {Cognition},
	number = 2,
	pages = {160--170},
	title = {Development of infants' attention to faces during the first year},
	volume = 110,
	year = 2009}

@article{stoet2013,
	abstract = {We analyzed one decade of data collected by the Programme for
              International Student Assessment (PISA), including the
              mathematics and reading performance of nearly 1.5 million 15 year
              olds in 75 countries. Across nations, boys scored higher than
              girls in mathematics, but lower than girls in reading. The sex
              difference in reading was three times as large as in mathematics.
              There was considerable variation in the extent of the sex
              differences between nations. There are countries without a sex
              difference in mathematics performance, and in some countries
              girls scored higher than boys. Boys scored lower in reading in
              all nations in all four PISA assessments (2000, 2003, 2006,
              2009). Contrary to several previous studies, we found no evidence
              that the sex differences were related to nations' gender equality
              indicators. Further, paradoxically, sex differences in
              mathematics were consistently and strongly inversely correlated
              with sex differences in reading: Countries with a smaller sex
              difference in mathematics had a larger sex difference in reading
              and vice versa. We demonstrate that this was not merely a
              between-nation, but also a within-nation effect. This effect is
              related to relative changes in these sex differences across the
              performance continuum: We did not find a sex difference in
              mathematics among the lowest performing students, but this is
              where the sex difference in reading was largest. In contrast, the
              sex difference in mathematics was largest among the higher
              performing students, and this is where the sex difference in
              reading was smallest. The implication is that if policy makers
              decide that changes in these sex differences are desired,
              different approaches will be needed to achieve this for reading
              and mathematics. Interventions that focus on high-achieving girls
              in mathematics and on low achieving boys in reading are likely to
              yield the strongest educational benefits.},
	author = {Stoet, Gijsbert and Geary, David C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {PLoS One},
	language = {en},
	month = mar,
	number = 3,
	pages = {e57988},
	title = {Sex differences in mathematics and reading achievement are inversely related: within- and across-nation assessment of 10 years of {PISA} data},
	volume = 8,
	year = 2013}

@article{wicherts2010,
	abstract = {Measurement invariance with respect to groups is an essential
               aspect of the fair use of scores of intelligence tests and other
               psychological measurements. It is widely believed that equal
               factor loadings are sufficient to establish measurement
               invariance in confirmatory factor analysis. Here, it is shown
               why establishing measurement invariance with confirmatory factor
               analysis requires a statistical test of the equality over groups
               of measurement intercepts. Without this essential test,
               measurement bias may be overlooked. A re-analysis of a study by
               Te Nijenhuis, Tolboom, Resing, and Bleichrodt (2004) on ethnic
               differences on the RAKIT IQ test illustrates that ignoring
               intercept differences may lead to the conclusion that bias of IQ
               tests with respect to minorities is small, while in reality bias
               is quite severe.},
	author = {Wicherts, Jelte M and Dolan, Conor V},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Educ. Meas. Issu. Pr.},
	language = {en},
	month = sep,
	number = 3,
	pages = {39--47},
	publisher = {Wiley},
	title = {Measurement invariance in confirmatory factor analysis: An illustration using {IQ} test performance of minorities},
	volume = 29,
	year = 2010}

@misc{reinhart2010,
	author = {Reinhart, Carmen and Rogoff, Kenneth},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Growth in a Time of Debt},
	year = 2010}

@article{simmons2011,
	abstract = {In this article, we accomplish two things. First, we show that
              despite empirical psychologists' nominal endorsement of a low
              rate of false-positive findings ($\leq$ .05), flexibility in data
              collection, analysis, and reporting dramatically increases actual
              false-positive rates. In many cases, a researcher is more likely
              to falsely find evidence that an effect exists than to correctly
              find evidence that it does not. We present computer simulations
              and a pair of actual experiments that demonstrate how
              unacceptably easy it is to accumulate (and report) statistically
              significant evidence for a false hypothesis. Second, we suggest a
              simple, low-cost, and straightforwardly effective
              disclosure-based solution to this problem. The solution involves
              six concrete requirements for authors and four guidelines for
              reviewers, all of which impose a minimal burden on the
              publication process.},
	author = {Simmons, Joseph P and Nelson, Leif D and Simonsohn, Uri},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	language = {en},
	month = nov,
	number = 11,
	pages = {1359--1366},
	title = {False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant},
	volume = 22,
	year = 2011}

@article{cronbach1955,
	author = {Cronbach, L J and Meehl, P E},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Bull.},
	keywords = {SCALE},
	language = {en},
	month = jul,
	number = 4,
	pages = {281--302},
	title = {Construct validity in psychological tests},
	volume = 52,
	year = 1955}

@misc{lewis2018,
	author = {Lewis, Molly L and Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychological Science},
	number = 12,
	pages = {2039--2047},
	title = {Still Suspicious: The {Suspicious-Coincidence} Effect Revisited},
	volume = 29,
	year = 2018}

@misc{broman2018,
	author = {Broman, Karl W and Woo, Kara H},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Data organization in spreadsheets},
	year = 2018}

@article{westfall2016,
	author = {Westfall, Jacob and Nichols, Thomas E and Yarkoni, Tal},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Wellcome Open Research},
	title = {Fixing the stimulus-as-fixed-effect fallacy in task {fMRI}},
	year = 2016}

@article{wagenmakers2016,
	abstract = {According to the facial feedback hypothesis, people?s affective
               responses can be influenced by their own facial expression
               (e.g., smiling, pouting), even when their expression did not
               result from their emotional experiences. For example, Strack,
               Martin, and Stepper (1988) instructed participants to rate the
               funniness of cartoons using a pen that they held in their mouth.
               In line with the facial feedback hypothesis, when participants
               held the pen with their teeth (inducing a ?smile?), they rated
               the cartoons as funnier than when they held the pen with their
               lips (inducing a ?pout?). This seminal study of the facial
               feedback hypothesis has not been replicated directly. This
               Registered Replication Report describes the results of 17
               independent direct replications of Study 1 from Strack et al.
               (1988), all of which followed the same vetted protocol. A
               meta-analysis of these studies examined the difference in
               funniness ratings between the ?smile? and ?pout? conditions. The
               original Strack et al. (1988) study reported a rating difference
               of 0.82 units on a 10-point Likert scale. Our meta-analysis
               revealed a rating difference of 0.03 units with a 95\%
               confidence interval ranging from ?0.11 to 0.16.},
	author = {Wagenmakers, E-J and Beek, T and Dijkhoff, L and Gronau, Q F and Acosta, A and Adams, R B and Albohn, D N and Allard, E S and Benning, S D and Blouin-Hudon, E-M and Bulnes, L C and Caldwell, T L and Calin-Jageman, R J and Capaldi, C A and Carfagno, N S and Chasten, K T and Cleeremans, A and Connell, L and DeCicco, J M and Dijkstra, K and Fischer, A H and Foroni, F and Hess, U and Holmes, K J and Jones, J L H and Klein, O and Koch, C and Korb, S and Lewinski, P and Liao, J D and Lund, S and Lupianez, J and Lynott, D and Nance, C N and Oosterwijk, S and Ozdo{\u g}ru, A A and Pacheco-Unguetti, A P and Pearson, B and Powis, C and Riding, S and Roberts, T-A and Rumiati, R I and Senden, M and Shea-Shumsky, N B and Sobocko, K and Soto, J A and Steiner, T G and Talarico, J M and van Allen, Z M and Vandekerckhove, M and Wainwright, B and Wayand, J F and Zeelenberg, R and Zetzer, E E and Zwaan, R A},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Perspect. Psychol. Sci.},
	month = nov,
	number = 6,
	pages = {917--928},
	publisher = {SAGE Publications Inc},
	title = {Registered Replication Report: Strack, Martin, \& Stepper (1988)},
	volume = 11,
	year = 2016}

@article{cumming2014,
	abstract = {We need to make substantial changes to how we conduct research.
              First, in response to heightened concern that our published
              research literature is incomplete and untrustworthy, we need new
              requirements to ensure research integrity. These include
              prespecification of studies whenever possible, avoidance of
              selection and other inappropriate data-analytic practices,
              complete reporting, and encouragement of replication. Second, in
              response to renewed recognition of the severe flaws of
              null-hypothesis significance testing (NHST), we need to shift
              from reliance on NHST to estimation and other preferred
              techniques. The new statistics refers to recommended practices,
              including estimation based on effect sizes, confidence intervals,
              and meta-analysis. The techniques are not new, but adopting them
              widely would be new for many researchers, as well as highly
              beneficial. This article explains why the new statistics are
              important and offers guidance for their use. It describes an
              eight-step new-statistics strategy for research with integrity,
              which starts with formulation of research questions in estimation
              terms, has no place for NHST, and is aimed at building a
              cumulative quantitative discipline.},
	author = {Cumming, Geoff},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	keywords = {estimation; meta-analysis; replication; research integrity; research methods; statistical analysis; the new statistics},
	language = {en},
	month = jan,
	number = 1,
	pages = {7--29},
	title = {The new statistics: why and how},
	volume = 25,
	year = 2014}

@unpublished{isager2020,
	abstract = {Robust scientific knowledge is contingent upon replication of
              original findings. However, replicating researchers are
              constrained by resources, and will almost always have to choose
              one replication effort to focus on from a set of potential
              candidates. To select a candidate efficiently in these cases, we
              need methods for deciding which out of all candidates considered
              would be the most useful to replicate, given some overall goal
              researchers wish to achieve. In this article we assume that the
              overall goal researchers wish to achieve is to maximize the
              utility gained by conducting the replication study. We then
              propose a general rule for study selection in replication
              research based on the *replication value* of the set of claims
              considered for replication. The *replication value* of a claim is
              defined as the maximum expected utility we could gain by
              conducting a replication of the claim, and is a function of (1)
              the value of being certain about the claim, and (2) uncertainty
              about the claim based on current evidence. We formalize this
              definition in terms of a causal decision model, utilizing
              concepts from decision theory and causal graph modeling. We
              discuss the validity of using *replication value* as a measure of
              expected utility gain, and we suggest approaches for deriving
              quantitative estimates of *replication value*. Our goal in this
              article is not to define concrete guidelines for study selection,
              but to provide the necessary theoretical foundations on which
              such concrete guidelines could be built.},
	author = {Isager, Peder M and van Aert, Robbie C M and Bahn{\'\i}k, {\v S}t{\v e}p{\'a}n and Brandt, Mark J and DeSoto, Kurt A and Giner-Sorolla, Roger and Krueger, Joachim and Perugini, Marco and Ropovik, Ivan and van 't Veer, Anna E and al., Et},
	date-modified = {2021-08-17 14:56:05 -0400},
	keywords = {expected utility; replication; replication value; study selection},
	month = sep,
	title = {Deciding what to replicate: A decision model for replication study selection under resource and knowledge constraints},
	year = 2020}

@article{vanderweele2019,
	author = {VanderWeele, Tyler J and Mathur, Maya B and Chen, Ying},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {JAMA Psychiatry},
	language = {en},
	month = sep,
	number = 9,
	pages = {891--892},
	title = {Media Portrayals and Public Health Implications for Suicide and Other Behaviors},
	volume = 76,
	year = 2019}

@misc{frank2016,
	author = {Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Science},
	number = 6278,
	pages = {1161.2--1161},
	title = {Comment on ``Math at home adds up to achievement in school''},
	volume = 351,
	year = 2016}

@misc{franco2014,
	author = {Franco, A and Malhotra, N and Simonovits, G},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Science},
	number = 6203,
	pages = {1502--1505},
	title = {Publication bias in the social sciences: Unlocking the file drawer},
	volume = 345,
	year = 2014}

@misc{barner2016,
	author = {Barner, David and Alvarez, George and Sullivan, Jessica and Brooks, Neon and Srinivasan, Mahesh and Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Child Development},
	number = 4,
	pages = {1146--1158},
	title = {Learning Mathematics in a Visuospatial Format: A Randomized, Controlled Trial of Mental Abacus Instruction},
	volume = 87,
	year = 2016}

@article{crump2013,
	abstract = {Amazon Mechanical Turk (AMT) is an online crowdsourcing service
              where anonymous online workers complete web-based tasks for small
              sums of money. The service has attracted attention from
              experimental psychologists interested in gathering human subject
              data more efficiently. However, relative to traditional
              laboratory studies, many aspects of the testing environment are
              not under the experimenter's control. In this paper, we attempt
              to empirically evaluate the fidelity of the AMT system for use in
              cognitive behavioral experiments. These types of experiment
              differ from simple surveys in that they require multiple trials,
              sustained attention from participants, comprehension of complex
              instructions, and millisecond accuracy for response recording and
              stimulus presentation. We replicate a diverse body of tasks from
              experimental psychology including the Stroop, Switching, Flanker,
              Simon, Posner Cuing, attentional blink, subliminal priming, and
              category learning tasks using participants recruited using AMT.
              While most of replications were qualitatively successful and
              validated the approach of collecting data anonymously online
              using a web-browser, others revealed disparity between laboratory
              results and online results. A number of important lessons were
              encountered in the process of conducting these replications that
              should be of value to other researchers.},
	author = {Crump, Matthew J C and McDonnell, John V and Gureckis, Todd M},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {PLoS One},
	language = {en},
	month = mar,
	number = 3,
	pages = {e57410},
	title = {Evaluating Amazon's Mechanical Turk as a tool for experimental behavioral research},
	volume = 8,
	year = 2013}

@article{yarkoni2020,
	abstract = {Most theories and hypotheses in psychology are verbal in nature,
              yet their evaluation overwhelmingly relies on inferential
              statistical procedures. The validity of the move from qualitative
              to quantitative analysis depends on the verbal and statistical
              expressions of a hypothesis being closely aligned-that is, that
              the two must refer to roughly the same set of hypothetical
              observations. Here I argue that many applications of statistical
              inference in psychology fail to meet this basic condition.
              Focusing on the most widely used class of model in psychology-the
              linear mixed model-I explore the consequences of failing to
              statistically operationalize verbal hypotheses in a way that
              respects researchers' actual generalization intentions. I
              demonstrate that whereas the ``random effect'' formalism is used
              pervasively in psychology to model inter-subject variability, few
              researchers accord the same treatment to other variables they
              clearly intend to generalize over (e.g., stimuli, tasks, or
              research sites). The under-specification of random effects
              imposes far stronger constraints on the generalizability of
              results than most researchers appreciate. Ignoring these
              constraints can dramatically inflate false positive rates, and
              often leads researchers to draw sweeping verbal generalizations
              that lack a meaningful connection to the statistical quantities
              they are putatively based on. I argue that failure to take the
              alignment between verbal and statistical expressions seriously
              lies at the heart of many of psychology's ongoing problems (e.g.,
              the replication crisis), and conclude with a discussion of
              several potential avenues for improvement.},
	author = {Yarkoni, Tal},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Behav. Brain Sci.},
	keywords = {generalization; inference; philosophy of science; psychology; random effects; statistics},
	language = {en},
	month = dec,
	pages = {1--37},
	title = {The generalizability crisis},
	year = 2020}

@article{grant2009,
	abstract = {BACKGROUND AND OBJECTIVES: The expansion of evidence-based
               practice across sectors has lead to an increasing variety of
               review types. However, the diversity of terminology used means
               that the full potential of these review types may be lost
               amongst a confusion of indistinct and misapplied terms. The
               objective of this study is to provide descriptive insight into
               the most common types of reviews, with illustrative examples
               from health and health information domains. METHODS: Following
               scoping searches, an examination was made of the vocabulary
               associated with the literature of review and synthesis (literary
               warrant). A simple analytical framework -- Search, AppraisaL,
               Synthesis and Analysis (SALSA) -- was used to examine the main
               review types. RESULTS: Fourteen review types and associated
               methodologies were analysed against the SALSA framework,
               illustrating the inputs and processes of each review type. A
               description of the key characteristics is given, together with
               perceived strengths and weaknesses. A limited number of review
               types are currently utilized within the health information
               domain. CONCLUSIONS: Few review types possess prescribed and
               explicit methodologies and many fall short of being mutually
               exclusive. Notwithstanding such limitations, this typology
               provides a valuable reference point for those commissioning,
               conducting, supporting or interpreting reviews, both within
               health information and the wider health care domain.},
	author = {Grant, Maria J and Booth, Andrew},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Health Info. Libr. J.},
	language = {en},
	month = jun,
	number = 2,
	pages = {91--108},
	publisher = {Wiley},
	title = {A typology of reviews: an analysis of 14 review types and associated methodologies},
	volume = 26,
	year = 2009}

@article{kruschke2018,
	abstract = {In the practice of data analysis, there is a conceptual
              distinction between hypothesis testing, on the one hand, and
              estimation with quantified uncertainty on the other. Among
              frequentists in psychology, a shift of emphasis from hypothesis
              testing to estimation has been dubbed ``the New Statistics''
              (Cumming 2014). A second conceptual distinction is between
              frequentist methods and Bayesian methods. Our main goal in this
              article is to explain how Bayesian methods achieve the goals of
              the New Statistics better than frequentist methods. The article
              reviews frequentist and Bayesian approaches to hypothesis testing
              and to estimation with confidence or credible intervals. The
              article also describes Bayesian approaches to meta-analysis,
              randomized controlled trials, and power analysis.},
	author = {Kruschke, John K and Liddell, Torrin M},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychon. Bull. Rev.},
	keywords = {Bayes factor; Bayesian inference; Confidence interval; Credible interval; Effect size; Equivalence testing; Highest density interval; Meta-analysis; Null hypothesis significance testing; Power analysis; Randomized controlled trial; Region of practical equivalence},
	language = {en},
	month = feb,
	number = 1,
	pages = {178--206},
	title = {The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective},
	volume = 25,
	year = 2018}

@article{wilkinson2016,
	abstract = {There is an urgent need to improve the infrastructure supporting
              the reuse of scholarly data. A diverse set of
              stakeholders-representing academia, industry, funding agencies,
              and scholarly publishers-have come together to design and jointly
              endorse a concise and measureable set of principles that we refer
              to as the FAIR Data Principles. The intent is that these may act
              as a guideline for those wishing to enhance the reusability of
              their data holdings. Distinct from peer initiatives that focus on
              the human scholar, the FAIR Principles put specific emphasis on
              enhancing the ability of machines to automatically find and use
              the data, in addition to supporting its reuse by individuals.
              This Comment is the first formal publication of the FAIR
              Principles, and includes the rationale behind them, and some
              exemplar implementations in the community.},
	author = {Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and Bouwman, Jildau and Brookes, Anthony J and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J G and Groth, Paul and Goble, Carole and Grethe, Jeffrey S and Heringa, Jaap and 't Hoen, Peter A C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J and Martone, Maryann E and Mons, Albert and Packer, Abel L and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Sci Data},
	language = {en},
	month = mar,
	pages = {160018},
	title = {The {FAIR} Guiding Principles for scientific data management and stewardship},
	volume = 3,
	year = 2016}

@misc{xu2007a,
	author = {Xu, Fei and Tenenbaum, Joshua B},
	date-modified = {2021-08-17 14:56:16 -0400},
	journal = {Developmental Science},
	number = 3,
	pages = {288--297},
	title = {Sensitivity to sampling in Bayesian word learning},
	volume = 10,
	year = 2007}

@article{meehl1978,
	abstract = {Theories in ``soft'' areas of psychology (e.g., clinical,
              counseling, social, personality, school, and community) lack the
              cumulative character of scientific knowledge because they tend
              neither to be refuted nor corroborated, but instead merely fade
              away as people lose interest. Even though intrinsic subject
              matter difficulties (20 are listed) contribute to this, the
              excessive reliance on significance testing is partly responsible
              (Ronald A. Fisher). Karl Popper's approach, with modifications,
              would be prophylactic. Since the null hypothesis is quasi-always
              false, tables summarizing research in terms of patterns of
              ``significant differences'' are little more than complex,
              causally uninterpretable outcomes of statistical power functions.
              Multiple paths to estimating numerical point values
              (``consistency tests'') are better, even if approximate with
              rough tolerances; and lacking this, ranges, orderings, 2nd-order
              differences, curve peaks and valleys, and function forms should
              be used. Such methods are usual in developed sciences that seldom
              report statistical significance. Consistency tests of a
              conjectural taxometric model yielded 94\% success with no false
              negatives. (3 p ref) (PsycINFO Database Record (c) 2016 APA, all
              rights reserved)},
	author = {Meehl, Paul E},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Consult. Clin. Psychol.},
	month = aug,
	number = 4,
	pages = {806--834},
	title = {Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology},
	volume = 46,
	year = 1978}

@article{funder2019,
	abstract = {Effect sizes are underappreciated and often misinterpreted?the
               most common mistakes being to describe them in ways that are
               uninformative (e.g., using arbitrary standards) or misleading
               (e.g., squaring effect-size rs). We propose that effect sizes
               can be usefully evaluated by comparing them with well-understood
               benchmarks or by considering them in terms of concrete
               consequences. In that light, we conclude that when reliably
               estimated (a critical consideration), an effect-size r of .05
               indicates an effect that is very small for the explanation of
               single events but potentially consequential in the not-very-long
               run, an effect-size r of .10 indicates an effect that is still
               small at the level of single events but potentially more
               ultimately consequential, an effect-size r of .20 indicates a
               medium effect that is of some explanatory and practical use even
               in the short run and therefore even more important, and an
               effect-size r of .30 indicates a large effect that is
               potentially powerful in both the short and the long run. A very
               large effect size (r = .40 or greater) in the context of
               psychological research is likely to be a gross overestimate that
               will rarely be found in a large sample or in a replication. Our
               goal is to help advance the treatment of effect sizes so that
               rather than being numbers that are ignored, reported without
               interpretation, or interpreted superficially or incorrectly,
               they become aspects of research reports that can better inform
               the application and theoretical development of psychological
               research.},
	author = {Funder, David C and Ozer, Daniel J},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Advances in Methods and Practices in Psychological Science},
	month = jun,
	number = 2,
	pages = {156--168},
	publisher = {SAGE Publications Inc},
	title = {Evaluating Effect Size in Psychological Research: Sense and Nonsense},
	volume = 2,
	year = 2019}

@misc{manybabies2020,
	author = {{The ManyBabies Consortium} and Frank, Michael C and Alcock, Katherine Jane and Arias-Trejo, Natalia and Aschersleben, Gisa and Baldwin, Dare and Barbu, St{\'e}phanie and Bergelson, Elika and Bergmann, Christina and Black, Alexis K and Blything, Ryan and B{\"o}hland, Maximilian P and Bolitho, Petra and Borovsky, Arielle and Brady, Shannon M and Braun, Bettina and Brown, Anna and Byers-Heinlein, Krista and Campbell, Linda E and Cashon, Cara and Choi, Mihye and Christodoulou, Joan and Cirelli, Laura K and Conte, Stefania and Cordes, Sara and Cox, Christopher and Cristia, Alejandrina and Cusack, Rhodri and Davies, Catherine and de Klerk, Maartje and Luche, Claire Delle and de Ruiter, Laura and Dinakar, Dhanya and Dixon, Kate C and Durier, Virginie and Durrant, Samantha and Fennell, Christopher and Ferguson, Brock and Ferry, Alissa and Fikkert, Paula and Flanagan, Teresa and Floccia, Caroline and Foley, Megan and Fritzsche, Tom and Frost, Rebecca L A and Gampe, Anja and Gervain, Judit and Gonzalez-Gomez, Nayeli and Gupta, Anna and Hahn, Laura E and Kiley Hamlin, J and Hannon, Erin E and Havron, Naomi and Hay, Jessica and Hernik, Miko{\l}aj and H{\"o}hle, Barbara and Houston, Derek M and Howard, Lauren H and Ishikawa, Mitsuhiko and Itakura, Shoji and Jackson, Iain and Jakobsen, Krisztina V and Jarto, Marianna and Johnson, Scott P and Junge, Caroline and Karadag, Didar and Kartushina, Natalia and Kellier, Danielle J and Keren-Portnoy, Tamar and Klassen, Kelsey and Kline, Melissa and Ko, Eon-Suk and Kominsky, Jonathan F and Kosie, Jessica E and Kragness, Haley E and Krieger, Andrea A R and Krieger, Florian and Lany, Jill and Lazo, Roberto J and Lee, Michelle and Leservoisier, Chlo{\'e} and Levelt, Claartje and Lew-Williams, Casey and Lippold, Matthias and Liszkowski, Ulf and Liu, Liquan and Luke, Steven G and Lundwall, Rebecca A and Cassia, Viola Macchi and Mani, Nivedita and Marino, Caterina and Martin, Alia and Mastroberardino, Meghan and Mateu, Victoria and Mayor, Julien and Menn, Katharina and Michel, Christine and Moriguchi, Yusuke and Morris, Benjamin and Nave, Karli M and Nazzi, Thierry and Noble, Claire and Novack, Miriam A and Olesen, Nonah M and Orena, Adriel John and Ota, Mitsuhiko and Panneton, Robin and Esfahani, Sara Parvanezadeh and Paulus, Markus and Pletti, Carolina and Polka, Linda and Potter, Christine and Rabagliati, Hugh and Ramachandran, Shruthilaya and Rennels, Jennifer L and Reynolds, Greg D and Roth, Kelly C and Rothwell, Charlotte and Rubez, Doroteja and Ryjova, Yana and Saffran, Jenny and Sato, Ayumi and Savelkouls, Sophie and Schachner, Adena and Schafer, Graham and Schreiner, Melanie S and Seidl, Amanda and Shukla, Mohinish and Simpson, Elizabeth A and Singh, Leher and Skarabela, Barbora and Soley, Gaye and Sundara, Megha and Theakston, Anna and Thompson, Abbie and Trainor, Laurel J and Trehub, Sandra E and Tr{\o}an, Anna S and Tsui, Angeline Sin-Mei and Twomey, Katherine and Von Holzen, Katie and Wang, Yuanyuan and Waxman, Sandra and Werker, Janet F and Wermelinger, Stephanie and Woolard, Alix and Yurovsky, Daniel and Zahner, Katharina and Zettersten, Martin and Soderstrom, Melanie},
	date-modified = {2021-08-17 14:57:31 -0400},
	journal = {Advances in Methods and Practices in Psychological Science},
	number = 1,
	pages = {24--52},
	title = {Quantifying Sources of Variability in Infancy Research Using the {Infant-Directed-Speech} Preference},
	volume = 3,
	year = 2020}

@article{knuth1984,
	abstract = {Abstract. The author and his associates have been experimenting
               for the past several years with a programming language and
               documentation system called WEB. This},
	author = {Knuth, D E},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Comput. J.},
	language = {en},
	month = jan,
	number = 2,
	pages = {97--111},
	publisher = {Oxford Academic},
	title = {Literate Programming},
	volume = 27,
	year = 1984}

@book{porter2020,
	abstract = {An essential work on the origins of statisticsThe Rise of
               Statistical Thinking, 1820--1900 explores the history of
               statistics from the field's origins in the nineteenth century
               through to the factors that produced the burst of modern
               statistical innovation in the early twentieth century. Theodore
               Porter shows that statistics was not developed by mathematicians
               and then applied to the sciences and social sciences. Rather,
               the field came into being through the efforts of social
               scientists, who saw a need for statistical tools in their
               examination of society. Pioneering statistical physicists and
               biologists James Clerk Maxwell, Ludwig Boltzmann, and Francis
               Galton introduced statistical models to the sciences by pointing
               to analogies between their disciplines and the social sciences.
               A new preface by the author looks at how the book has remained
               relevant since its initial publication, and considers the
               current place of statistics in scientific research.},
	author = {Porter, Theodore M},
	date-modified = {2021-08-17 14:56:05 -0400},
	language = {en},
	month = aug,
	publisher = {Princeton University Press},
	title = {The Rise of Statistical Thinking, 1820--1900},
	year = 2020}

@article{gelman2013,
	abstract = {The importance of graphical displays in statistical practice has
               been recognized sporadically in the statistical literature over
               the past century, with wider awareness following Tukey's
               Exploratory Data Analysis and Tufte's books in the succeeding
               decades. But statistical graphics still occupy an awkward
               in-between position: within statistics, exploratory and
               graphical methods represent a minor subfield and are not well
               integrated with larger themes of modeling and inference. Outside
               of statistics, infographics (also called information
               visualization or Infovis) are huge, but their purveyors and
               enthusiasts appear largely to be uninterested in statistical
               principles.We present here a set of goals for graphical displays
               discussed primarily from the statistical point of view and
               discuss some inherent contradictions in these goals that may be
               impeding communication between the fields of statistics and
               Infovis. One of our constructive suggestions, to Infovis
               practitioners and statisticians alike, is to try not to cram
               into a single graph what can be better displayed in two or more.
               We recognize that we offer only one perspective and intend this
               article to be a starting point for a wide-ranging discussion
               among graphic designers, statisticians, and users of statistical
               methods. The purpose of this article is not to criticize but to
               explore the different goals that lead researchers in different
               fields to value different aspects of data visualization.},
	author = {Gelman, Andrew and Unwin, Antony},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Comput. Graph. Stat.},
	month = jan,
	number = 1,
	pages = {2--28},
	publisher = {Taylor \& Francis},
	title = {Infovis and Statistical Graphics: Different Goals, Different Looks},
	volume = 22,
	year = 2013}

@article{bland2009,
	author = {Bland, John Martin},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {BMJ},
	language = {en},
	month = oct,
	pages = {b3985},
	title = {The tyranny of power: is there a better way to calculate sample size?},
	volume = 339,
	year = 2009}

@article{noguera2003,
	abstract = {There is considerable confusion regarding why Black males are
               overrepresented in categories typically associated with negative
               behavioral outcomes. Drawing on research from a variety of
               disciplines, this article explores the influence of
               environmental and cultural factors on the academic performance
               of Black males. The article also examines the ways in which
               environmental and cultural forces shape the relationship between
               identity, particularly related to race and gender, and school
               performance. Finally, strategies for countering harmful
               environmental and cultural influences, both the diffuse and the
               direct, are explored with particular attention paid to
               recommendations for educators, parents, and youth service
               providers who seek to support young African American males.},
	author = {Noguera, Pedro A},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Urban Education},
	month = jul,
	number = 4,
	pages = {431--459},
	publisher = {SAGE Publications Inc},
	title = {The Trouble with Black Boys:: The Role and Influence of Environmental and Cultural Factors on the Academic Performance of African American Males},
	volume = 38,
	year = 2003}

@article{bishop2018,
	author = {Bishop, D V M},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Advances in Methods and Practices in Psychological Science},
	month = sep,
	number = 3,
	pages = {432--438},
	publisher = {SAGE Publications Inc},
	title = {Fallibility in Science: Responding to Errors in the Work of Oneself and Others},
	volume = 1,
	year = 2018}

@misc{goodman2016,
	author = {Goodman, Noah D and Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Trends in Cognitive Sciences},
	number = 11,
	pages = {818--829},
	title = {Pragmatic Language Interpretation as Probabilistic Inference},
	volume = 20,
	year = 2016}

@article{mathur2019,
	abstract = {Psychological scientists are now trying to replicate published
              research from scratch to confirm the findings. In an increasingly
              widespread replication study design, each of several
              collaborating sites (such as universities) independently tries to
              replicate an original study, and the results are synthesized
              across sites. Hedges and Schauer (2019) proposed statistical
              analyses for these replication projects; their analyses focus on
              assessing the extent to which results differ across the
              replication sites, by testing for heterogeneity among a set of
              replication studies, while excluding the original study. We agree
              with their premises regarding the limitations of existing
              analysis methods and regarding the importance of accounting for
              heterogeneity among the replications. This objective may be
              interesting in its own right. However, we argue that by focusing
              only on whether the replication studies have similar effect sizes
              to one another, these analyses are not particularly appropriate
              for assessing whether the replications in fact support the
              scientific effect under investigation or for assessing the power
              of multisite replication projects. We reanalyze Hedges and
              Schauer's (2019) example dataset using alternative metrics of
              replication success that directly address these objectives. We
              reach a more optimistic conclusion regarding replication success
              than they did, illustrating that the alternative metrics can lead
              to quite different conclusions from those of Hedges and Schauer
              (2019). (PsycINFO Database Record (c) 2019 APA, all rights
              reserved).},
	author = {Mathur, Maya B and VanderWeele, Tyler J},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Methods},
	language = {en},
	month = oct,
	number = 5,
	pages = {571--575},
	title = {Challenges and suggestions for defining replication ``success'' when effects may be heterogeneous: Comment on Hedges and Schauer (2019)},
	volume = 24,
	year = 2019}

@article{mathur2020,
	abstract = {Summary Increasingly, researchers are attempting to replicate
               published original studies by using large, multisite replication
               projects, at least 134 of which have been completed or are on
               going. These designs are promising to assess whether the
               original study is statistically consistent with the replications
               and to reassess the strength of evidence for the scientific
               effect of interest. However, existing analyses generally focus
               on single replications; when applied to multisite designs, they
               provide an incomplete view of aggregate evidence and can lead to
               misleading conclusions about replication success. We propose new
               statistical metrics representing firstly the probability that
               the original study's point estimate would be at least as extreme
               as it actually was, if in fact the original study were
               statistically consistent with the replications, and secondly the
               estimated proportion of population effects agreeing in direction
               with the original study. Generalized versions of the second
               metric enable consideration of only meaningfully strong
               population effects that agree in direction, or alternatively
               that disagree in direction, with the original study. These
               metrics apply when there are at least 10 replications (unless
               the heterogeneity estimate $\tau$^=0, in which case the metrics
               apply regardless of the number of replications). The first
               metric assumes normal population effects but appears robust to
               violations in simulations; the second is distribution free. We
               provide R packages (Replicate and MetaUtility).},
	author = {Mathur, Maya B and VanderWeele, Tyler J},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. R. Stat. Soc. Ser. A Stat. Soc.},
	language = {en},
	month = jun,
	number = 3,
	pages = {1145--1166},
	publisher = {Wiley},
	title = {New statistical metrics for multisite replication projects},
	volume = 183,
	year = 2020}

@article{schonbrodt2017,
	abstract = {Unplanned optional stopping rules have been criticized for
              inflating Type I error rates under the null hypothesis
              significance testing (NHST) paradigm. Despite these criticisms,
              this research practice is not uncommon, probably because it
              appeals to researcher's intuition to collect more data to push an
              indecisive result into a decisive region. In this contribution,
              we investigate the properties of a procedure for Bayesian
              hypothesis testing that allows optional stopping with unlimited
              multiple testing, even after each participant. In this procedure,
              which we call Sequential Bayes Factors (SBFs), Bayes factors are
              computed until an a priori defined level of evidence is reached.
              This allows flexible sampling plans and is not dependent upon
              correct effect size guesses in an a priori power analysis. We
              investigated the long-term rate of misleading evidence, the
              average expected sample sizes, and the biasedness of effect size
              estimates when an SBF design is applied to a test of mean
              differences between 2 groups. Compared with optimal NHST, the SBF
              design typically needs 50\% to 70\% smaller samples to reach a
              conclusion about the presence of an effect, while having the same
              or lower long-term rate of wrong inference. (PsycINFO Database
              Record},
	author = {Sch{\"o}nbrodt, Felix D and Wagenmakers, Eric-Jan and Zehetleitner, Michael and Perugini, Marco},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Methods},
	language = {en},
	month = jun,
	number = 2,
	pages = {322--339},
	title = {Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences},
	volume = 22,
	year = 2017}

@book{kant1785,
	author = {Kant, Immanuel},
	date-modified = {2021-08-17 14:56:05 -0400},
	language = {en},
	title = {Groundwork for the Metaphysics of Morals},
	year = 1785}

@misc{zwaan2018,
	author = {Zwaan, Rolf Antonius and Etz, Alexander and Lucas, Richard E and Donnellan, Brent},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Making Replication Mainstream},
	year = 2018}

@book{rosenthal1984,
	address = {New York},
	author = {Rosenthal, Robert and Rosnow, Ralph L},
	date-modified = {2021-08-17 14:56:05 -0400},
	publisher = {McGraw-Hill},
	title = {Essentials of behavioral research: Methods and data analysis},
	year = 1984}

@article{nuijten2016,
	abstract = {This study documents reporting errors in a sample of over 250,000
              p-values reported in eight major psychology journals from 1985
              until 2013, using the new R package ``statcheck.'' statcheck
              retrieved null-hypothesis significance testing (NHST) results
              from over half of the articles from this period. In line with
              earlier research, we found that half of all published psychology
              papers that use NHST contained at least one p-value that was
              inconsistent with its test statistic and degrees of freedom. One
              in eight papers contained a grossly inconsistent p-value that may
              have affected the statistical conclusion. In contrast to earlier
              findings, we found that the average prevalence of inconsistent
              p-values has been stable over the years or has declined. The
              prevalence of gross inconsistencies was higher in p-values
              reported as significant than in p-values reported as
              nonsignificant. This could indicate a systematic bias in favor of
              significant results. Possible solutions for the high prevalence
              of reporting inconsistencies could be to encourage sharing data,
              to let co-authors check results in a so-called ``co-pilot
              model,'' and to use statcheck to flag possible inconsistencies in
              one's own manuscript or during the review process.},
	author = {Nuijten, Mich{\`e}le B and Hartgerink, Chris H J and van Assen, Marcel A L M and Epskamp, Sacha and Wicherts, Jelte M},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Behav. Res. Methods},
	month = dec,
	number = 4,
	pages = {1205--1226},
	title = {The prevalence of statistical reporting errors in psychology (1985--2013)},
	volume = 48,
	year = 2016}

@article{knuth1992,
	author = {Knuth, Donald E},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Center for the Study of Language and Information},
	title = {Literate Programming, 1992},
	year = 1992}

@article{hoekstra2020,
	author = {Hoekstra, R and Vazire, S},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Hoekstra \& Vazire (2020), Aspiring to greater intellectual humility in science},
	year = 2020}

@misc{biagetti2020,
	author = {Biagetti, Maria Teresa and Gedutis, Aldis and Ma, Lai},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Scholarly Assessment Reports},
	number = 1,
	title = {Ethical Theories in Research Evaluation: An Exploratory Approach},
	volume = 2,
	year = 2020}

@article{sklar2012,
	abstract = {The modal view in the cognitive and neural sciences holds that
              consciousness is necessary for abstract, symbolic, and
              rule-following computations. Hence, semantic processing of
              multiple-word expressions, and performing of abstract
              mathematical computations, are widely believed to require
              consciousness. We report a series of experiments in which we show
              that multiple-word verbal expressions can be processed outside
              conscious awareness and that multistep, effortful arithmetic
              equations can be solved unconsciously. All experiments used
              Continuous Flash Suppression to render stimuli invisible for
              relatively long durations (up to 2,000 ms). Where appropriate,
              unawareness was verified using both objective and subjective
              measures. The results show that novel word combinations, in the
              form of expressions that contain semantic violations, become
              conscious before expressions that do not contain semantic
              violations, that the more negative a verbal expression is, the
              more quickly it becomes conscious, and that subliminal arithmetic
              equations prime their results. These findings call for a
              significant update of our view of conscious and unconscious
              processes.},
	author = {Sklar, Asael Y and Levy, Nir and Goldstein, Ariel and Mandel, Roi and Maril, Anat and Hassin, Ran R},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	language = {en},
	month = nov,
	number = 48,
	pages = {19614--19619},
	title = {Reading and doing arithmetic nonconsciously},
	volume = 109,
	year = 2012}

@misc{vadillo2016,
	author = {Vadillo, Miguel A and Hardwicke, Tom E and Shanks, David R},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Journal of Experimental Psychology: General},
	number = 5,
	pages = {655--663},
	title = {Selection bias, vote counting, and money-priming effects: A comment on Rohrer, Pashler, and Harris (2015) and Vohs (2015)},
	volume = 145,
	year = 2016}

@article{moors2018,
	abstract = {A recent study claimed to have obtained evidence that
              participants can solve invisible multistep arithmetic equations
              (Sklar et al., 2012). The authors used a priming paradigm in
              which reaction times to targets congruent with the equation's
              solution were responded to faster compared with incongruent ones.
              We critically reanalyzed the data set of Sklar et al. and show
              that the claims being made in the article are not fully supported
              by the alternative analyses that we applied. A Bayesian
              reanalysis of the data accounting for the random variability of
              the target stimuli in addition to the subjects shows that the
              evidence for priming effects is less strong than initially
              claimed. That is, although Bayes factors revealed evidence for
              the presence of a priming effect, it was generally weak. Second,
              the claim that unconscious arithmetic occurs for subtraction but
              not for addition is not supported when the critical interaction
              is tested. Third, the data do not show well-established features
              of numerosity priming as derived from V-shaped response time
              curves for prime-target distances. Fourth, we show that it is
              impossible to classify reaction times as resulting from congruent
              or incongruent prime-target relationships, which should be
              expected if their results imply that participants genuinely solve
              the equations on each trial. We conclude that the claims being
              made in the original article are not fully supported by the
              analyses that we apply. Together with a recent failure to
              replicate the original results and a critique of the analysis
              based on regression to the mean, we argue that the current
              evidence for unconscious arithmetic is inconclusive. We argue
              that strong claims require strong evidence and stress that
              cumulative research strategies are needed to provide such
              evidence.},
	author = {Moors, Pieter and Hesselmann, Guido},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychon. Bull. Rev.},
	keywords = {Interocular suppression; Reproducibility; Unconscious processing},
	language = {en},
	month = feb,
	number = 1,
	pages = {472--481},
	title = {A critical reexamination of doing arithmetic nonconsciously},
	volume = 25,
	year = 2018}

@article{lash2015,
	abstract = {An abstract is unavailable.},
	author = {Lash, Timothy L and Kaufman, Jay S},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Epidemiology},
	month = jul,
	number = 4,
	pages = {449},
	title = {Seeking Persuasively Null Results},
	volume = 26,
	year = 2015}

@misc{gilmore2017,
	author = {Gilmore, Rick O and Adolph, Karen E},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Nature Human Behaviour},
	number = 7,
	title = {Video can make behavioural science more reproducible},
	volume = 1,
	year = 2017}

@article{clark1973,
	abstract = {Current investigators of words, sentences, and other language
              materials almost never provide statistical evidence that their
              findings generalize beyond the specific sample of language
              materials they have chosen. Nevertheless, these same
              investigators do not hesitate to conclude that their findings are
              true for language in general. In so doing, it is argued, they are
              committing the language-as-fixed-effect fallacy, which can lead
              to serious error. The problem is illustrated for one well-known
              series of studies in semantic memory. With the appropriate
              statistics these studies are shown to provide no reliable
              evidence for most of the main conclusions drawn from them. A
              review of other experiments in semantic memory shows that many of
              them are likewise suspect. It is demonstrated how this fallacy
              can be avoided by doing the right statistics, selecting the
              appropriate design, and sampling by systematic procedures, or,
              alternatively, by proceeding according to the so-called method of
              single cases.},
	author = {Clark, Herbert H},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Journal of Verbal Learning and Verbal Behavior},
	month = aug,
	number = 4,
	pages = {335--359},
	title = {The language-as-fixed-effect fallacy: A critique of language statistics in psychological research},
	volume = 12,
	year = 1973}

@article{osc2012,
	author = {{Open Science Collaboration}},
	date-modified = {2021-08-17 14:56:38 -0400},
	journal = {Perspect. Psychol. Sci.},
	number = 6,
	pages = {657--660},
	publisher = {Sage Publications Sage CA: Los Angeles, CA},
	title = {An open, large-scale, collaborative effort to estimate the reproducibility of psychological science},
	volume = 7,
	year = 2012}

@article{bem1987,
	author = {Bem, Daryl J},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {The compleat academic: A practical guide for the beginning social scientist},
	pages = {185--219},
	publisher = {Citeseer},
	title = {Writing the empirical journal article},
	volume = 2,
	year = 1987}

@article{aronow2019,
	abstract = {Dropping subjects based on the results of a manipulation check
               following treatment assignment is common practice across the
               social sciences, presumably to restrict estimates to a
               subpopulation of subjects who understand the experimental
               prompt. We show that this practice can lead to serious bias and
               argue for a focus on what is revealed without discarding
               subjects. Generalizing results developed in Zhang and Rubin
               (2003) and Lee (2009) to the case of multiple treatments, we
               provide sharp bounds for potential outcomes among those who
               would pass a manipulation check regardless of treatment
               assignment. These bounds may have large or infinite width,
               implying that this inferential target is often out of reach. As
               an application, we replicate Press, Sagan, and Valentino (2013)
               with a design that does not drop subjects that failed the
               manipulation check and show that the findings are likely
               stronger than originally reported. We conclude with suggestions
               for practice, namely alterations to the experimental design.},
	author = {Aronow, Peter M and Baron, Jonathon and Pinson, Lauren},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Polit. Anal.},
	keywords = {causal inference; survey experiments; randomized experiments},
	month = oct,
	number = 4,
	pages = {572--589},
	publisher = {Cambridge University Press},
	title = {A Note on Dropping Experimental Subjects who Fail a Manipulation Check},
	volume = 27,
	year = 2019}

@article{nieuwenhuis2011,
	abstract = {In theory, a comparison of two experimental effects requires a
              statistical test on their difference. In practice, this
              comparison is often based on an incorrect procedure involving two
              separate tests in which researchers conclude that effects differ
              when one effect is significant (P 0.05). We reviewed 513
              behavioral, systems and cognitive neuroscience articles in five
              top-ranking journals (Science, Nature, Nature Neuroscience,
              Neuron and The Journal of Neuroscience) and found that 78 used
              the correct procedure and 79 used the incorrect procedure. An
              additional analysis suggests that incorrect analyses of
              interactions are even more common in cellular and molecular
              neuroscience. We discuss scenarios in which the erroneous
              procedure is particularly beguiling.},
	author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Nat. Neurosci.},
	language = {en},
	month = aug,
	number = 9,
	pages = {1105--1107},
	title = {Erroneous analyses of interactions in neuroscience: a problem of significance},
	volume = 14,
	year = 2011}

@misc{hardwicke2021a,
	author = {Hardwicke, Tom E and Bohn, Manuel and MacDonald, Kyle and Hembacher, Emily and Nuijten, Mich{\`e}le B and Peloquin, Benjamin N and deMayo, Benjamin E and Long, Bria and Yoon, Erica J and Frank, Michael C},
	date-modified = {2021-08-17 14:57:02 -0400},
	journal = {Royal Society Open Science},
	number = 1,
	pages = {201494},
	title = {Analytic reproducibility in articles receiving open data badges at the journal Psychological Science : an observational study},
	volume = 8,
	year = 2021}

@article{watts2018,
	abstract = {We replicated and extended Shoda, Mischel, and Peake's (1990)
              famous marshmallow study, which showed strong bivariate
              correlations between a child's ability to delay gratification
              just before entering school and both adolescent achievement and
              socioemotional behaviors. Concentrating on children whose mothers
              had not completed college, we found that an additional minute
              waited at age 4 predicted a gain of approximately one tenth of a
              standard deviation in achievement at age 15. But this bivariate
              correlation was only half the size of those reported in the
              original studies and was reduced by two thirds in the presence of
              controls for family background, early cognitive ability, and the
              home environment. Most of the variation in adolescent achievement
              came from being able to wait at least 20 s. Associations between
              delay time and measures of behavioral outcomes at age 15 were
              much smaller and rarely statistically significant.},
	author = {Watts, Tyler W and Duncan, Greg J and Quan, Haonan},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	keywords = {achievement; behavioral problems; early childhood; gratification delay; longitudinal analysis; marshmallow test; open data},
	language = {en},
	month = jul,
	number = 7,
	pages = {1159--1177},
	title = {Revisiting the Marshmallow Test: A Conceptual Replication Investigating Links Between Early Delay of Gratification and Later Outcomes},
	volume = 29,
	year = 2018}

@misc{hardwicke2018b,
	author = {Hardwicke, Tom E and Mathur, Maya B and MacDonald, Kyle Earl and Nilsonne, Gustav and Banks, George Christopher and Kidwell, Mallory and Mohr, Alicia Hofelich and Clayton, Elizabeth and Yoon, Erica J and Tessler, Michael Henry and Lenne, Richie L and Altman, Sara Kai and Long, Bria and Frank, Michael C},
	date-modified = {2021-08-17 14:57:05 -0400},
	title = {Data availability, reusability, and analytic reproducibility: Evaluating the impact of a mandatory open data policy at the journal Cognition},
	year = 2018}

@misc{mcelreath2018,
	author = {McElreath, Richard},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Statistical Rethinking},
	year = 2018}

@misc{mathur,
	author = {Mathur, Maya B and VanderWeele, Tyler},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {Methods to address confounding and other biases in meta-analyses: Review and recommendations}}

@article{moshontz2018,
	abstract = {Concerns have been growing about the veracity of psychological
              research. Many findings in psychological science are based on
              studies with insufficient statistical power and nonrepresentative
              samples, or may otherwise be limited to specific, ungeneralizable
              settings or populations. Crowdsourced research, a type of
              large-scale collaboration in which one or more research projects
              are conducted across multiple lab sites, offers a pragmatic
              solution to these and other current methodological challenges.
              The Psychological Science Accelerator (PSA) is a distributed
              network of laboratories designed to enable and support
              crowdsourced research projects. These projects can focus on novel
              research questions, or attempt to replicate prior research, in
              large, diverse samples. The PSA's mission is to accelerate the
              accumulation of reliable and generalizable evidence in
              psychological science. Here, we describe the background,
              structure, principles, procedures, benefits, and challenges of
              the PSA. In contrast to other crowdsourced research networks, the
              PSA is ongoing (as opposed to time-limited), efficient (in terms
              of re-using structures and principles for different projects),
              decentralized, diverse (in terms of participants and
              researchers), and inclusive (of proposals, contributions, and
              other relevant input from anyone inside or outside of the
              network). The PSA and other approaches to crowdsourced
              psychological science will advance our understanding of mental
              processes and behaviors by enabling rigorous research and
              systematically examining its generalizability.},
	author = {Moshontz, Hannah and Campbell, Lorne and Ebersole, Charles R and IJzerman, Hans and Urry, Heather L and Forscher, Patrick S and Grahe, Jon E and McCarthy, Randy J and Musser, Erica D and Antfolk, Jan and Castille, Christopher M and Evans, Thomas Rhys and Fiedler, Susann and Flake, Jessica Kay and Forero, Diego A and Janssen, Steve M J and Keene, Justin Robert and Protzko, John and Aczel, Balazs and Solas, Sara {\'A}lvarez and Ansari, Daniel and Awlia, Dana and Baskin, Ernest and Batres, Carlota and Borras-Guevara, Martha Lucia and Brick, Cameron and Chandel, Priyanka and Chatard, Armand and Chopik, William J and Clarance, David and Coles, Nicholas A and Corker, Katherine S and Dixson, Barnaby James Wyld and Dranseika, Vilius and Dunham, Yarrow and Fox, Nicholas W and Gardiner, Gwendolyn and Garrison, S Mason and Gill, Tripat and Hahn, Amanda C and Jaeger, Bastian and Ka{\v c}m{\'a}r, Pavol and Kaminski, Gwena{\"e}l and Kanske, Philipp and Kekecs, Zoltan and Kline, Melissa and Koehn, Monica A and Kujur, Pratibha and Levitan, Carmel A and Miller, Jeremy K and Okan, Ceylan and Olsen, Jerome and Oviedo-Trespalacios, Oscar and {\"O}zdo{\u g}ru, Asil Ali and Pande, Babita and Parganiha, Arti and Parveen, Noorshama and Pfuhl, Gerit and Pradhan, Sraddha and Ropovik, Ivan and Rule, Nicholas O and Saunders, Blair and Schei, Vidar and Schmidt, Kathleen and Singh, Margaret Messiah and Sirota, Miroslav and Steltenpohl, Crystal N and Stieger, Stefan and Storage, Daniel and Sullivan, Gavin Brent and Szabelska, Anna and Tamnes, Christian K and Vadillo, Miguel A and Valentova, Jaroslava V and Vanpaemel, Wolf and Varella, Marco A C and Vergauwe, Evie and Verschoor, Mark and Vianello, Michelangelo and Voracek, Martin and Williams, Glenn P and Wilson, John Paul and Zickfeld, Janis H and Arnal, Jack D and Aydin, Burak and Chen, Sau-Chin and DeBruine, Lisa M and Fernandez, Ana Maria and Horstmann, Kai T and Isager, Peder M and Jones, Benedict and Kapucu, Aycan and Lin, Hause and Mensink, Michael C and Navarrete, Gorka and Silan, Miguel A and Chartier, Christopher R},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Adv Methods Pract Psychol Sci},
	keywords = {Psychological Science Accelerator; crowdsourcing; generalizability; large-scale collaboration; theory development},
	language = {en},
	month = dec,
	number = 4,
	pages = {501--515},
	title = {The Psychological Science Accelerator: Advancing Psychology through a Distributed Collaborative Network},
	volume = 1,
	year = 2018}

@misc{strack1988,
	author = {Strack, Fritz and Martin, Leonard L and Stepper, Sabine},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Journal of Personality and Social Psychology},
	number = 5,
	pages = {768--777},
	title = {Inhibiting and facilitating conditions of the human smile: A nonobtrusive test of the facial feedback hypothesis},
	volume = 54,
	year = 1988}

@article{frank2012,
	author = {Frank, Michael C and Saxe, Rebecca},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Perspectives on Psychological Science},
	pages = {595--599},
	title = {Teaching Replication},
	volume = 7,
	year = 2012}

@article{hawkins2018,
	abstract = {Replications are important to science, but who will do them? One
               proposal is that students can conduct replications as part of
               their training. As a proof of concept for this idea, here we
               report a series of 11 preregistered replications of findings
               from the 2015 volume of Psychological Science, all conducted as
               part of a graduate-level course. As was expected given larger,
               more systematic prior efforts, the replications typically
               yielded effects that were smaller than the original ones: The
               modal outcome was partial support for the original claim. This
               work documents the challenges facing motivated students as they
               attempt to replicate previously published results on a first
               attempt. We describe the workflow and pedagogical methods that
               were used in the class and discuss implications both for the
               adoption of this pedagogical model and for replication research
               more broadly.},
	author = {Hawkins, Robert X D and Smith, Eric N and Au, Carolyn and Arias, Juan Miguel and Catapano, Rhia and Hermann, Eric and Keil, Martin and Lampinen, Andrew and Raposo, Sarah and Reynolds, Jesse and Salehi, Shima and Salloum, Justin and Tan, Jed and Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Advances in Methods and Practices in Psychological Science},
	month = mar,
	number = 1,
	pages = {7--18},
	publisher = {SAGE Publications Inc},
	title = {Improving the Replicability of Psychological Science Through Pedagogy},
	volume = 1,
	year = 2018}

@article{rabagliati2018,
	abstract = {Is consciousness required for high level cognitive processes, or
              can the unconscious mind perform tasks that are as complex and
              difficult as, for example, understanding a sentence? Recent work
              has argued that, yes, the unconscious mind can: Sklar et al.
              (2012) found that sentences, masked from consciousness using the
              technique of continuous flash suppression (CFS), broke into
              awareness more rapidly when their meanings were more unusual or
              more emotionally negative, even though processing the sentences'
              meaning required unconsciously combining each word's meaning.
              This has motivated the important claim that consciousness plays
              little-to-no functional role in high-level cognitive operations.
              Here, we aimed to replicate and extend these findings, but
              instead, across 10 high-powered studies, we found no evidence
              that the meaning of a phrase or word could be understood without
              awareness. We did, however, consistently find evidence that
              low-level perceptual features, such as sentence length and
              familiarity of alphabet, could be processed unconsciously. Our
              null findings for sentence processing are corroborated by a
              meta-analysis that aggregates our studies with the prior
              literature. We offer a potential explanation for prior positive
              results through a set of computational simulations, which show
              how the distributional characteristics of this type of CFS data,
              in particular its skew and heavy tail, can cause an elevated
              level of false positive results when common data exclusion
              criteria are applied. Our findings thus have practical
              implication for analyzing such data. More importantly, they
              suggest that consciousness may well be required for high-level
              cognitive tasks such as understanding language. (PsycINFO
              Database Record},
	author = {Rabagliati, Hugh and Robertson, Alexander and Carmel, David},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {J. Exp. Psychol. Gen.},
	language = {en},
	month = feb,
	number = 2,
	pages = {190--208},
	title = {The importance of awareness for understanding language},
	volume = 147,
	year = 2018}

@unpublished{yanai2020,
	abstract = {When analyzing the results of an experiment, the mental focus on
              a specific hypothesis might prevent the exploration of other
              aspects of the data, effectively blinding one to new ideas. To
              test this notion, we performed an experiment in which we asked
              undergraduate students to analyze a fictitious dataset. In
              addition to being asked what they could conclude from the
              dataset, half of the students were asked to also test specific
              hypotheses. In line with our notion, students in the
              hypothesis-free group were almost 5 times more likely to observe
              an image of a gorilla when simply plotting the data, a proxy for
              an initial step towards data analysis. If these findings are
              representative also of scientific research as a whole, they
              warrant concern about the current emphasis on hypothesis-driven
              research, especially in the context of information-rich datasets
              such as those now routinely created in the biological sciences.
              Our work provides evidence for a link between the psychological
              effect of selective attention and hypothesis-driven data
              analysis, and suggests a hidden cost to having a hypothesis when
              analyzing a dataset. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.},
	author = {Yanai, Itai and Lercher, Martin},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {bioRxiv},
	language = {en},
	month = jul,
	pages = {2020.07.30.228916},
	title = {Selective attention in hypothesis-driven data analysis},
	year = 2020}

@article{scheibehenne2016,
	author = {Scheibehenne, Benjamin and Jamil, Tahira and Wagenmakers, Eric-Jan},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	language = {en},
	month = jul,
	number = 7,
	pages = {1043--1046},
	title = {Bayesian Evidence Synthesis Can Reconcile Seemingly Inconsistent Results: The Case of Hotel Towel Reuse},
	volume = 27,
	year = 2016}

@unpublished{hardwicke2021b,
	abstract = {Scientific research is performed by fallible humans. Degrees of
              freedom in the construction and selection of evidence and
              hypotheses grant scientists considerable latitude to obtain study
              outcomes that align more with their preferences than is
              warranted. This creates a risk of bias and can lead to scientists
              fooling themselves and fooling others. Preregistration involves
              archiving study information (e.g., hypotheses, methods, and
              analyses) in a public registry before data are inspected. This
              offers two potential benefits: (1) reduce bias by ensuring that
              research decisions are made independently of study outcomes; and
              (2) calibrate confidence in research by transparently
              communicating information about a study's risk of bias. In this
              article, we briefly review the historical evolution of
              preregistration in medicine, psychology, and other domains,
              clarify its pragmatic functions, discuss relevant meta-research,
              and provide recommendations for scientists and journal editors.},
	author = {Hardwicke, Tom E and Wagenmakers, Eric-Jan},
	date-modified = {2021-08-17 14:57:09 -0400},
	keywords = {bias; meta-research; multiplicity; preregistration; transparency},
	month = apr,
	title = {Preregistration: A pragmatic tool to reduce bias and calibrate confidence in scientific research},
	year = 2021}

@article{strand2019,
	abstract = {Speech recognition is improved when the acoustic input is
              accompanied by visual cues provided by a talking face (Erber in
              Journal of Speech and Hearing Research, 12(2), 423-425 1969;
              Sumby \& Pollack in The Journal of the Acoustical Society of
              America, 26(2), 212-215, 1954). One way that the visual signal
              facilitates speech recognition is by providing the listener with
              information about fine phonetic detail that complements
              information from the auditory signal. However, given that
              degraded face stimuli can still improve speech recognition
              accuracy (Munhall et al. in Perception \& Psychophysics, 66(4),
              574-583, 2004), and static or moving shapes can improve speech
              detection accuracy (Bernstein et al. in Speech Communication,
              44(1/4), 5-18, 2004), aspects of the visual signal other than
              fine phonetic detail may also contribute to the perception of
              speech. In two experiments, we show that a modulating circle
              providing information about the onset, offset, and acoustic
              amplitude envelope of the speech does not improve recognition of
              spoken sentences (Experiment 1) or words (Experiment 2), but does
              reduce the effort necessary to recognize speech. These results
              suggest that although fine phonetic detail may be required for
              the visual signal to benefit speech recognition, low-level
              features of the visual signal may function to reduce the
              cognitive effort associated with processing speech.},
	author = {Strand, Julia F and Brown, Violet A and Barbour, Dennis L},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychon. Bull. Rev.},
	keywords = {Cross-modal attention; Speech perception; Spoken word recognition},
	language = {en},
	month = feb,
	number = 1,
	pages = {291--297},
	title = {Talking points: A modulating circle reduces listening effort without improving speech recognition},
	volume = 26,
	year = 2019}

@book{frank2021,
	author = {Frank, Michael C and Braginsky, Mika and Yurovsky, Daniel and Marchman, Virginia A},
	date-modified = {2021-08-17 14:56:05 -0400},
	publisher = {MIT Press},
	title = {Variability and consistency in early language learning: The Wordbank project},
	year = 2021}

@article{roberts2000,
	abstract = {Quantitative theories with free parameters often gain credence
              when they closely fit data. This is a mistake. A good fit reveals
              nothing about the flexibility of the theory (how much it cannot
              fit), the variability of the data (how firmly the data rule out
              what the theory cannot fit), or the likelihood of other outcomes
              (perhaps the theory could have fit any plausible result), and a
              reader needs all 3 pieces of information to decide how much the
              fit should increase belief in the theory. The use of good fits as
              evidence is not supported by philosophers of science nor by the
              history of psychology; there seem to be no examples of a theory
              supported mainly by good fits that has led to demonstrable
              progress. A better way to test a theory with free parameters is
              to determine how the theory constrains possible outcomes (i.e.,
              what it predicts), assess how firmly actual outcomes agree with
              those constraints, and determine if plausible alternative
              outcomes would have been inconsistent with the theory, allowing
              for the variability of the data.},
	author = {Roberts, S and Pashler, H},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Rev.},
	language = {en},
	month = apr,
	number = 2,
	pages = {358--367},
	title = {How persuasive is a good fit? A comment on theory testing},
	volume = 107,
	year = 2000}

@article{spencer2011,
	abstract = {A major debate in the study of word learning centers on the
              extension of categories to new items. The rational approach
              assumes that learners make structured inferences about category
              membership, whereas the mechanistic approach emphasizes the
              attentional and memory processes that form the basis of
              generalization behaviors. Recent support for the rational view
              comes from observations of the suspicious-coincidence effect:
              People generalize category membership narrowly when presented
              with three subordinate-level exemplars that share the same label
              and generalize category membership broadly when presented with
              one exemplar. Across three experiments, we examined the
              mechanistic basis of this effect. Results showed that the
              presentation of multiple subordinate-level exemplars led to
              narrow generalization only when the exemplars were presented
              simultaneously, even when the number of exemplars was increased
              from three to six. These data demonstrate that the
              suspicious-coincidence effect is firmly grounded in the general
              cognitive processes of attention, memory, and visual comparison.},
	author = {Spencer, John P and Perone, Sammy and Smith, Linda B and Samuelson, Larissa K},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	language = {en},
	month = aug,
	number = 8,
	pages = {1049--1057},
	title = {Learning words in space and time: probing the mechanisms behind the suspicious-coincidence effect},
	volume = 22,
	year = 2011}

@misc{newell1973,
	author = {Newell, Allen},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Visual Information Processing},
	pages = {283--308},
	title = {{YOU} {CAN'T} {PLAY} 20 {QUESTIONS} {WITH} {NATURE} {AND} {WIN}: {PROJECTIVE} {COMMENTS} {ON} {THE} {PAPERS} {OF} {THIS} {SYMPOSIUM}},
	year = 1973}

@article{coles2019,
	abstract = {Researchers have proposed that blocking facial feedback via
               glabellar-region botulinum toxin injections (GBTX) can reduce
               depression. Random-effects meta-analyses of studies that
               administered GBTX to individuals with depression indicate that,
               6 weeks postintervention, GBTX groups were significantly less
               depressed compared to placebo groups (d = 0.83) and pretreatment
               levels (d = 1.57). However, we noted the following concerns: (a)
               effect sizes were extraordinarily large, (b) authors failed to
               provide information to compute 51\% of relevant effect sizes,
               (c) 96\% of effect sizes came from studies conducted by
               investigators with conflicts of interest, (d) there is some
               evidence of publication bias, and (e) studies used ineffective
               blinding procedures. These considerations suggest that
               confidence in GBTX as a treatment for depression is premature.},
	author = {Coles, Nicholas A and Larsen, Jeff T and Kuribayashi, Joyce and Kuelz, Ashley},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Emot. Rev.},
	month = oct,
	number = 4,
	pages = {294--309},
	publisher = {SAGE Publications},
	title = {Does Blocking Facial Feedback Via Botulinum Toxin Injections Decrease Depression? A Critical Review and {Meta-Analysis}},
	volume = 11,
	year = 2019}

@article{rocher2019,
	abstract = {While rich medical, behavioral, and socio-demographic data are
              key to modern data-driven research, their collection and use
              raise legitimate privacy concerns. Anonymizing datasets through
              de-identification and sampling before sharing them has been the
              main tool used to address those concerns. We here propose a
              generative copula-based method that can accurately estimate the
              likelihood of a specific person to be correctly re-identified,
              even in a heavily incomplete dataset. On 210 populations, our
              method obtains AUC scores for predicting individual uniqueness
              ranging from 0.84 to 0.97, with low false-discovery rate. Using
              our model, we find that 99.98\% of Americans would be correctly
              re-identified in any dataset using 15 demographic attributes. Our
              results suggest that even heavily sampled anonymized datasets are
              unlikely to satisfy the modern standards for anonymization set
              forth by GDPR and seriously challenge the technical and legal
              adequacy of the de-identification release-and-forget model.},
	author = {Rocher, Luc and Hendrickx, Julien M and de Montjoye, Yves-Alexandre},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Nat. Commun.},
	language = {en},
	month = jul,
	number = 1,
	pages = {3069},
	title = {Estimating the success of re-identifications in incomplete datasets using generative models},
	volume = 10,
	year = 2019}

@misc{frank2009a,
	author = {Frank, Michael C and Slemmer, Jonathan A and Marcus, Gary F and Johnson, Scott P},
	date-modified = {2021-08-17 14:56:47 -0400},
	journal = {Developmental Science},
	number = 4,
	pages = {504--509},
	title = {Information from multiple modalities helps 5-month-olds learn abstract rules},
	volume = 12,
	year = 2009}

@article{simonsohn2015,
	abstract = {This article introduces a new approach for evaluating replication
              results. It combines effect-size estimation with hypothesis
              testing, assessing the extent to which the replication results
              are consistent with an effect size big enough to have been
              detectable in the original study. The approach is demonstrated by
              examining replications of three well-known findings. Its benefits
              include the following: (a) differentiating ``unsuccessful''
              replication attempts (i.e., studies yielding p > .05) that are
              too noisy from those that actively indicate the effect is
              undetectably different from zero, (b) ``protecting'' true
              findings from underpowered replications, and (c) arriving at
              intuitively compelling inferences in general and for the
              revisited replications in particular.},
	author = {Simonsohn, Uri},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Psychol. Sci.},
	keywords = {hypothesis testing; open materials; replication; statistical power},
	language = {en},
	month = may,
	number = 5,
	pages = {559--569},
	title = {Small telescopes: detectability and the evaluation of replication results},
	volume = 26,
	year = 2015}

@article{montgomery2018,
	author = {Montgomery, Jacob M and Nyhan, Brendan and Torres, Michelle},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Am. J. Pol. Sci.},
	language = {en},
	month = jul,
	number = 3,
	pages = {760--775},
	publisher = {Wiley},
	title = {How conditioning on posttreatment variables can ruin your experiment and what to do about it},
	volume = 62,
	year = 2018}

@misc{klein2018,
	author = {Klein, Olivier and Hardwicke, Tom Elis and Aust, Frederik and Breuer, Johannes and Danielsson, Henrik and Mohr, Alicia Hofelich and IJzerman, Hans and Nilsonne, Gustav and Vanpaemel, Wolf and Frank, Michael C},
	date-modified = {2021-08-17 14:56:05 -0400},
	title = {A practical guide for transparency in psychological science},
	year = 2018}

@article{stevens1946,
	author = {Stevens, S S},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Science},
	language = {en},
	month = jun,
	number = 2684,
	pages = {677--680},
	publisher = {American Association for the Advancement of Science (AAAS)},
	title = {On the theory of scales of measurement},
	volume = 103,
	year = 1946}

@misc{xu2007b,
	author = {Xu, Fei and Tenenbaum, Joshua B},
	date-modified = {2021-08-17 14:56:27 -0400},
	journal = {Psychological Review},
	number = 2,
	pages = {245--272},
	title = {Word learning as Bayesian inference},
	volume = 114,
	year = 2007}

@article{majid2018,
	abstract = {People struggle to name odors [1-4]. This has been attributed to
              a diminution of olfaction in trade-off to vision [5-10]. This
              presumption has been challenged recently by data from the
              hunter-gatherer Jahai who, unlike English speakers, find odors as
              easy to name as colors [4]. Is the superior olfactory performance
              among the Jahai because of their ecology (tropical rainforest),
              their language family (Aslian), or because of their subsistence
              (they are hunter-gatherers)? We provide novel evidence from the
              hunter-gatherer Semaq Beri and the non-hunter-gatherer
              (swidden-horticulturalist) Semelai that subsistence is the
              critical factor. Semaq Beri and Semelai speakers-who speak
              closely related languages and live in the tropical rainforest of
              the Malay Peninsula-took part in a controlled odor- and
              color-naming experiment. The swidden-horticulturalist Semelai
              found odors much more difficult to name than colors, replicating
              the typical Western finding. But for the hunter-gatherer Semaq
              Beri odor naming was as easy as color naming, suggesting that
              hunter-gatherer olfactory cognition is special.},
	author = {Majid, Asifa and Kruspe, Nicole},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Curr. Biol.},
	keywords = {Aslian; Austroasiatic; Semaq Beri; Semelai; cognition; culture; horticulturalist; hunter-gatherer; language; olfaction},
	language = {en},
	month = feb,
	number = 3,
	pages = {409--413.e2},
	title = {{Hunter-Gatherer} Olfaction Is Special},
	volume = 28,
	year = 2018}

@misc{hardwicke2018a,
	author = {Hardwicke, Tom E and Tessler, Michael Henry and Peloquin, Benjamin N and Frank, Michael C},
	date-modified = {2021-08-17 14:56:57 -0400},
	journal = {Behavioral and Brain Sciences},
	title = {A Bayesian decision-making framework for replication},
	volume = 41,
	year = 2018}

@book{pearl2018,
	abstract = {A Turing Award-winning computer scientist and statistician shows
               how understanding causality has revolutionized science and will
               revolutionize artificial intelligence ``Correlation is not
               causation.'' This mantra, chanted by scientists for more than a
               century, has led to a virtual prohibition on causal talk. Today,
               that taboo is dead. The causal revolution, instigated by Judea
               Pearl and his colleagues, has cut through a century of confusion
               and established causality -- the study of cause and effect -- on
               a firm scientific basis. His work explains how we can know easy
               things, like whether it was rain or a sprinkler that made a
               sidewalk wet; and how to answer hard questions, like whether a
               drug cured an illness. Pearl's work enables us to know not just
               whether one thing causes another: it lets us explore the world
               that is and the worlds that could have been. It shows us the
               essence of human thought and key to artificial intelligence.
               Anyone who wants to understand either needs The Book of Why.},
	author = {Pearl, Judea and Mackenzie, Dana},
	date-modified = {2021-08-17 14:56:05 -0400},
	language = {en},
	month = may,
	publisher = {Basic Books},
	title = {The Book of Why: The New Science of Cause and Effect},
	year = 2018}

@article{sperry2019,
	abstract = {Amid growing controversy about the oft-cited ``30-million-word
              gap,'' this investigation uses language data from five American
              communities across the socioeconomic spectrum to test, for the
              first time, Hart and Risley's (1995) claim that poor children
              hear 30 million fewer words than their middle-class counterparts
              during the early years of life. The five studies combined
              ethnographic fieldwork with longitudinal home observations of 42
              children (18-48 months) interacting with family members in
              everyday life contexts. Results do not support Hart and Risley's
              claim, reveal substantial variation in vocabulary environments
              within each socioeconomic stratum, and suggest that definitions
              of verbal environments that exclude multiple caregivers and
              bystander talk disproportionately underestimate the number of
              words to which low-income children are exposed.},
	author = {Sperry, Douglas E and Sperry, Linda L and Miller, Peggy J},
	date-modified = {2021-08-17 14:56:05 -0400},
	journal = {Child Dev.},
	language = {en},
	month = jul,
	number = 4,
	pages = {1303--1318},
	title = {Reexamining the Verbal Environments of Children From Different Socioeconomic Backgrounds},
	volume = 90,
	year = 2019}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>R. A. Fisher</string>
		<key>keys</key>
		<string>fisher1956</string>
	</dict>
</array>
</plist>
}}
