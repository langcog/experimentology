# (PART) Analysis and Reporting {-}

# Visualization {#viz}

::: {.learning-goals}
üçé Learning goals: Analyze the principles behind informative visualizations; incorporate visualization into analysis workflow; learn to make ‚Äúthe design plot‚Äù showing raw data relative to the critical design inferences of the experiment; select different visualizations of variability and distribution; connect visualization concepts to measurement principles.
:::

::: {.case-study}
üî¨ Case study: Sklar et al. (2012) reported evidence of ‚Äúunconscious‚Äù arithmetic. Further reanalyses didn‚Äôt support this finding (Moors and Hesselmann 2018). Rabagliati et al. (2018) also failed to replicate. Visualizations provide a framework for asking about the ways the measurements relate to the manipulation that might have shed light on the issues. 
:::

```{marginfigure, echo=TRUE}
<img src="images/snow_cholera_voronoi.jpeg"/>
Mapping out a cholera epidemic (1854). Line shows region for which Broad Street pump is nearest.
```

In 1854, a deadly outbreak of cholera was sweeping through London.
The scientific consensus at the time was that diseases like cholera spread through breathing poisonous and foul-smelling vapors, an idea known as the "miasma theory" [@halliday2001death].
An obstetrician and anesthesiologist named John Snow, however, had proposed an alternative theory: rather than spreading through foul air, he thought that it was spreading a polluted water supply [@snow1855mode].
To make a public case for this idea, he started counting cholera deaths.
He marked each case on a map of the area, and indicated the locations of the water pumps for reference.
Furthermore, a line could be drawn representing the region that was closest to each water pump, a technique which is now known as a [Voronoi diagram](https://en.wikipedia.org/wiki/Voronoi_diagram).
The resulting illustration clearly reveals that cases clustered around an area called Golden Square, which received water from a pump on Broad Street.
Indeed, the outbreak died down shortly after the pump's handle was removed.
Although the precise causal role of these maps in Snow's own thinking is disputed, and it is likely that he produced them well after the incident [@brody2000map], they have nonetheless played a significant role in the history of data visualization [@friendly2021history] more broadly^[Actually, the use of disease maps goes back even further! [@seaman1798inquiry] mapped an outbreak of yellow fever in New York City to argue that deaths clustered around a handful of waste sites. He turned out to be right, but for the wrong reasons! These waste sites were breeding grounds for mosquitos, which were the real culprits. Coincidentally, Seaman is also known as the first to introduce vaccines to the United States. He vaccinated his children against smallpox and later organized a program to provide free vaccines to the public.].

What makes visualizations so useful, and what role do they play in the toolkit of experimentology?
Simply put, data visualization is the act of "making the invisible visible." 
Our visual systems are remarkably powerful pattern detectors, and relationships that aren't at all clear when scanning through rows of raw data can immediately jump out at us when presented in an appropriate graphical form [@zacks2020designing].
Good visualizations aim to delibrately harness this power and put it to work at every stage of the research process, from the quick sanity checks we run when first reading in our data to the publication-quality figures we design when we are ready to communicate our findings.
Yet our powerful pattern detectors can also be a liability; if we're not careful, we can easily be fooled into seeing patterns that are unreliable or even misleading.
As psychology moves into an era of bigger data and more complex behaviors, we become increasingly reliant on **data visualization literacy** [@borner2019data] to make sense of what is going on.

## Basic principles of visualization

In this section, we begin by introducing a few simple guidelines to keep in mind when making informative visualizations in the context of experimental psychology^[Given this relatively narrow focus, a full treatment of visualization is outside the scope of this book. The classic volumes are by @tukey1977exploratory and [@tufte2001visual,@tufte1997visual], and we recommend @healy2018data for a more contemporary guide. For the purposes of understanding the examples in this chapter, it should be sufficient to work through our R tutorials for data manipulation and visualization in Appendices C and D].
Remember that these needs may be distinct from other contexts, such as journalism or public policy.
You may have seen beautiful and engaging full-page graphics with small print and a wealth of information.
The art of designing and producing these graphics is typically known as **infoviz** and should be distinguished from what we call **statistical vizualization** [@gelman2013].
Roughly, infoviz aims to construct rich and immersive worlds to visually explore: a reader can spend hours pouring over the most intricate graphics and continue to find new and intruiging patterns.
Statistical visualization, on the other hand, aims to convey the logic of the experiment, supporting specific questions or statistical inferences.
The principles below are tailored toward statistical visualizations.

```{marginfigure, echo=TRUE}
<img src="images/viz_infoviz.png"/>
Unlike statistical visualization, which aims to clearly expose the logic of an experiment at a glance, infoviz aims to provide a rich world of patterns to explore [reproduced from @infoviz].
```

### Show the design

(see below for the ‚Äúdata plot‚Äù): make sure that the variables you manipulate are visible in your plots

### Facilitate comparison

```{marginfigure, echo=TRUE}
<img src="images/viz_hierarchy.png"/>
A suspiciously uniform distribution abruptly cutting off at 50k miles, reproduced from @datacolada.
```

make sure that the contrasts you want to interpret are highlighted visually

### Maximize information, minimize ink

following Tufte, use the simplest possible presentation of the maximal amount of information.

### ``Fix the axis labels''

## Exploratory visualization

```{marginfigure, echo=TRUE}
<img src="images/viz_anscombe.png"/>
[@anscombe1973graphs]
```

- Visualization as a source of "data diagnostics" - can find artificats.

- The critical importance of visualizing the data distribution (histograms). 
- Mapping ‚Äúvisual variables‚Äù (size, color, etc.) to the critical variables in your design

::: {.accident-report}
‚ö†Ô∏è Accident report: [Distributional] gorillas in the midst: Many data analysts don‚Äôt bother checking whether they are violating distribution assumptions. If they did, they‚Äôd sometimes realize there is a gorilla in the midst (Yanai and Lercher 2020).
:::

Confirmatory visualization (including ‚ÄúThe design plot‚Äù)

- How to make a plot that maps onto the key, pre-registered analyses
- Different levels of specificity for different audiences 

Visualizing variability

- Measures of precision: confidence intervals and how to extract them from our statistical models.

::: {.interactive}
‚å®Ô∏è Interactive box: bootstrapping for confidence intervals, a nice generic method for getting some sense of precision. But be careful: there are many common abuses of the bootstrap, for example to obtain inference in small samples.
:::

```{marginfigure, echo=TRUE}
<img src="images/data_colada_uniform.png"/>
A suspiciously uniform distribution abruptly cutting off at 50k miles. Ring the alarm!
```

::: {.accident-report}
‚ö†Ô∏è Accident report: Visualizations have been instrumental in detecting fraudulent data. For example, when [@datacolada] made a simple histogram of the car mileage data reported in [@shu2012signing] and released publicly by [@kristal2020signing], they were immediately able to observe that it followed an unusually uniform distribution, truncated at exactly 50,000 miles. Over a given period of time, we would typically expect something more bell-shaped: a small number of people will drive very little (e.g. 1000 miles), a small number of people will drive a lot (e.g. 50,000 miles), but most people will fall between these tails. It is highly surprising to find exactly the same number of drivers in every mileage bin. While more specialized analyses revealed further evidence of fraud (e.g. based on patterns of rounding and pairs of duplicated data points), this humble histogram was already enough to set off alarm bells. A recurring regret raised by the co-authors of this paper is that they never thought to visualize the data before reporting statistics.
:::
